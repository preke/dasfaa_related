{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_list = [\n",
    "    'DR0008_activity_accumulator_2016_09.csv',\n",
    "    'DR0008_activity_accumulator_2016-10.csv',\n",
    "    'DR0008_activity_accumulator_2016-11.csv',\n",
    "    'DR0008_activity_accumulator_2016-12.csv'\n",
    "]\n",
    "\n",
    "def create_day_seq(days, length):\n",
    "\n",
    "    tmp_dict = {}\n",
    "    for day in days:\n",
    "        try:\n",
    "            tmp_dict[day] += 1\n",
    "        except:\n",
    "            tmp_dict[day] = 1\n",
    "    res = [0]*(length+1)\n",
    "    for k,v in tmp_dict.items():\n",
    "        res[k] = v\n",
    "    return res\n",
    "\n",
    "def extract_function_seq(data_path, function, month='9', within_day=False):\n",
    "    df                   = pd.read_csv(data_path, sep='\\t')\n",
    "    df_temp              = df[df['event_type'] == function][['De-id', 'timestamp']]\n",
    "    df_temp['timestamp'] = df_temp['timestamp'].apply(pd.to_datetime)\n",
    "    df_temp['day']       = df_temp['timestamp'].apply(lambda x: x.day)\n",
    "    df_day_list          = df_temp[['De-id', 'day']].groupby('De-id').agg(create_day_seq, length=df_temp['day'].nunique()).reset_index()\n",
    "    df_day_list.columns  = ['De-id', month + '_day_list']\n",
    "    return df_day_list\n",
    "\n",
    "\n",
    "def ApEn(U, m, r):\n",
    "\n",
    "    def _maxdist(x_i, x_j):\n",
    "        return max([abs(ua - va) for ua, va in zip(x_i, x_j)])\n",
    "\n",
    "    def _phi(m):\n",
    "        x = [[U[j] for j in range(i, i + m - 1 + 1)] for i in range(N - m + 1)]\n",
    "        C = [len([1 for x_j in x if _maxdist(x_i, x_j) <= r]) / (N - m + 1.0) for x_i in x]\n",
    "        return (N - m + 1.0)**(-1) * sum(np.log(C))\n",
    "\n",
    "    N = len(U)\n",
    "\n",
    "    return abs(_phi(m+1) - _phi(m))\n",
    "\n",
    "def get_all_seq(data_path_list, function):\n",
    "    first_flag = 1\n",
    "    for data_path in data_path_list:\n",
    "        df_day_list = extract_function_seq(data_path, function, data_path.split('.')[0][-2:])\n",
    "        if first_flag:\n",
    "            df_all = df_day_list.copy()\n",
    "            first_flag = 0\n",
    "        else:\n",
    "            df_all = pd.merge(df_all, df_day_list, on='De-id', how='left')\n",
    "\n",
    "    df_all['09_day_list'] = df_all['09_day_list'].fillna(0)\n",
    "    df_all['10_day_list'] = df_all['10_day_list'].fillna(0)\n",
    "    df_all['11_day_list'] = df_all['11_day_list'].fillna(0)\n",
    "    df_all['12_day_list'] = df_all['12_day_list'].fillna(0)\n",
    "\n",
    "    df_all['09_day_list'] = df_all['09_day_list'].apply(lambda x: [0]*31 if x == 0 else x)\n",
    "    df_all['10_day_list'] = df_all['10_day_list'].apply(lambda x: [0]*32 if x == 0 else x)\n",
    "    df_all['11_day_list'] = df_all['11_day_list'].apply(lambda x: [0]*31 if x == 0 else x)\n",
    "    df_all['12_day_list'] = df_all['12_day_list'].apply(lambda x: [0]*32 if x == 0 else x)\n",
    "\n",
    "    df_all['total_list']  = df_all.apply(lambda row: row['09_day_list'][1:] +  row['10_day_list'][1:]\n",
    "                                           + row['11_day_list'][1:] +  row['12_day_list'][1:], axis=1)\n",
    "    return df_all\n",
    "\n",
    "def get_seq_entropy(df_all, m):\n",
    "    \n",
    "    df_all['09_entropy' + '_' + str(m)]    = df_all['09_day_list'].apply(lambda x: ApEn(x, m=m, r=np.mean(x)*0.2))\n",
    "    df_all['10_entropy' + '_' + str(m)]    = df_all['10_day_list'].apply(lambda x: ApEn(x, m=m, r=np.mean(x)*0.2))\n",
    "    df_all['11_entropy' + '_' + str(m)]    = df_all['11_day_list'].apply(lambda x: ApEn(x, m=m, r=np.mean(x)*0.2))\n",
    "    df_all['12_entropy' + '_' + str(m)]    = df_all['12_day_list'].apply(lambda x: ApEn(x, m=m, r=np.mean(x)*0.2))\n",
    "    \n",
    "    df_all['total_entropy' + '_' + str(m)] = df_all['total_list'].apply(lambda x: ApEn(x, m=m, r=np.mean(x)*0.2))\n",
    "    return df_all\n",
    "\n",
    "\n",
    "\n",
    "def get_weekday_seq_entropy(df_all, m):\n",
    "\n",
    "    \n",
    "    df_all['09_weekday_entropy' + '_' + str(m)]    = df_all['09_weekday_seq'].apply(lambda x: ApEn(x, m=m, r=np.mean(x)*0.2))\n",
    "    df_all['10_weekday_entropy' + '_' + str(m)]    = df_all['10_weekday_seq'].apply(lambda x: ApEn(x, m=m, r=np.mean(x)*0.2))\n",
    "    df_all['11_weekday_entropy' + '_' + str(m)]    = df_all['11_weekday_seq'].apply(lambda x: ApEn(x, m=m, r=np.mean(x)*0.2))\n",
    "    df_all['12_weekday_entropy' + '_' + str(m)]    = df_all['12_weekday_seq'].apply(lambda x: ApEn(x, m=m, r=np.mean(x)*0.2))\n",
    "    \n",
    "    df_all['total_weekday_entropy' + '_' + str(m)] = df_all['total_weekday_seq'].apply(lambda x: ApEn(x, m=m, r=np.mean(x)*0.2))\n",
    "    return df_all\n",
    "\n",
    "\n",
    "def get_weekend_seq_entropy(df_all, m):\n",
    "    \n",
    "    df_all['09_weekend_entropy' + '_' + str(m)]    = df_all['09_weekend_seq'].apply(lambda x: ApEn(x, m=m, r=np.mean(x)*0.2))\n",
    "    df_all['10_weekend_entropy' + '_' + str(m)]    = df_all['10_weekend_seq'].apply(lambda x: ApEn(x, m=m, r=np.mean(x)*0.2))\n",
    "    df_all['11_weekend_entropy' + '_' + str(m)]    = df_all['11_weekend_seq'].apply(lambda x: ApEn(x, m=m, r=np.mean(x)*0.2))\n",
    "    df_all['12_weekend_entropy' + '_' + str(m)]    = df_all['12_weekend_seq'].apply(lambda x: ApEn(x, m=m, r=np.mean(x)*0.2))\n",
    "    \n",
    "    df_all['total_weekend_entropy' + '_' + str(m)] = df_all['total_weekend_seq'].apply(lambda x: ApEn(x, m=m, r=np.mean(x)*0.2))\n",
    "    return df_all\n",
    "\n",
    "def add_at_risk_label(df_all):\n",
    "    at_rsk_label            = pd.read_csv('Std_list_atRist_2016_se1.csv')\n",
    "    at_rsk_label['at_risk'] = at_rsk_label['CUM_GPA'].apply(lambda x: '1' if x <= 2.0 else '0')\n",
    "    at_rsk_label.columns    = ['De-id', 'CUM_GPA', 'at_risk']\n",
    "    df_all                  = pd.merge(df_all, at_rsk_label, on='De-id', how='left')\n",
    "    df_all['at_risk']       = df_all['at_risk'].fillna('0')\n",
    "    return df_all\n",
    "\n",
    "\n",
    "def get_weekday(day_list):\n",
    "    weekday_list = []\n",
    "    for i in range(len(day_list)):\n",
    "        if (i + 4) % 7 > 0 and (i + 4) % 7 <= 5: # 4 indicates 2016.9.1 is Thursday\n",
    "            weekday_list.append(day_list[i])\n",
    "    return weekday_list\n",
    "\n",
    "def get_weekend(day_list):\n",
    "    weekend_list = []\n",
    "    for i in range(len(day_list)):\n",
    "        if (i + 4) % 7 > 0 and (i + 4) % 7 <= 5: # 4 indicates 2016.9.1 is Thursday\n",
    "            pass\n",
    "        else:\n",
    "            weekend_list.append(day_list[i])\n",
    "    return weekend_list\n",
    "\n",
    "def int_handle_cnt(internel_handle_list, df_int_handle, name):\n",
    "    df_temp = df_int_handle[df_int_handle['internal_handle'].isin(internel_handle_list)]\n",
    "    df_temp = df_temp.groupby(['De-id']).count().reset_index('De-id')\n",
    "    df_temp.columns = ['De-id', PRE_FIX + name]\n",
    "    return df_temp\n",
    "\n",
    "def extract_one_month(df, PRE_FIX):\n",
    "    df_t = df[(df['event_type']=='PAGE_ACCESS') |\n",
    "              (df['event_type']=='COURSE_ACCESS') |\n",
    "              (df['event_type']=='LOGIN_ATTEMPT') |\n",
    "              (df['event_type']=='SESSION_TIMEOUT') |\n",
    "              (df['event_type']=='LOGOUT')]\n",
    "    df_t = df_t[['De-id', 'event_type', 'course_id', 'internal_handle', 'timestamp']]\n",
    "\n",
    "    df_evt = df_t[['De-id', 'event_type']]\n",
    "    df_login = df_evt[df_evt['event_type'] == 'LOGIN_ATTEMPT'].groupby(['De-id']).count().reset_index('De-id')\n",
    "    df_login.columns = ['De-id', PRE_FIX + 'LOGIN_ATTEMPT']\n",
    "\n",
    "    df_se_out = df_evt[df_evt['event_type'] == 'SESSION_TIMEOUT'].groupby(['De-id']).count().reset_index('De-id')\n",
    "    df_se_out.columns = ['De-id', PRE_FIX + 'SESSION_TIMEOUT']\n",
    "\n",
    "    df_logout = df_evt[df_evt['event_type'] == 'LOGOUT'].groupby(['De-id']).count().reset_index('De-id')\n",
    "    df_logout.columns = ['De-id', PRE_FIX + 'LOGOUT']\n",
    "\n",
    "    df_all = df_login\n",
    "    df_all = pd.merge(df_all, df_se_out, on='De-id', how='left')\n",
    "    df_all = pd.merge(df_all, df_logout, on='De-id', how='left')\n",
    "\n",
    "    df_int_handle = df_t[['De-id', 'internal_handle']]\n",
    "\n",
    "    group_list        = ['groups', 'cp_group_create_self_groupmem', 'group_file', 'group_file', 'group_forum', 'groups_sign_up', 'agroup', 'group_blogs','group_task_create', 'group_task_view','cp_group_edit_self_groupmem','group_file_add', 'group_email', 'cp_groups', 'cp_groups_settings','edit_group_blog_entry', 'db_forum_collection_group', 'group_tasks', 'group_journal','group_virtual_classroom', 'add_group_journal_entry','email_all_groups', 'edit_group_journal_entry', 'email_select_groups', 'add_group_blog_entry']\n",
    "    db_list           = ['discussion_board_entry', 'db_thread_list_entry', 'discussion_board', 'db_thread_list','db_collection', 'db_collection_group', 'db_collection_entry', 'db_thread_list_group']\n",
    "    myinfo_list       = ['my_inst_personal_info', 'my_inst_personal_settings','my_inst_personal_edit', 'my_inst_myplaces_settings','my_tasks', 'my_task_create', 'my_email_courses','my_task_view', 'my_announcements']\n",
    "    course_list       = ['course_tools_area', 'course_task_view', 'enroll_course', 'classic_course_catalog']\n",
    "    journal_list      = ['journal', 'journal_view', 'view_draft_journal_entry',  'add_journal_entry', 'edit_journal_entry']\n",
    "    email_list        = ['send_email', 'email_all_instructors', 'email_all_students', 'email_select_students','email_all_users',  'email_select_groups','email_all_groups']\n",
    "    staff_list        = ['staff_information', 'cp_staff_information']\n",
    "    annoucements_list = ['my_announcements', 'announcements_entry', 'announcements', 'cp_announcements']\n",
    "    content_list      = ['content', 'cp_content']\n",
    "    grade_list        = ['check_grade']\n",
    "\n",
    "    df_group        = int_handle_cnt(group_list, df_int_handle, 'group')\n",
    "    df_db           = int_handle_cnt(db_list, df_int_handle, 'db')\n",
    "    df_myinfo       = int_handle_cnt(myinfo_list, df_int_handle, 'myinfo')\n",
    "    df_course       = int_handle_cnt(course_list, df_int_handle, 'course')\n",
    "    df_journal      = int_handle_cnt(journal_list, df_int_handle, 'journal')\n",
    "    df_email        = int_handle_cnt(email_list, df_int_handle, 'email')\n",
    "    df_staff        = int_handle_cnt(staff_list, df_int_handle, 'staff')\n",
    "    df_annoucements = int_handle_cnt(annoucements_list, df_int_handle, 'annoucements')\n",
    "    df_content      = int_handle_cnt(content_list, df_int_handle, 'content')\n",
    "    df_grade        = int_handle_cnt(grade_list, df_int_handle, 'grade')\n",
    "\n",
    "    dfs = [df_group, df_db, df_myinfo, df_course, df_journal, df_email, df_staff, df_annoucements, df_content, df_grade]\n",
    "\n",
    "    for df in dfs:\n",
    "        df_all = pd.merge(df_all, df, on='De-id', how='left')   \n",
    "\n",
    "    df_all = df_all.rename(columns={'De-id':'MASKED_STUDENT_ID'})\n",
    "    return df_all\n",
    "\n",
    "\n",
    "def get_weekday_entropy(df_all, m, function):\n",
    "    df_all['09_weekday_entropy' + '_' + str(function)]    = df_all['09_weekday_seq'].apply(lambda x: ApEn(x, m=m, r=np.mean(x)*0.2))\n",
    "    df_all['10_weekday_entropy' + '_' + str(function)]    = df_all['10_weekday_seq'].apply(lambda x: ApEn(x, m=m, r=np.mean(x)*0.2))\n",
    "    df_all['11_weekday_entropy' + '_' + str(function)]    = df_all['11_weekday_seq'].apply(lambda x: ApEn(x, m=m, r=np.mean(x)*0.2))\n",
    "    df_all['12_weekday_entropy' + '_' + str(function)]    = df_all['12_weekday_seq'].apply(lambda x: ApEn(x, m=m, r=np.mean(x)*0.2))\n",
    "    # df_all['lib_total_weekday_entropy' + '_' + str(m)] = df_all['lib_total_weekday_seq'].apply(lambda x: ApEn(x, m=m, r=np.mean(x)*0.2))\n",
    "    return df_all\n",
    "\n",
    "def get_weekend_entropy(df_all, m, function):\n",
    "    df_all['09_weekend_entropy' + '_' + str(function)]    = df_all['09_weekend_seq'].apply(lambda x: ApEn(x, m=m, r=np.mean(x)*0.2))\n",
    "    df_all['10_weekend_entropy' + '_' + str(function)]    = df_all['10_weekend_seq'].apply(lambda x: ApEn(x, m=m, r=np.mean(x)*0.2))\n",
    "    df_all['11_weekend_entropy' + '_' + str(function)]    = df_all['11_weekend_seq'].apply(lambda x: ApEn(x, m=m, r=np.mean(x)*0.2))\n",
    "    df_all['12_weekend_entropy' + '_' + str(function)]    = df_all['12_weekend_seq'].apply(lambda x: ApEn(x, m=m, r=np.mean(x)*0.2))\n",
    "    # df_all['lib_total_weekend_entropy' + '_' + str(m)] = df_all['lib_total_weekend_seq'].apply(lambda x: ApEn(x, m=m, r=np.mean(x)*0.2))\n",
    "    return df_all\n",
    "\n",
    "def get_funtions_seq(df_temp=None, function=None):\n",
    "    if df_temp is None:\n",
    "        df_temp = get_all_seq(data_path_list, function)\n",
    "    \n",
    "    df_temp['09_weekday_seq']    = df_temp['09_day_list'].apply(get_weekday)\n",
    "    df_temp['09_weekend_seq']    = df_temp['09_day_list'].apply(get_weekend)\n",
    "    df_temp['10_weekday_seq']    = df_temp['10_day_list'].apply(get_weekday)\n",
    "    df_temp['10_weekend_seq']    = df_temp['10_day_list'].apply(get_weekend)\n",
    "    df_temp['11_weekday_seq']    = df_temp['11_day_list'].apply(get_weekday)\n",
    "    df_temp['11_weekend_seq']    = df_temp['11_day_list'].apply(get_weekend)\n",
    "    df_temp['12_weekday_seq']    = df_temp['12_day_list'].apply(get_weekday)\n",
    "    df_temp['12_weekend_seq']    = df_temp['12_day_list'].apply(get_weekend)\n",
    "\n",
    "    df_temp = get_weekday_entropy(df_temp, 5, function)\n",
    "    df_temp = get_weekend_entropy(df_temp, 2, function)\n",
    "    df_temp = df_temp.rename(columns={'De-id':'MASKED_STUDENT_ID'})\n",
    "    return df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_se1 = pd.read_csv('2016_se1_lib_lms.csv')\n",
    "df_se1.head()\n",
    "df_se1_features = df_se1[[i for i in df_se1.columns if i != 'label_atRist']]\n",
    "df_se1_labels = df_se1['label_atRist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['workday', 'weekend', 'morning', 'afternoon', 'evening', 'overnight',\n",
       "       'workday_ExamMonth', 'weekend_ExamMonth', 'morning_ExamMonth',\n",
       "       'afternoon_ExamMonth', 'evening_ExamMonth', 'overnight_ExamMonth',\n",
       "       'workday_notExamMonth', 'weekend_notExamMonth', 'morning_notExamMonth',\n",
       "       'afternoon_notExamMonth', 'evening_notExamMonth',\n",
       "       'overnight_notExamMonth', 'workday_firstMonth', 'weekend_firstMonth',\n",
       "       'morning_firstMonth', 'afternoon_firstMonth', 'evening_firstMonth',\n",
       "       'overnight_firstMonth', 'examMonth', 'notExamMonth', 'firstMonth',\n",
       "       'total_checkin', '09LOGIN_ATTEMPT', '09SESSION_TIMEOUT', '09LOGOUT',\n",
       "       '09group', '09db', '09myinfo', '09course', '09journal', '09email',\n",
       "       '09staff', '09annoucements', '09content', '09grade', '10LOGIN_ATTEMPT',\n",
       "       '10SESSION_TIMEOUT', '10LOGOUT', '10group', '10db', '10myinfo',\n",
       "       '10course', '10journal', '10email', '10staff', '10annoucements',\n",
       "       '10content', '10grade', '11LOGIN_ATTEMPT', '11SESSION_TIMEOUT',\n",
       "       '11LOGOUT', '11group', '11db', '11myinfo', '11course', '11journal',\n",
       "       '11email', '11staff', '11annoucements', '11content', '11grade',\n",
       "       '12LOGIN_ATTEMPT', '12SESSION_TIMEOUT', '12LOGOUT', '12group', '12db',\n",
       "       '12myinfo', '12course', '12journal', '12email', '12staff',\n",
       "       '12annoucements', '12content', '12grade'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_se1_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting seq of PAGE_ACCESS ...\n",
      "getting seq of LOGIN_ATTEMPT ...\n",
      "getting seq of SESSION_TIMEOUT ...\n",
      "getting seq of LOGOUT ...\n"
     ]
    }
   ],
   "source": [
    "lms_functions = ['COURSE_ACCESS', 'PAGE_ACCESS', 'LOGIN_ATTEMPT', 'SESSION_TIMEOUT', 'LOGOUT']\n",
    "index = 0\n",
    "\n",
    "for fun in lms_functions[1:]:\n",
    "    print('getting seq of', fun, '...')\n",
    "    df = get_funtions_seq(function=fun)\n",
    "    features = [i for i in list(df.columns) if i.endswith(fun)]\n",
    "    features.append('MASKED_STUDENT_ID')\n",
    "    df_se1_features = pd.merge(df_se1_features, df[features], on='MASKED_STUDENT_ID', how='left').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>De-id</th>\n",
       "      <th>lib_total_list</th>\n",
       "      <th>09_day_list</th>\n",
       "      <th>10_day_list</th>\n",
       "      <th>11_day_list</th>\n",
       "      <th>12_day_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8TMIKVZ5</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 4, 0, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 4, 0, 1, ...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, ...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 2, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OZ6FIGHH</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 7, 0, 0, 0, 1, 0, 3, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 0, 0, 0, 5, 1, 4, 2, 2, 2, 1, 0, 2, 1, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QSGBC7CZ</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EIC4AO9Q</td>\n",
       "      <td>[0, 2, 1, 0, 2, 2, 1, 1, 0, 0, 0, 1, 0, 1, 0, ...</td>\n",
       "      <td>[0, 2, 1, 0, 2, 2, 1, 1, 0, 0, 0, 1, 0, 1, 0, ...</td>\n",
       "      <td>[0, 0, 0, 2, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, ...</td>\n",
       "      <td>[0, 2, 0, 1, 1, 0, 0, 1, 1, 0, 2, 0, 0, 1, 2, ...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S9BIH11O</td>\n",
       "      <td>[0, 3, 1, 0, 6, 2, 1, 1, 3, 0, 0, 4, 2, 3, 3, ...</td>\n",
       "      <td>[0, 3, 1, 0, 6, 2, 1, 1, 3, 0, 0, 4, 2, 3, 3, ...</td>\n",
       "      <td>[7, 3, 5, 3, 5, 2, 2, 3, 0, 4, 6, 1, 2, 6, 4, ...</td>\n",
       "      <td>[2, 3, 2, 4, 3, 0, 4, 2, 1, 2, 3, 3, 2, 5, 2, ...</td>\n",
       "      <td>[3, 0, 3, 2, 10, 3, 3, 4, 5, 1, 4, 3, 2, 2, 3,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      De-id                                     lib_total_list  \\\n",
       "0  8TMIKVZ5  [0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 4, 0, 1, ...   \n",
       "1  OZ6FIGHH  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  QSGBC7CZ  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...   \n",
       "3  EIC4AO9Q  [0, 2, 1, 0, 2, 2, 1, 1, 0, 0, 0, 1, 0, 1, 0, ...   \n",
       "4  S9BIH11O  [0, 3, 1, 0, 6, 2, 1, 1, 3, 0, 0, 4, 2, 3, 3, ...   \n",
       "\n",
       "                                         09_day_list  \\\n",
       "0  [0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 4, 0, 1, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...   \n",
       "3  [0, 2, 1, 0, 2, 2, 1, 1, 0, 0, 0, 1, 0, 1, 0, ...   \n",
       "4  [0, 3, 1, 0, 6, 2, 1, 1, 3, 0, 0, 4, 2, 3, 3, ...   \n",
       "\n",
       "                                         10_day_list  \\\n",
       "0  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, ...   \n",
       "1  [1, 1, 1, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 2, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, ...   \n",
       "4  [7, 3, 5, 3, 5, 2, 2, 3, 0, 4, 6, 1, 2, 6, 4, ...   \n",
       "\n",
       "                                         11_day_list  \\\n",
       "0  [1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 2, ...   \n",
       "1  [0, 0, 0, 7, 0, 0, 0, 1, 0, 3, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 2, 0, 1, 1, 0, 0, 1, 1, 0, 2, 0, 0, 1, 2, ...   \n",
       "4  [2, 3, 2, 4, 3, 0, 4, 2, 1, 2, 3, 3, 2, 5, 2, ...   \n",
       "\n",
       "                                         12_day_list  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [1, 0, 0, 0, 5, 1, 4, 2, 2, 2, 1, 0, 2, 1, 2, ...  \n",
       "2  [0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, ...  \n",
       "3  [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...  \n",
       "4  [3, 0, 3, 2, 10, 3, 3, 4, 5, 1, 4, 3, 2, 2, 3,...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lib_seq = pd.read_csv('Std_Lib_sequence_day_2016_se1.csv')\n",
    "df_lib_seq = df_lib_seq[['0','1']]\n",
    "df_lib_seq = df_lib_seq.rename(columns= {'0': 'De-id', '1':'lib_total_list'})\n",
    "\n",
    "\n",
    "semester_days = 122\n",
    "def clean_list(day_list):\n",
    "    try: \n",
    "        len(day_list)\n",
    "        ans = day_list[2:-2].split('.')[:-1]\n",
    "        return [int(i) for i in ans]\n",
    "    except:\n",
    "        return [0] * semester_days \n",
    "df_lib_seq['lib_total_list'] = df_lib_seq['lib_total_list'].apply(clean_list)\n",
    "\n",
    "df_lib_seq['09_day_list'] = df_lib_seq['lib_total_list'].apply(lambda x: x[:30])\n",
    "df_lib_seq['10_day_list'] = df_lib_seq['lib_total_list'].apply(lambda x: x[30:61])\n",
    "df_lib_seq['11_day_list'] = df_lib_seq['lib_total_list'].apply(lambda x: x[61:91])\n",
    "df_lib_seq['12_day_list'] = df_lib_seq['lib_total_list'].apply(lambda x: x[91:122])\n",
    "\n",
    "df_lib_seq_ = get_funtions_seq(df_lib_seq, 'LIB')\n",
    "features = [i for i in list(df_lib_seq_.columns) if i.endswith('LIB')]\n",
    "features.append('MASKED_STUDENT_ID')\n",
    "df_se1_features = pd.merge(df_se1_features, df_lib_seq_[features], on='MASKED_STUDENT_ID', how='left').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_se1_features.to_csv('all_seq_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_se1_features = df_se1_features[[i for i in df_se1_features.columns if i != 'label_atRist' and i != 'MASKED_STUDENT_ID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the classifier is : gradient_boost\n",
      "1551\n",
      "Sum of predictions: 111\n",
      "Sum of Y test: 38\n",
      "the neg recall is : 0.2631578947368421\n",
      "10.0\n",
      "the pos recall is : 0.9332452081956378\n",
      "the score is : 0.9168278529980658\n",
      "1551\n",
      "Sum of predictions: 111\n",
      "Sum of Y test: 38\n",
      "the neg recall is : 0.2631578947368421\n",
      "10.0\n",
      "the pos recall is : 0.9332452081956378\n",
      "the score is : 0.9168278529980658\n",
      "1551\n",
      "Sum of predictions: 111\n",
      "Sum of Y test: 38\n",
      "the neg recall is : 0.2631578947368421\n",
      "10.0\n",
      "the pos recall is : 0.9332452081956378\n",
      "the score is : 0.9168278529980658\n",
      "1551\n",
      "Sum of predictions: 111\n",
      "Sum of Y test: 38\n",
      "the neg recall is : 0.2631578947368421\n",
      "10.0\n",
      "the pos recall is : 0.9332452081956378\n",
      "the score is : 0.9168278529980658\n",
      "1551\n",
      "Sum of predictions: 111\n",
      "Sum of Y test: 38\n",
      "the neg recall is : 0.2631578947368421\n",
      "10.0\n",
      "the pos recall is : 0.9332452081956378\n",
      "the score is : 0.9168278529980658\n",
      "1551\n",
      "Sum of predictions: 111\n",
      "Sum of Y test: 38\n",
      "the neg recall is : 0.2631578947368421\n",
      "10.0\n",
      "the pos recall is : 0.9332452081956378\n",
      "the score is : 0.9168278529980658\n",
      "1551\n",
      "Sum of predictions: 111\n",
      "Sum of Y test: 38\n",
      "the neg recall is : 0.2631578947368421\n",
      "10.0\n",
      "the pos recall is : 0.9332452081956378\n",
      "the score is : 0.9168278529980658\n",
      "1551\n",
      "Sum of predictions: 111\n",
      "Sum of Y test: 38\n",
      "the neg recall is : 0.2631578947368421\n",
      "10.0\n",
      "the pos recall is : 0.9332452081956378\n",
      "the score is : 0.9168278529980658\n",
      "1551\n",
      "Sum of predictions: 111\n",
      "Sum of Y test: 38\n",
      "the neg recall is : 0.2631578947368421\n",
      "10.0\n",
      "the pos recall is : 0.9332452081956378\n",
      "the score is : 0.9168278529980658\n",
      "1551\n",
      "Sum of predictions: 111\n",
      "Sum of Y test: 38\n",
      "the neg recall is : 0.2631578947368421\n",
      "10.0\n",
      "the pos recall is : 0.9332452081956378\n",
      "the score is : 0.9168278529980658\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, SVMSMOTE\n",
    "\n",
    "from sklearn import tree, svm, naive_bayes,neighbors\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "def try_different_method(clf):\n",
    "    clf.fit(X_resampled_smote,y_resampled_smote.ravel())\n",
    "    # predictions = clf.predict(X_test)\n",
    "    y_predprob = clf.predict_proba(X_test)[:,1]\n",
    "    predictions = np.array([1 if i > 0.001 else 0 for i in y_predprob ])\n",
    "    print(len(predictions))\n",
    "    print('Sum of predictions:', predictions.sum())\n",
    "    print('Sum of Y test:', y_test.sum())\n",
    "    neg_recall = recall_score(y_test, predictions, pos_label=1)\n",
    "    print('the neg recall is :', neg_recall)\n",
    "    print(neg_recall*y_test.sum())\n",
    "    pos_recall = recall_score(y_test, predictions, pos_label=0)\n",
    "    print('the pos recall is :', pos_recall)\n",
    "    score = f1_score(y_test, predictions, average='micro')\n",
    "    print('the score is :', score)\n",
    "    return y_predprob\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_se1_features, df_se1_labels, test_size = 0.1, stratify=df_se1_labels)\n",
    "X_resampled_smote, y_resampled_smote = SVMSMOTE(random_state=42, sampling_strategy='auto',k_neighbors=10).fit_sample(X_train, y_train)\n",
    "clfs = {\n",
    "    #     'svm': svm.SVC(),\\\n",
    "    #         'decision_tree':tree.DecisionTreeClassifier(),\n",
    "    #         'naive_gaussian': naive_bayes.GaussianNB(), \\\n",
    "    #         'naive_mul':naive_bayes.MultinomialNB(),\\\n",
    "    #         'K_neighbor' : neighbors.KNeighborsClassifier(),\\\n",
    "    #         'bagging_knn' : BaggingClassifier(neighbors.KNeighborsClassifier(), max_samples=0.5,max_features=0.5), \\\n",
    "    #         'bagging_tree': BaggingClassifier(tree.DecisionTreeClassifier(), max_samples=0.5,max_features=0.5),\n",
    "            #'random_forest' : RandomForestClassifier(n_estimators=50),\\\n",
    "    #         'adaboost':AdaBoostClassifier(n_estimators=50),\\\n",
    "        'gradient_boost' : GradientBoostingClassifier(n_estimators=50, learning_rate=0.5,max_depth=10, random_state=0, min_samples_leaf=2),\n",
    "            }\n",
    "y_predprob = np.array([0]*len(y_test))\n",
    "for clf_key in clfs.keys():\n",
    "    print('the classifier is :',clf_key)\n",
    "    clf = clfs[clf_key]\n",
    "    for i in range(0, 10):\n",
    "        predprob = try_different_method(clf)\n",
    "        y_predprob = y_predprob + predprob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4651\n",
      "Sum of predictions: 413\n",
      "Sum of Y test: 114\n",
      "the neg recall is : 0.24561403508771928\n",
      "28.0\n",
      "the pos recall is : 0.9151421644258321\n",
      "the score is : 0.898731455600946\n"
     ]
    }
   ],
   "source": [
    "    predictions = np.array([1 if i > 0.001 else 0 for i in y_predprob ])\n",
    "    print(len(predictions))\n",
    "    print('Sum of predictions:', predictions.sum())\n",
    "    print('Sum of Y test:', y_test.sum())\n",
    "    neg_recall = recall_score(y_test, predictions, pos_label=1)\n",
    "    print('the neg recall is :', neg_recall)\n",
    "    print(neg_recall*y_test.sum())\n",
    "    pos_recall = recall_score(y_test, predictions, pos_label=0)\n",
    "    print('the pos recall is :', pos_recall)\n",
    "    score = f1_score(y_test, predictions, average='micro')\n",
    "    print('the score is :', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.101000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.954869e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.938999e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.952236e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.198245e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.049353e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.348784e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.994582e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "count  3.101000e+03\n",
       "mean   2.954869e-03\n",
       "std    3.938999e-02\n",
       "min    2.952236e-07\n",
       "25%    9.198245e-06\n",
       "50%    3.049353e-05\n",
       "75%    1.348784e-04\n",
       "max    9.994582e-01"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_predprob).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = [\n",
    "    'workday',\n",
    " 'weekend',\n",
    " 'morning',\n",
    " 'afternoon',\n",
    " 'evening',\n",
    " 'overnight',\n",
    " 'workday_ExamMonth',\n",
    " 'weekend_ExamMonth',\n",
    " 'morning_ExamMonth',\n",
    " 'afternoon_ExamMonth',\n",
    " 'evening_ExamMonth',\n",
    " 'overnight_ExamMonth',\n",
    " 'workday_notExamMonth',\n",
    " 'weekend_notExamMonth',\n",
    " 'morning_notExamMonth',\n",
    " 'afternoon_notExamMonth',\n",
    " 'evening_notExamMonth',\n",
    " 'overnight_notExamMonth',\n",
    " 'workday_firstMonth',\n",
    " 'weekend_firstMonth',\n",
    " 'morning_firstMonth',\n",
    " 'afternoon_firstMonth',\n",
    " 'evening_firstMonth',\n",
    " 'overnight_firstMonth',\n",
    " 'examMonth',\n",
    " 'notExamMonth',\n",
    " 'firstMonth'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = list(df_se1_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "common = ['workday',\n",
    " 'weekend',\n",
    " 'morning',\n",
    " 'afternoon',\n",
    " 'evening',\n",
    " 'overnight',\n",
    " 'workday_ExamMonth',\n",
    " 'weekend_ExamMonth',\n",
    " 'morning_ExamMonth',\n",
    " 'afternoon_ExamMonth',\n",
    " 'evening_ExamMonth',\n",
    " 'overnight_ExamMonth',\n",
    " 'workday_notExamMonth',\n",
    " 'weekend_notExamMonth',\n",
    " 'morning_notExamMonth',\n",
    " 'afternoon_notExamMonth',\n",
    " 'evening_notExamMonth',\n",
    " 'overnight_notExamMonth',\n",
    " 'workday_firstMonth',\n",
    " 'weekend_firstMonth',\n",
    " 'morning_firstMonth',\n",
    " 'afternoon_firstMonth',\n",
    " 'evening_firstMonth',\n",
    " 'overnight_firstMonth',\n",
    " 'examMonth',\n",
    " 'notExamMonth',\n",
    " 'firstMonth']\n",
    "fs_09 = [i for i in fs if i.startswith('09')]\n",
    "fs_09 = common + fs_09\n",
    "fs_10 = [i for i in fs if i.startswith('10')]\n",
    "fs_10 = fs_09 + fs_10\n",
    "fs_11 = [i for i in fs if i.startswith('11')]\n",
    "fs_11 = fs_10 + fs_11\n",
    "fs_12 = [i for i in fs if i.startswith('12')]\n",
    "fs_12 = fs_11 + fs_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['workday',\n",
       " 'weekend',\n",
       " 'morning',\n",
       " 'afternoon',\n",
       " 'evening',\n",
       " 'overnight',\n",
       " 'workday_ExamMonth',\n",
       " 'weekend_ExamMonth',\n",
       " 'morning_ExamMonth',\n",
       " 'afternoon_ExamMonth',\n",
       " 'evening_ExamMonth',\n",
       " 'overnight_ExamMonth',\n",
       " 'workday_notExamMonth',\n",
       " 'weekend_notExamMonth',\n",
       " 'morning_notExamMonth',\n",
       " 'afternoon_notExamMonth',\n",
       " 'evening_notExamMonth',\n",
       " 'overnight_notExamMonth',\n",
       " 'workday_firstMonth',\n",
       " 'weekend_firstMonth',\n",
       " 'morning_firstMonth',\n",
       " 'afternoon_firstMonth',\n",
       " 'evening_firstMonth',\n",
       " 'overnight_firstMonth',\n",
       " 'examMonth',\n",
       " 'notExamMonth',\n",
       " 'firstMonth',\n",
       " '09LOGIN_ATTEMPT',\n",
       " '09SESSION_TIMEOUT',\n",
       " '09LOGOUT',\n",
       " '09group',\n",
       " '09db',\n",
       " '09myinfo',\n",
       " '09course',\n",
       " '09journal',\n",
       " '09email',\n",
       " '09staff',\n",
       " '09annoucements',\n",
       " '09content',\n",
       " '09grade',\n",
       " '09_weekday_entropy_LOGIN_ATTEMPT',\n",
       " '09_weekend_entropy_LOGIN_ATTEMPT',\n",
       " '09_weekday_entropy_PAGE_ACCESS',\n",
       " '09_weekend_entropy_PAGE_ACCESS',\n",
       " '09_weekday_entropy_COURSE_ACCESS',\n",
       " '09_weekend_entropy_COURSE_ACCESS',\n",
       " '10LOGIN_ATTEMPT',\n",
       " '10SESSION_TIMEOUT',\n",
       " '10LOGOUT',\n",
       " '10group',\n",
       " '10db',\n",
       " '10myinfo',\n",
       " '10course',\n",
       " '10journal',\n",
       " '10email',\n",
       " '10staff',\n",
       " '10annoucements',\n",
       " '10content',\n",
       " '10grade',\n",
       " '10_weekday_entropy_LOGIN_ATTEMPT',\n",
       " '10_weekend_entropy_LOGIN_ATTEMPT',\n",
       " '10_weekday_entropy_PAGE_ACCESS',\n",
       " '10_weekend_entropy_PAGE_ACCESS',\n",
       " '10_weekday_entropy_COURSE_ACCESS',\n",
       " '10_weekend_entropy_COURSE_ACCESS',\n",
       " '11LOGIN_ATTEMPT',\n",
       " '11SESSION_TIMEOUT',\n",
       " '11LOGOUT',\n",
       " '11group',\n",
       " '11db',\n",
       " '11myinfo',\n",
       " '11course',\n",
       " '11journal',\n",
       " '11email',\n",
       " '11staff',\n",
       " '11annoucements',\n",
       " '11content',\n",
       " '11grade',\n",
       " '11_weekday_entropy_LOGIN_ATTEMPT',\n",
       " '11_weekend_entropy_LOGIN_ATTEMPT',\n",
       " '11_weekday_entropy_PAGE_ACCESS',\n",
       " '11_weekend_entropy_PAGE_ACCESS',\n",
       " '11_weekday_entropy_COURSE_ACCESS',\n",
       " '11_weekend_entropy_COURSE_ACCESS',\n",
       " '12LOGIN_ATTEMPT',\n",
       " '12SESSION_TIMEOUT',\n",
       " '12LOGOUT',\n",
       " '12group',\n",
       " '12db',\n",
       " '12myinfo',\n",
       " '12course',\n",
       " '12journal',\n",
       " '12email',\n",
       " '12staff',\n",
       " '12annoucements',\n",
       " '12content',\n",
       " '12grade',\n",
       " '12_weekday_entropy_LOGIN_ATTEMPT',\n",
       " '12_weekend_entropy_LOGIN_ATTEMPT',\n",
       " '12_weekday_entropy_PAGE_ACCESS',\n",
       " '12_weekend_entropy_PAGE_ACCESS',\n",
       " '12_weekday_entropy_COURSE_ACCESS',\n",
       " '12_weekend_entropy_COURSE_ACCESS']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs_12"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
