{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score, recall_score, precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree, svm, naive_bayes,neighbors\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, SVMSMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve  ###计算roc和auc\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MASKED_STUDENT_ID</th>\n",
       "      <th>workday</th>\n",
       "      <th>weekend</th>\n",
       "      <th>morning</th>\n",
       "      <th>afternoon</th>\n",
       "      <th>evening</th>\n",
       "      <th>overnight</th>\n",
       "      <th>workday_ExamMonth</th>\n",
       "      <th>weekend_ExamMonth</th>\n",
       "      <th>morning_ExamMonth</th>\n",
       "      <th>...</th>\n",
       "      <th>forteenth_weekgroup</th>\n",
       "      <th>forteenth_weekdb</th>\n",
       "      <th>forteenth_weekmyinfo</th>\n",
       "      <th>forteenth_weekcourse</th>\n",
       "      <th>forteenth_weekjournal</th>\n",
       "      <th>forteenth_weekemail</th>\n",
       "      <th>forteenth_weekstaff</th>\n",
       "      <th>forteenth_weekannoucements</th>\n",
       "      <th>forteenth_weekcontent</th>\n",
       "      <th>forteenth_weekgrade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8TMIKVZ5</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N2YYKTMZ</td>\n",
       "      <td>61</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BZRW4GD3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HJTBF62Q</td>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33XUIDIG</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 212 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  MASKED_STUDENT_ID  workday  weekend  morning  afternoon  evening  overnight  \\\n",
       "0          8TMIKVZ5       25        0        0         25        0          0   \n",
       "1          N2YYKTMZ       61        3        1         45       18          0   \n",
       "2          BZRW4GD3        0        1        0          1        0          0   \n",
       "3          HJTBF62Q       14       21        1         26        8          0   \n",
       "4          33XUIDIG       20        5        0         16        9          0   \n",
       "\n",
       "   workday_ExamMonth  weekend_ExamMonth  morning_ExamMonth  ...  \\\n",
       "0                  0                  0                  0  ...   \n",
       "1                  5                  0                  0  ...   \n",
       "2                  0                  1                  0  ...   \n",
       "3                  4                  7                  1  ...   \n",
       "4                  3                  0                  0  ...   \n",
       "\n",
       "   forteenth_weekgroup  forteenth_weekdb  forteenth_weekmyinfo  \\\n",
       "0                  9.0               0.0                   1.0   \n",
       "1                  0.0               0.0                   1.0   \n",
       "2                  0.0               0.0                   0.0   \n",
       "3                  0.0               0.0                   0.0   \n",
       "4                  0.0               0.0                   0.0   \n",
       "\n",
       "   forteenth_weekcourse  forteenth_weekjournal  forteenth_weekemail  \\\n",
       "0                   1.0                    0.0                  0.0   \n",
       "1                   0.0                    0.0                  0.0   \n",
       "2                   0.0                    0.0                  0.0   \n",
       "3                   0.0                    0.0                  0.0   \n",
       "4                   0.0                    0.0                  0.0   \n",
       "\n",
       "   forteenth_weekstaff  forteenth_weekannoucements  forteenth_weekcontent  \\\n",
       "0                  0.0                         4.0                  187.0   \n",
       "1                  1.0                         2.0                   21.0   \n",
       "2                  0.0                         0.0                    6.0   \n",
       "3                  0.0                         0.0                    0.0   \n",
       "4                  0.0                         0.0                    1.0   \n",
       "\n",
       "   forteenth_weekgrade  \n",
       "0                  1.0  \n",
       "1                  2.0  \n",
       "2                  2.0  \n",
       "3                  0.0  \n",
       "4                  0.0  \n",
       "\n",
       "[5 rows x 212 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_se1_stat = pd.read_csv('2016_se1_stat_features.csv', index_col=0)\n",
    "df_se1_stat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MASKED_STUDENT_ID</th>\n",
       "      <th>2015_se1_CUM_GPA</th>\n",
       "      <th>2015_at_risk_se1</th>\n",
       "      <th>2015_se2_CUM_GPA</th>\n",
       "      <th>2015_at_risk_se2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TNND4TTX</td>\n",
       "      <td>3.10</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2CRLLUNY</td>\n",
       "      <td>2.69</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.81</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DSDPNLSC</td>\n",
       "      <td>3.15</td>\n",
       "      <td>-1</td>\n",
       "      <td>3.04</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G8LUICJE</td>\n",
       "      <td>2.80</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.87</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CQK4ZMHC</td>\n",
       "      <td>2.57</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.48</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  MASKED_STUDENT_ID  2015_se1_CUM_GPA  2015_at_risk_se1  2015_se2_CUM_GPA  \\\n",
       "0          TNND4TTX              3.10                -1              0.00   \n",
       "1          2CRLLUNY              2.69                -1              2.81   \n",
       "2          DSDPNLSC              3.15                -1              3.04   \n",
       "3          G8LUICJE              2.80                -1              2.87   \n",
       "4          CQK4ZMHC              2.57                -1              2.48   \n",
       "\n",
       "   2015_at_risk_se2  \n",
       "0               0.0  \n",
       "1              -1.0  \n",
       "2              -1.0  \n",
       "3              -1.0  \n",
       "4              -1.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## history gpa:\n",
    "at_risk_2015 = pd.read_csv('Std_list_normal_2015_se1.csv')\n",
    "normal_2015 = pd.read_csv('Std_list_atRist_2015_se1.csv')\n",
    "at_risk_2015.columns = ['MASKED_STUDENT_ID', '2015_se1_CUM_GPA']\n",
    "normal_2015.columns = ['MASKED_STUDENT_ID', '2015_se1_CUM_GPA']\n",
    "his_2015_se1 = pd.concat([at_risk_2015, normal_2015])\n",
    "\n",
    "his_2015_se1['2015_at_risk_se1'] = his_2015_se1['2015_se1_CUM_GPA'].apply(lambda x: 1 if x < 2.0 else -1).fillna(0)\n",
    "\n",
    "at_risk_2015 = pd.read_csv('Std_list_normal_2015_se2.csv')\n",
    "normal_2015 = pd.read_csv('Std_list_atRist_2015_se2.csv')\n",
    "at_risk_2015.columns = ['MASKED_STUDENT_ID', '2015_se2_CUM_GPA']\n",
    "normal_2015.columns = ['MASKED_STUDENT_ID', '2015_se2_CUM_GPA']\n",
    "his_2015_se2 = pd.concat([at_risk_2015, normal_2015])\n",
    "his_2015_se2['2015_at_risk_se2'] = his_2015_se2['2015_se2_CUM_GPA'].apply(lambda x: 1 if x < 2.0 else -1).fillna(0)\n",
    "\n",
    "his_2015 = pd.merge(his_2015_se1, his_2015_se2, on='MASKED_STUDENT_ID', how='left').fillna(0)\n",
    "his_2015.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MASKED_STUDENT_ID</th>\n",
       "      <th>workday</th>\n",
       "      <th>weekend</th>\n",
       "      <th>morning</th>\n",
       "      <th>afternoon</th>\n",
       "      <th>evening</th>\n",
       "      <th>overnight</th>\n",
       "      <th>workday_ExamMonth</th>\n",
       "      <th>weekend_ExamMonth</th>\n",
       "      <th>morning_ExamMonth</th>\n",
       "      <th>...</th>\n",
       "      <th>forteenth_weekjournal</th>\n",
       "      <th>forteenth_weekemail</th>\n",
       "      <th>forteenth_weekstaff</th>\n",
       "      <th>forteenth_weekannoucements</th>\n",
       "      <th>forteenth_weekcontent</th>\n",
       "      <th>forteenth_weekgrade</th>\n",
       "      <th>2015_se1_CUM_GPA</th>\n",
       "      <th>2015_at_risk_se1</th>\n",
       "      <th>2015_se2_CUM_GPA</th>\n",
       "      <th>2015_at_risk_se2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8TMIKVZ5</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.03</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.99</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N2YYKTMZ</td>\n",
       "      <td>61</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BZRW4GD3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HJTBF62Q</td>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33XUIDIG</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 216 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  MASKED_STUDENT_ID  workday  weekend  morning  afternoon  evening  overnight  \\\n",
       "0          8TMIKVZ5       25        0        0         25        0          0   \n",
       "1          N2YYKTMZ       61        3        1         45       18          0   \n",
       "2          BZRW4GD3        0        1        0          1        0          0   \n",
       "3          HJTBF62Q       14       21        1         26        8          0   \n",
       "4          33XUIDIG       20        5        0         16        9          0   \n",
       "\n",
       "   workday_ExamMonth  weekend_ExamMonth  morning_ExamMonth  ...  \\\n",
       "0                  0                  0                  0  ...   \n",
       "1                  5                  0                  0  ...   \n",
       "2                  0                  1                  0  ...   \n",
       "3                  4                  7                  1  ...   \n",
       "4                  3                  0                  0  ...   \n",
       "\n",
       "   forteenth_weekjournal  forteenth_weekemail  forteenth_weekstaff  \\\n",
       "0                    0.0                  0.0                  0.0   \n",
       "1                    0.0                  0.0                  1.0   \n",
       "2                    0.0                  0.0                  0.0   \n",
       "3                    0.0                  0.0                  0.0   \n",
       "4                    0.0                  0.0                  0.0   \n",
       "\n",
       "   forteenth_weekannoucements  forteenth_weekcontent  forteenth_weekgrade  \\\n",
       "0                         4.0                  187.0                  1.0   \n",
       "1                         2.0                   21.0                  2.0   \n",
       "2                         0.0                    6.0                  2.0   \n",
       "3                         0.0                    0.0                  0.0   \n",
       "4                         0.0                    1.0                  0.0   \n",
       "\n",
       "   2015_se1_CUM_GPA  2015_at_risk_se1  2015_se2_CUM_GPA  2015_at_risk_se2  \n",
       "0              3.03              -1.0              2.99              -1.0  \n",
       "1              0.00               0.0              0.00               0.0  \n",
       "2              0.00               0.0              0.00               0.0  \n",
       "3              0.00               0.0              0.00               0.0  \n",
       "4              0.00               0.0              0.00               0.0  \n",
       "\n",
       "[5 rows x 216 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_se1_stat = pd.merge(df_se1_stat, his_2015, on='MASKED_STUDENT_ID', how='left').fillna(0)\n",
    "df_se1_stat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_time(features, first_weeks):\n",
    "    pre_fix_list = ['first_', 'sencond_', 'third_', 'forth_',\n",
    "                    'fifth_', 'sixth_', 'seventh_', 'eighth_',\n",
    "                    'nineth_', 'tenth_', 'eleventh_', 'twelfth_',\n",
    "                    'thirteenth_', 'fourteenth_']\n",
    "    blacklist = pre_fix_list[first_weeks:]\n",
    "    feature_list = []\n",
    "    for i in features:\n",
    "        flag = 0\n",
    "        for j in blacklist:\n",
    "            if not i.startswith(j):\n",
    "                pass\n",
    "            else:\n",
    "                flag = 1\n",
    "        if flag == 0:\n",
    "            feature_list.append(i)\n",
    "    return feature_list\n",
    "    \n",
    "\n",
    "df_se1_features = df_se1_stat[[i for i in df_se1_stat.columns if i != 'label_atRist' and i != 'MASKED_STUDENT_ID']]\n",
    "df_se1_features = df_se1_features[select_time(list(df_se1_features.columns), first_weeks=12)]\n",
    "df_se1_labels = df_se1_stat['label_atRist']\n",
    "labels = df_se1_labels.apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['workday', 'weekend', 'morning', 'afternoon', 'evening', 'overnight',\n",
       "       'workday_ExamMonth', 'weekend_ExamMonth', 'morning_ExamMonth',\n",
       "       'afternoon_ExamMonth',\n",
       "       ...\n",
       "       'forteenth_weekjournal', 'forteenth_weekemail', 'forteenth_weekstaff',\n",
       "       'forteenth_weekannoucements', 'forteenth_weekcontent',\n",
       "       'forteenth_weekgrade', '2015_se1_CUM_GPA', '2015_at_risk_se1',\n",
       "       '2015_se2_CUM_GPA', '2015_at_risk_se2'],\n",
       "      dtype='object', length=201)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_se1_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the classifier is : gradient_boost\n",
      "0.8400826446280993\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_se1_features, df_se1_labels, test_size=0.2, stratify=df_se1_labels)\n",
    "X_resampled_smote, y_resampled_smote = X_train, y_train\n",
    "# X_resampled_smote, y_resampled_smote = SMOTE(\n",
    "#     random_state=0, sampling_strategy='auto',k_neighbors=10).fit_sample(X_train, y_train)\n",
    "\n",
    "\n",
    "clfs = {\n",
    "        'lr': LogisticRegression(),\\\n",
    "        'svm': svm.SVC(class_weight='balanced'),\\\n",
    "        'decision_tree':tree.DecisionTreeClassifier(),\\\n",
    "        'naive_gaussian': naive_bayes.GaussianNB(), \\\n",
    "        'naive_mul':naive_bayes.MultinomialNB(),\\\n",
    "        'K_neighbor' : neighbors.KNeighborsClassifier(),\\\n",
    "        'bagging_knn' : BaggingClassifier(neighbors.KNeighborsClassifier(), max_samples=0.5,max_features=0.5),\\\n",
    "        'bagging_tree': BaggingClassifier(tree.DecisionTreeClassifier(), max_samples=0.5,max_features=0.5),\\\n",
    "        'random_forest' : RandomForestClassifier(n_estimators=100),\\\n",
    "        'balanced_rf':BalancedRandomForestClassifier(n_estimators=200, criterion = 'gini', max_features = 1.0, random_state=0),\n",
    "        'adaboost':AdaBoostClassifier(n_estimators=50),\\\n",
    "        'gradient_boost' : GradientBoostingClassifier(n_estimators=100, learning_rate=0.1,max_depth=10, random_state=42, min_samples_leaf=1),\n",
    "        'bbc' : BalancedBaggingClassifier(base_estimator=tree.DecisionTreeClassifier(),\n",
    "                                ratio='auto',\n",
    "                                replacement=False,\n",
    "                                random_state=0)\n",
    "\n",
    "}\n",
    "\n",
    "def try_different_method(clf):\n",
    "    # clf.fit(X_train, y_train.ravel())\n",
    "    clf.fit(X_resampled_smote, y_resampled_smote.ravel())\n",
    "    y_predprob = clf.predict_proba(X_test)[:,1]     \n",
    "    return y_predprob\n",
    "\n",
    "# clf_keys  = ['lr', 'svm', 'decision_tree', 'random_forest']\n",
    "clf_keys  = ['gradient_boost']\n",
    "roc_aucs  = []\n",
    "predprobs = []\n",
    "for clf_key in clf_keys:\n",
    "    print('the classifier is :',clf_key)\n",
    "    clf = clfs[clf_key]\n",
    "    y_predprob = try_different_method(clf)\n",
    "    fpr,tpr,threshold = roc_curve(y_test, y_predprob)\n",
    "    roc_auc = auc(fpr,tpr)\n",
    "    roc_aucs.append(roc_auc)\n",
    "    print(roc_auc)\n",
    "    predprobs.append(y_predprob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wenzhy/.conda/envs/py3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the macro F-score is : 0.02392193893610324\n",
      "current j is: 0\n",
      "the macro F-score is : 0.44544161506428254\n",
      "current j is: 0.001\n",
      "the macro F-score is : 0.4984492713265843\n",
      "current j is: 0.002\n",
      "the macro F-score is : 0.5199686511992051\n",
      "current j is: 0.003\n",
      "the macro F-score is : 0.5329130831765798\n",
      "current j is: 0.004\n",
      "the macro F-score is : 0.5423922084194146\n",
      "current j is: 0.005\n",
      "the macro F-score is : 0.5467818396447376\n",
      "current j is: 0.006\n",
      "the macro F-score is : 0.5570616386716412\n",
      "current j is: 0.007\n",
      "the macro F-score is : 0.5601445371016658\n",
      "current j is: 0.008\n",
      "the macro F-score is : 0.5603460498113796\n",
      "current j is: 0.009000000000000001\n",
      "the macro F-score is : 0.5630424980272799\n",
      "current j is: 0.010000000000000002\n",
      "the macro F-score is : 0.571863030217052\n",
      "current j is: 0.011000000000000003\n",
      "the macro F-score is : 0.5776318735603088\n",
      "current j is: 0.012000000000000004\n",
      "the macro F-score is : 0.5828983859337734\n",
      "current j is: 0.013000000000000005\n",
      "the macro F-score is : 0.5869809926445315\n",
      "current j is: 0.014000000000000005\n",
      "the macro F-score is : 0.5874849958545247\n",
      "current j is: 0.017000000000000008\n",
      "the macro F-score is : 0.5932871105008517\n",
      "current j is: 0.01800000000000001\n",
      "the macro F-score is : 0.5963715831772648\n",
      "current j is: 0.01900000000000001\n"
     ]
    }
   ],
   "source": [
    "predprob = predprobs[0]\n",
    "j = 0\n",
    "best_f1 = 0\n",
    "while j < 1:\n",
    "    predictions = np.array([1 if i > j else 0 for i in predprob])\n",
    "    score = f1_score(y_test, predictions, average='macro')\n",
    "    if best_f1 < score:\n",
    "        print('the macro F-score is :', score)\n",
    "        print('current j is:', j)\n",
    "        best_f1 = score\n",
    "    j += 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of predictions: 392\n",
      "Sum of Y test: 76\n",
      "the at-risk recall is : 0.47368421052631576\n",
      "the normal recall is : 0.8823140495867768\n",
      "the macro F-score is : 0.5423922084194146\n",
      "the micro F-score is : 0.872299258303773\n",
      "the weighted F-score is : 0.9118931161706387\n",
      "the binary F-score is : 0.15384615384615385\n",
      "precision score is: 0.5385355692664663\n",
      "*****************************\n"
     ]
    }
   ],
   "source": [
    "j = 0.005\n",
    "predictions = np.array([1 if i > j else 0 for i in predprob])\n",
    "print('Sum of predictions:', predictions.sum())\n",
    "print('Sum of Y test:', y_test.sum())\n",
    "pos_recall = recall_score(y_test, predictions, pos_label=1)\n",
    "print('the at-risk recall is :', pos_recall)\n",
    "neg_recall = recall_score(y_test, predictions, pos_label=0)\n",
    "print('the normal recall is :', neg_recall)\n",
    "score = f1_score(y_test, predictions, average='macro')\n",
    "print('the macro F-score is :', score)\n",
    "score = f1_score(y_test, predictions, average='micro')\n",
    "print('the micro F-score is :', score)\n",
    "score = f1_score(y_test, predictions, average='weighted')\n",
    "print('the weighted F-score is :', score)\n",
    "score = f1_score(y_test, predictions, average='binary')\n",
    "print('the binary F-score is :', score)\n",
    "score = precision_score(y_test, predictions , average='macro')\n",
    "print('precision score is:', score)\n",
    "print('*****************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MASKED_STUDENT_ID</th>\n",
       "      <th>reg_7_COURSE_ACCESS</th>\n",
       "      <th>reg_7_PAGE_ACCESS</th>\n",
       "      <th>reg_7_LOGIN_ATTEMPT</th>\n",
       "      <th>reg_7_SESSION_TIMEOUT</th>\n",
       "      <th>reg_7_LIB</th>\n",
       "      <th>reg_7_COURSE_ACCESS_0</th>\n",
       "      <th>reg_7_COURSE_ACCESS_1</th>\n",
       "      <th>reg_7_COURSE_ACCESS_2</th>\n",
       "      <th>reg_7_COURSE_ACCESS_3</th>\n",
       "      <th>...</th>\n",
       "      <th>reg_7_LIB_237</th>\n",
       "      <th>reg_7_LIB_238</th>\n",
       "      <th>reg_7_LIB_239</th>\n",
       "      <th>reg_7_LIB_240</th>\n",
       "      <th>reg_7_LIB_241</th>\n",
       "      <th>reg_7_LIB_242</th>\n",
       "      <th>reg_7_LIB_243</th>\n",
       "      <th>reg_7_LIB_244</th>\n",
       "      <th>reg_7_LIB_245</th>\n",
       "      <th>reg_7_LIB_246</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8TMIKVZ5</td>\n",
       "      <td>[87.0, 6.0, 9.0, 72.0, 2.0, 0.0, 8.0, 0.0, 5.0...</td>\n",
       "      <td>[88.0, 6.0, 8.0, 74.0, 2.0, 0.0, 8.0, 0.0, 3.0...</td>\n",
       "      <td>[88.0, 6.0, 8.0, 74.0, 2.0, 0.0, 8.0, 0.0, 3.0...</td>\n",
       "      <td>[84.0, 6.0, 10.0, 68.0, 3.0, 2.0, 4.0, 0.0, 10...</td>\n",
       "      <td>[18.0, 6.0, 8.0, 4.0, 5.0, 5.0, 0.0, 4.0, 2.0,...</td>\n",
       "      <td>87.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OZ6FIGHH</td>\n",
       "      <td>[35.0, 10.0, 9.0, 16.0, 5.0, 4.0, 6.0, 4.0, 0....</td>\n",
       "      <td>[34.0, 10.0, 10.0, 14.0, 5.0, 4.0, 8.0, 4.0, 0...</td>\n",
       "      <td>[35.0, 10.0, 9.0, 16.0, 5.0, 4.0, 6.0, 4.0, 0....</td>\n",
       "      <td>[34.0, 9.0, 9.0, 16.0, 5.0, 5.0, 6.0, 4.0, 0.0...</td>\n",
       "      <td>[36.0, 7.0, 7.0, 22.0, 4.0, 4.0, 10.0, 3.0, 0....</td>\n",
       "      <td>35.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QSGBC7CZ</td>\n",
       "      <td>[87.0, 9.0, 10.0, 68.0, 0.0, 0.0, 4.0, 2.0, 15...</td>\n",
       "      <td>[91.0, 10.0, 11.0, 70.0, 0.0, 2.0, 2.0, 0.0, 1...</td>\n",
       "      <td>[91.0, 10.0, 11.0, 70.0, 0.0, 2.0, 2.0, 0.0, 1...</td>\n",
       "      <td>[92.0, 12.0, 8.0, 72.0, 0.0, 2.0, 6.0, 0.0, 10...</td>\n",
       "      <td>[22.0, 8.0, 8.0, 6.0, 4.0, 3.0, 6.0, 3.0, 0.0,...</td>\n",
       "      <td>87.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EIC4AO9Q</td>\n",
       "      <td>[73.0, 17.0, 14.0, 42.0, 3.0, 0.0, 16.0, 0.0, ...</td>\n",
       "      <td>[73.0, 17.0, 14.0, 42.0, 4.0, 0.0, 14.0, 3.0, ...</td>\n",
       "      <td>[75.0, 16.0, 15.0, 44.0, 4.0, 0.0, 14.0, 2.0, ...</td>\n",
       "      <td>[71.0, 15.0, 16.0, 40.0, 4.0, 4.0, 16.0, 0.0, ...</td>\n",
       "      <td>[42.0, 11.0, 13.0, 18.0, 7.0, 4.0, 8.0, 5.0, 6...</td>\n",
       "      <td>73.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S9BIH11O</td>\n",
       "      <td>[102.0, 3.0, 5.0, 94.0, 2.0, 0.0, 2.0, 0.0, 4....</td>\n",
       "      <td>[107.0, 7.0, 4.0, 96.0, 0.0, 0.0, 2.0, 0.0, 8....</td>\n",
       "      <td>[107.0, 7.0, 4.0, 96.0, 0.0, 0.0, 2.0, 0.0, 8....</td>\n",
       "      <td>[103.0, 9.0, 4.0, 90.0, 2.0, 0.0, 6.0, 0.0, 9....</td>\n",
       "      <td>[106.0, 8.0, 6.0, 92.0, 2.0, 0.0, 8.0, 0.0, 2....</td>\n",
       "      <td>102.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1241 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  MASKED_STUDENT_ID                                reg_7_COURSE_ACCESS  \\\n",
       "0          8TMIKVZ5  [87.0, 6.0, 9.0, 72.0, 2.0, 0.0, 8.0, 0.0, 5.0...   \n",
       "1          OZ6FIGHH  [35.0, 10.0, 9.0, 16.0, 5.0, 4.0, 6.0, 4.0, 0....   \n",
       "2          QSGBC7CZ  [87.0, 9.0, 10.0, 68.0, 0.0, 0.0, 4.0, 2.0, 15...   \n",
       "3          EIC4AO9Q  [73.0, 17.0, 14.0, 42.0, 3.0, 0.0, 16.0, 0.0, ...   \n",
       "4          S9BIH11O  [102.0, 3.0, 5.0, 94.0, 2.0, 0.0, 2.0, 0.0, 4....   \n",
       "\n",
       "                                   reg_7_PAGE_ACCESS  \\\n",
       "0  [88.0, 6.0, 8.0, 74.0, 2.0, 0.0, 8.0, 0.0, 3.0...   \n",
       "1  [34.0, 10.0, 10.0, 14.0, 5.0, 4.0, 8.0, 4.0, 0...   \n",
       "2  [91.0, 10.0, 11.0, 70.0, 0.0, 2.0, 2.0, 0.0, 1...   \n",
       "3  [73.0, 17.0, 14.0, 42.0, 4.0, 0.0, 14.0, 3.0, ...   \n",
       "4  [107.0, 7.0, 4.0, 96.0, 0.0, 0.0, 2.0, 0.0, 8....   \n",
       "\n",
       "                                 reg_7_LOGIN_ATTEMPT  \\\n",
       "0  [88.0, 6.0, 8.0, 74.0, 2.0, 0.0, 8.0, 0.0, 3.0...   \n",
       "1  [35.0, 10.0, 9.0, 16.0, 5.0, 4.0, 6.0, 4.0, 0....   \n",
       "2  [91.0, 10.0, 11.0, 70.0, 0.0, 2.0, 2.0, 0.0, 1...   \n",
       "3  [75.0, 16.0, 15.0, 44.0, 4.0, 0.0, 14.0, 2.0, ...   \n",
       "4  [107.0, 7.0, 4.0, 96.0, 0.0, 0.0, 2.0, 0.0, 8....   \n",
       "\n",
       "                               reg_7_SESSION_TIMEOUT  \\\n",
       "0  [84.0, 6.0, 10.0, 68.0, 3.0, 2.0, 4.0, 0.0, 10...   \n",
       "1  [34.0, 9.0, 9.0, 16.0, 5.0, 5.0, 6.0, 4.0, 0.0...   \n",
       "2  [92.0, 12.0, 8.0, 72.0, 0.0, 2.0, 6.0, 0.0, 10...   \n",
       "3  [71.0, 15.0, 16.0, 40.0, 4.0, 4.0, 16.0, 0.0, ...   \n",
       "4  [103.0, 9.0, 4.0, 90.0, 2.0, 0.0, 6.0, 0.0, 9....   \n",
       "\n",
       "                                           reg_7_LIB  reg_7_COURSE_ACCESS_0  \\\n",
       "0  [18.0, 6.0, 8.0, 4.0, 5.0, 5.0, 0.0, 4.0, 2.0,...                   87.0   \n",
       "1  [36.0, 7.0, 7.0, 22.0, 4.0, 4.0, 10.0, 3.0, 0....                   35.0   \n",
       "2  [22.0, 8.0, 8.0, 6.0, 4.0, 3.0, 6.0, 3.0, 0.0,...                   87.0   \n",
       "3  [42.0, 11.0, 13.0, 18.0, 7.0, 4.0, 8.0, 5.0, 6...                   73.0   \n",
       "4  [106.0, 8.0, 6.0, 92.0, 2.0, 0.0, 8.0, 0.0, 2....                  102.0   \n",
       "\n",
       "   reg_7_COURSE_ACCESS_1  reg_7_COURSE_ACCESS_2  reg_7_COURSE_ACCESS_3  ...  \\\n",
       "0                    6.0                    9.0                   72.0  ...   \n",
       "1                   10.0                    9.0                   16.0  ...   \n",
       "2                    9.0                   10.0                   68.0  ...   \n",
       "3                   17.0                   14.0                   42.0  ...   \n",
       "4                    3.0                    5.0                   94.0  ...   \n",
       "\n",
       "   reg_7_LIB_237  reg_7_LIB_238  reg_7_LIB_239  reg_7_LIB_240  reg_7_LIB_241  \\\n",
       "0            0.0            0.0            0.0            0.0            0.0   \n",
       "1            0.0            0.0            0.0            0.0            0.0   \n",
       "2            0.0            0.0            0.0            0.0            0.0   \n",
       "3            0.0            0.0            0.0            0.0            0.0   \n",
       "4            0.0           18.0            0.0            0.0            0.0   \n",
       "\n",
       "   reg_7_LIB_242  reg_7_LIB_243  reg_7_LIB_244  reg_7_LIB_245  reg_7_LIB_246  \n",
       "0            0.0            0.0            0.0            0.0            0.0  \n",
       "1            6.0            0.0            0.0            0.0            0.0  \n",
       "2            0.0            0.0            0.0            0.0            0.0  \n",
       "3            0.0            0.0            0.0            0.0            0.0  \n",
       "4            0.0            0.0            0.0            0.0           56.0  \n",
       "\n",
       "[5 rows x 1241 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## add regularity\n",
    "\n",
    "df_se1_reg = pd.read_csv('Se1_seq_feature.csv', index_col=0)\n",
    "def str_to_list(s1):\n",
    "    try:\n",
    "        return [float(i) for i in s1[1:-1].split(',')]\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "for col in df_se1_reg.columns:\n",
    "    if col.startswith('reg_'):\n",
    "        df_se1_reg[col] = df_se1_reg[col].apply(str_to_list)\n",
    "\n",
    "df_se1_reg = df_se1_reg[[i for i in df_se1_reg.columns if i.startswith('reg_') or i == 'MASKED_STUDENT_ID']]\n",
    "\n",
    "def select(x, i):\n",
    "    try:\n",
    "        return x[i]\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "for col in df_se1_reg.columns:\n",
    "    if col.startswith('reg_'):\n",
    "        for i in range(len(df_se1_reg[col][0])):\n",
    "            df_se1_reg[col + '_' + str(i)] = df_se1_reg[col].apply(lambda x: select(x, i))\n",
    "\n",
    "df_se1_reg.head()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklist = ['reg_7_COURSE_ACCESS', 'reg_7_PAGE_ACCESS', 'reg_7_LOGIN_ATTEMPT', 'reg_7_SESSION_TIMEOUT', 'reg_7_LIB']\n",
    "df_se1_reg = df_se1_reg[[i for i in df_se1_reg if i not in blacklist]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_se1_stat_reg = pd.merge(df_se1_stat, df_se1_reg, on='MASKED_STUDENT_ID', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_time(features, first_weeks):\n",
    "    pre_fix_list = ['first_', 'sencond_', 'third_', 'forth_',\n",
    "                    'fifth_', 'sixth_', 'seventh_', 'eighth_',\n",
    "                    'nineth_', 'tenth_', 'eleventh_', 'twelfth_',\n",
    "                    'thirteenth_', 'fourteenth_']\n",
    "    blacklist = pre_fix_list[first_weeks:]\n",
    "    feature_list = []\n",
    "    for i in features:\n",
    "        flag = 0\n",
    "        for j in blacklist:\n",
    "            if not i.startswith(j):\n",
    "                pass\n",
    "            else:\n",
    "                flag = 1\n",
    "        if flag == 0:\n",
    "            feature_list.append(i)\n",
    "    return feature_list\n",
    "    \n",
    "\n",
    "df_se1_features = df_se1_stat_reg[[i for i in df_se1_stat_reg.columns if i != 'label_atRist' and i != 'MASKED_STUDENT_ID']]\n",
    "df_se1_features = df_se1_features[select_time(list(df_se1_features.columns), first_weeks=12)]\n",
    "df_se1_labels = df_se1_stat_reg['label_atRist']\n",
    "labels = df_se1_labels.apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the classifier is : gradient_boost\n",
      "(22590, 1436)\n",
      "(22590, 77)\n",
      "(2901, 1436)\n",
      "[[ 3.         3.         0.        ...  2.         0.         0.       ]\n",
      " [ 0.         0.        13.        ...  0.         0.         0.       ]\n",
      " [ 0.         0.         2.        ...  0.         0.         0.       ]\n",
      " ...\n",
      " [ 0.         0.         0.3895849 ...  2.3895849  0.         0.       ]\n",
      " [ 1.1006904  0.         0.        ...  0.         0.         0.       ]\n",
      " [ 0.         0.         0.        ...  0.         0.         0.       ]]\n",
      "[[51.  4.  6. ...  0.  0.  0.]\n",
      " [ 5.  0.  0. ...  0.  0.  0.]\n",
      " [16.  0.  2. ...  0.  0.  0.]\n",
      " ...\n",
      " [45.  0.  5. ...  0.  0.  0.]\n",
      " [22.  0.  9. ...  0.  0.  0.]\n",
      " [94.  7. 31. ...  0.  0.  7.]]\n",
      "0.8593619003260362\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_se1_features, df_se1_labels, test_size=0.2, stratify=df_se1_labels)\n",
    "# X_resampled_smote, y_resampled_smote = X_train, y_train\n",
    "\n",
    "X_resampled_smote, y_resampled_smote = SMOTE(\n",
    "     random_state=0, sampling_strategy='auto',k_neighbors=10).fit_sample(X_train, y_train)\n",
    "\n",
    "clfs = {\n",
    "        'lr': LogisticRegression(),\\\n",
    "        'svm': svm.SVC(class_weight='balanced'),\\\n",
    "        'decision_tree':tree.DecisionTreeClassifier(),\\\n",
    "        'naive_gaussian': naive_bayes.GaussianNB(), \\\n",
    "        'naive_mul':naive_bayes.MultinomialNB(),\\\n",
    "        'K_neighbor' : neighbors.KNeighborsClassifier(),\\\n",
    "        'bagging_knn' : BaggingClassifier(neighbors.KNeighborsClassifier(), max_samples=0.5,max_features=0.5),\\\n",
    "        'bagging_tree': BaggingClassifier(tree.DecisionTreeClassifier(), max_samples=0.5,max_features=0.5),\\\n",
    "        'random_forest' : RandomForestClassifier(n_estimators=100),\\\n",
    "        'balanced_rf':BalancedRandomForestClassifier(n_estimators=200, criterion = 'gini', max_features = 1.0, random_state=0),\n",
    "        'adaboost':AdaBoostClassifier(n_estimators=50),\\\n",
    "        'gradient_boost' : GradientBoostingClassifier(n_estimators=100, learning_rate=0.1,max_depth=10, random_state=42, min_samples_leaf=1),\n",
    "        'bbc' : BalancedBaggingClassifier(base_estimator=tree.DecisionTreeClassifier(),\n",
    "                                ratio='auto',\n",
    "                                replacement=False,\n",
    "                                random_state=0)\n",
    "\n",
    "}\n",
    "\n",
    "def try_different_method(clf, X_test):\n",
    "    # clf.fit(X_train, y_train.ravel())\n",
    "#     start = time.now()\n",
    "    print(X_resampled_smote.shape)\n",
    "    clf.fit(X_resampled_smote, y_resampled_smote.ravel())\n",
    "    X_train = X_resampled_smote[:, clf.feature_importances_>0.001]\n",
    "    print(X_train.shape)\n",
    "    print(X_test.shape)\n",
    "    print(X_train)\n",
    "    print(X_test.values)\n",
    "    X_test  = X_test.values[:, clf.feature_importances_>0.001]\n",
    "    clf.fit(X_train, y_resampled_smote.ravel())\n",
    "    y_predprob = clf.predict_proba(X_test)[:,1]     \n",
    "    return y_predprob\n",
    "\n",
    "# clf_keys  = ['lr', 'svm', 'decision_tree', 'random_forest']\n",
    "clf_keys  = ['gradient_boost']\n",
    "roc_aucs  = []\n",
    "predprobs = []\n",
    "for clf_key in clf_keys:\n",
    "    print('the classifier is :',clf_key)\n",
    "    clf = clfs[clf_key]\n",
    "    y_predprob = try_different_method(clf, X_test)\n",
    "    fpr,tpr,threshold = roc_curve(y_test, y_predprob)\n",
    "    roc_auc = auc(fpr,tpr)\n",
    "    roc_aucs.append(roc_auc)\n",
    "    print(roc_auc)\n",
    "    predprobs.append(y_predprob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wenzhy/.conda/envs/py3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the macro F-score is : 0.025529056096741685\n",
      "current j is: 0\n",
      "the macro F-score is : 0.49183027145689984\n",
      "current j is: 0.001\n",
      "the macro F-score is : 0.5189871101262369\n",
      "current j is: 0.002\n",
      "the macro F-score is : 0.5339652952118319\n",
      "current j is: 0.003\n",
      "the macro F-score is : 0.54161926431551\n",
      "current j is: 0.004\n",
      "the macro F-score is : 0.5517212215822078\n",
      "current j is: 0.005\n",
      "the macro F-score is : 0.5579476685968044\n",
      "current j is: 0.006\n",
      "the macro F-score is : 0.5589844937671025\n",
      "current j is: 0.009000000000000001\n",
      "the macro F-score is : 0.5625094254260293\n",
      "current j is: 0.010000000000000002\n",
      "the macro F-score is : 0.5629601551223922\n",
      "current j is: 0.011000000000000003\n",
      "the macro F-score is : 0.5644866388524157\n",
      "current j is: 0.012000000000000004\n",
      "the macro F-score is : 0.5649109124722539\n",
      "current j is: 0.013000000000000005\n",
      "the macro F-score is : 0.5660802492772491\n",
      "current j is: 0.014000000000000005\n",
      "the macro F-score is : 0.5692908381477295\n",
      "current j is: 0.017000000000000008\n",
      "the macro F-score is : 0.5701044426174599\n",
      "current j is: 0.01900000000000001\n",
      "the macro F-score is : 0.57184691750237\n",
      "current j is: 0.02000000000000001\n",
      "the macro F-score is : 0.5763898633589216\n",
      "current j is: 0.02100000000000001\n",
      "the macro F-score is : 0.5778083573487032\n",
      "current j is: 0.022000000000000013\n",
      "the macro F-score is : 0.5807284139241029\n",
      "current j is: 0.023000000000000013\n",
      "the macro F-score is : 0.5822320681748484\n",
      "current j is: 0.024000000000000014\n",
      "the macro F-score is : 0.5832514138167826\n",
      "current j is: 0.025000000000000015\n",
      "the macro F-score is : 0.5842350412038696\n",
      "current j is: 0.03000000000000002\n",
      "the macro F-score is : 0.5853372019662996\n",
      "current j is: 0.03200000000000002\n",
      "the macro F-score is : 0.5864562199148665\n",
      "current j is: 0.03300000000000002\n"
     ]
    }
   ],
   "source": [
    "predprob = predprobs[0]\n",
    "j = 0\n",
    "best_f1 = 0\n",
    "while j < 1:\n",
    "    predictions = np.array([1 if i > j else 0 for i in predprob])\n",
    "    score = f1_score(y_test, predictions, average='macro')\n",
    "    if best_f1 < score:\n",
    "        print('the macro F-score is :', score)\n",
    "        print('current j is:', j)\n",
    "        best_f1 = score\n",
    "    j += 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of predictions: 399\n",
      "Sum of Y test: 76\n",
      "the at-risk recall is : 0.5526315789473685\n",
      "the macro F-score is : 0.5517212215822078\n",
      "the micro F-score is : 0.865218890037918\n",
      "precision score is: 0.5458370145988473\n",
      "*****************************\n"
     ]
    }
   ],
   "source": [
    "j = 0.0050\n",
    "predictions = np.array([1 if i > j else 0 for i in predprob])\n",
    "print('Sum of predictions:', predictions.sum())\n",
    "print('Sum of Y test:', y_test.sum())\n",
    "pos_recall = recall_score(y_test, predictions, pos_label=1)\n",
    "print('the at-risk recall is :', pos_recall)\n",
    "# neg_recall = recall_score(y_test, predictions, pos_label=0)\n",
    "# print('the normal recall is :', neg_recall)\n",
    "score = f1_score(y_test, predictions, average='macro')\n",
    "print('the macro F-score is :', score)\n",
    "score = f1_score(y_test, predictions, average='micro')\n",
    "print('the micro F-score is :', score)\n",
    "# score = f1_score(y_test, predictions, average='weighted')\n",
    "# print('the weighted F-score is :', score)\n",
    "# score = f1_score(y_test, predictions, average='binary')\n",
    "# print('the binary F-score is :', score)\n",
    "score = precision_score(y_test, predictions , average='macro')\n",
    "print('precision score is:', score)\n",
    "print('*****************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15503, 769)\n"
     ]
    }
   ],
   "source": [
    "## add social homophily\n",
    "\n",
    "df_se1_soho = pd.read_csv('se1_weekly_node_embeddings.csv', index_col = 0)\n",
    "df_se1_soho = df_se1_soho[[i for i in df_se1_soho.columns if i != 'label_atRist']]\n",
    "# df_se1_soho.head()\n",
    "\n",
    "def str_to_list(s1):\n",
    "    try:\n",
    "        return [float(i) for i in s1[1:-1].split()]\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "for col in df_se1_soho.columns:\n",
    "    if col !='MASKED_STUDENT_ID':\n",
    "        df_se1_soho[col] = df_se1_soho[col].apply(str_to_list)\n",
    "\n",
    "        \n",
    "for col in df_se1_soho.columns:\n",
    "    if col.startswith('week_'):\n",
    "        for i in range(64):\n",
    "            df_se1_soho[col + '_' + str(i)] = df_se1_soho[col].apply(lambda x: select(x, i))\n",
    "\n",
    "blacklist = ['week_1', 'week_2', 'week_3', 'week_4', 'week_5', 'week_6', 'week_7', 'week_8', 'week_9', 'week_10', 'week_11', 'week_12']\n",
    "df_se1_soho = df_se1_soho[[i for i in df_se1_soho.columns if i not in blacklist]]\n",
    "print(df_se1_soho.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14501, 2219)\n"
     ]
    }
   ],
   "source": [
    "df_se1_stat_reg_soho = pd.merge(df_se1_stat_reg, df_se1_soho, on='MASKED_STUDENT_ID', how='left').fillna(0)\n",
    "print(df_se1_stat_reg_soho.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_time(features, first_weeks):\n",
    "    pre_fix_list = ['first_', 'sencond_', 'third_', 'forth_',\n",
    "                    'fifth_', 'sixth_', 'seventh_', 'eighth_',\n",
    "                    'nineth_', 'tenth_', 'eleventh_', 'twelfth_',\n",
    "                    'thirteenth_', 'fourteenth_']\n",
    "    blacklist = pre_fix_list[first_weeks:]\n",
    "    feature_list = []\n",
    "    for i in features:\n",
    "        flag = 0\n",
    "        for j in blacklist:\n",
    "            if not i.startswith(j):\n",
    "                pass\n",
    "            else:\n",
    "                flag = 1\n",
    "        if flag == 0:\n",
    "            feature_list.append(i)\n",
    "    return feature_list\n",
    "    \n",
    "\n",
    "df_se1_features = df_se1_stat_reg_soho[[i for i in df_se1_stat_reg_soho.columns if i != 'label_atRist' and i != 'MASKED_STUDENT_ID']]\n",
    "df_se1_features = df_se1_features[select_time(list(df_se1_features.columns), first_weeks=12)]\n",
    "df_se1_labels = df_se1_stat_reg_soho['label_atRist']\n",
    "labels = df_se1_labels.apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    0.0\n",
       "2    0.0\n",
       "3    0.0\n",
       "4    0.0\n",
       "Name: label_atRist, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_se1_labels.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the classifier is : svm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wenzhy/.conda/envs/py3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-177-5d35b784b8d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'the classifier is :'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclf_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclf_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0my_predprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtry_different_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mroc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-177-5d35b784b8d8>\u001b[0m in \u001b[0;36mtry_different_method\u001b[0;34m(clf, X_test, y_test)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtry_different_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# clf.fit(X_train, y_train.ravel())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_resampled_smote\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_resampled_smote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;31m#     X_train = X_resampled_smote# [:, clf.feature_importances_]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m#     print(X_train.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py3/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py3/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_se1_features, df_se1_labels, test_size=0.2, stratify=df_se1_labels)\n",
    "# X_resampled_smote, y_resampled_smote = X_train, y_train\n",
    "X_resampled_smote, y_resampled_smote = SMOTE(\n",
    "    random_state=0, sampling_strategy='auto',k_neighbors=10).fit_sample(X_train, y_train)\n",
    "\n",
    "\n",
    "clfs = {\n",
    "        'lr': LogisticRegression(),\\\n",
    "        'svm': svm.SVC(class_weight='balanced'),\\\n",
    "        'decision_tree':tree.DecisionTreeClassifier(),\\\n",
    "        'naive_gaussian': naive_bayes.GaussianNB(), \\\n",
    "        'naive_mul':naive_bayes.MultinomialNB(),\\\n",
    "        'K_neighbor' : neighbors.KNeighborsClassifier(),\\\n",
    "        'bagging_knn' : BaggingClassifier(neighbors.KNeighborsClassifier(), max_samples=0.5,max_features=0.5),\\\n",
    "        'bagging_tree': BaggingClassifier(tree.DecisionTreeClassifier(), max_samples=0.5,max_features=0.5),\\\n",
    "        'random_forest' : RandomForestClassifier(n_estimators=100),\\\n",
    "        'balanced_rf':BalancedRandomForestClassifier(n_estimators=200, criterion = 'gini', max_features = 1.0, random_state=0),\n",
    "        'adaboost':AdaBoostClassifier(n_estimators=50),\\\n",
    "        'gradient_boost' : GradientBoostingClassifier(n_estimators=100, learning_rate=0.1,max_depth=10, random_state=42, min_samples_leaf=1),\n",
    "        'bbc' : BalancedBaggingClassifier(base_estimator=tree.DecisionTreeClassifier(),\n",
    "                                ratio='auto',\n",
    "                                replacement=False,\n",
    "                                random_state=0)\n",
    "\n",
    "}\n",
    "\n",
    "def try_different_method(clf, X_test, y_test):\n",
    "    # clf.fit(X_train, y_train.ravel())\n",
    "    clf.fit(X_resampled_smote, y_resampled_smote.ravel())\n",
    "#     X_train = X_resampled_smote# [:, clf.feature_importances_]\n",
    "#     print(X_train.shape)\n",
    "#     print(X_test.shape)\n",
    "#     print(X_train)\n",
    "#     print(X_test.values)\n",
    "#     X_test  = X_test.values# [:, clf.feature_importances_]\n",
    "#     clf.fit(X_train, y_resampled_smote.ravel())\n",
    "    clf.fit(X_test, y_test)\n",
    "    y_predprob = clf.predict_proba(X_test)[:,1]     \n",
    "    return y_predprob\n",
    "\n",
    "# clf_keys  = ['lr', 'svm', 'decision_tree', 'random_forest']\n",
    "clf_keys  = ['svm']\n",
    "roc_aucs  = []\n",
    "predprobs = []\n",
    "for clf_key in clf_keys:\n",
    "    print('the classifier is :',clf_key)\n",
    "    clf = clfs[clf_key]\n",
    "    y_predprob = try_different_method(clf, X_test, y_test)\n",
    "    fpr,tpr,threshold = roc_curve(y_test, y_predprob)\n",
    "    roc_auc = auc(fpr,tpr)\n",
    "    roc_aucs.append(roc_auc)\n",
    "    print(roc_auc)\n",
    "    predprobs.append(y_predprob)\n",
    "\n",
    "current = time.time()\n",
    "print(current-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wenzhy/.conda/envs/py3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the macro F-score is : 0.025529056096741685\n",
      "current j is: 0\n",
      "the macro F-score is : 0.039869386913045944\n",
      "current j is: 0.001\n",
      "the macro F-score is : 0.04092449637312595\n",
      "current j is: 0.002\n",
      "the macro F-score is : 0.04267835975865173\n",
      "current j is: 0.003\n",
      "the macro F-score is : 0.043727897558749715\n",
      "current j is: 0.004\n",
      "the macro F-score is : 0.04477535854473846\n",
      "current j is: 0.005\n",
      "the macro F-score is : 0.04512405186992782\n",
      "current j is: 0.008\n",
      "the macro F-score is : 0.04547251544611787\n",
      "current j is: 0.009000000000000001\n",
      "the macro F-score is : 0.045820749524453225\n",
      "current j is: 0.011000000000000003\n",
      "the macro F-score is : 0.04616875435574745\n",
      "current j is: 0.012000000000000004\n",
      "the macro F-score is : 0.046516530190483615\n",
      "current j is: 0.01800000000000001\n",
      "the macro F-score is : 0.046864077278814954\n",
      "current j is: 0.022000000000000013\n",
      "the macro F-score is : 0.04721139587056543\n",
      "current j is: 0.026000000000000016\n",
      "the macro F-score is : 0.04755848621523032\n",
      "current j is: 0.02900000000000002\n",
      "the macro F-score is : 0.04790534856197687\n",
      "current j is: 0.03200000000000002\n",
      "the macro F-score is : 0.0485983902567471\n",
      "current j is: 0.035000000000000024\n",
      "the macro F-score is : 0.04894457010147028\n",
      "current j is: 0.04300000000000003\n",
      "the macro F-score is : 0.049290522941675255\n",
      "current j is: 0.047000000000000035\n",
      "the macro F-score is : 0.049636249024897855\n",
      "current j is: 0.04900000000000004\n",
      "the macro F-score is : 0.04998174859834939\n",
      "current j is: 0.05400000000000004\n",
      "the macro F-score is : 0.05032702190891725\n",
      "current j is: 0.05600000000000004\n",
      "the macro F-score is : 0.05067206920316547\n",
      "current j is: 0.06300000000000004\n",
      "the macro F-score is : 0.05101689072733541\n",
      "current j is: 0.06600000000000004\n",
      "the macro F-score is : 0.05136148672734618\n",
      "current j is: 0.06700000000000005\n",
      "the macro F-score is : 0.052050003136959656\n",
      "current j is: 0.06800000000000005\n",
      "the macro F-score is : 0.052393924036795145\n",
      "current j is: 0.06900000000000005\n",
      "the macro F-score is : 0.052737620392938216\n",
      "current j is: 0.07100000000000005\n",
      "the macro F-score is : 0.053081092449706005\n",
      "current j is: 0.07200000000000005\n",
      "the macro F-score is : 0.053424340451096945\n",
      "current j is: 0.07700000000000005\n",
      "the macro F-score is : 0.05376736464079142\n",
      "current j is: 0.07800000000000006\n",
      "the macro F-score is : 0.05411016526215226\n",
      "current j is: 0.08300000000000006\n",
      "the macro F-score is : 0.054452742558225395\n",
      "current j is: 0.08500000000000006\n",
      "the macro F-score is : 0.05479509677174037\n",
      "current j is: 0.08800000000000006\n",
      "the macro F-score is : 0.05513722814511096\n",
      "current j is: 0.09100000000000007\n",
      "the macro F-score is : 0.055479136920435684\n",
      "current j is: 0.09300000000000007\n",
      "the macro F-score is : 0.05616228764376912\n",
      "current j is: 0.09500000000000007\n",
      "the macro F-score is : 0.056844550872246394\n",
      "current j is: 0.10100000000000008\n",
      "the macro F-score is : 0.057525928531366156\n",
      "current j is: 0.10200000000000008\n",
      "the macro F-score is : 0.05786628587277065\n",
      "current j is: 0.10600000000000008\n",
      "the macro F-score is : 0.05820642254163816\n",
      "current j is: 0.10800000000000008\n",
      "the macro F-score is : 0.058546338777255805\n",
      "current j is: 0.11300000000000009\n",
      "the macro F-score is : 0.05888603481860122\n",
      "current j is: 0.11500000000000009\n",
      "the macro F-score is : 0.05922551090434302\n",
      "current j is: 0.11800000000000009\n",
      "the macro F-score is : 0.05956476727284135\n",
      "current j is: 0.11900000000000009\n",
      "the macro F-score is : 0.05990380416214851\n",
      "current j is: 0.1210000000000001\n",
      "the macro F-score is : 0.06024262181000947\n",
      "current j is: 0.1240000000000001\n",
      "the macro F-score is : 0.06058122045386241\n",
      "current j is: 0.12600000000000008\n",
      "the macro F-score is : 0.060919600330839374\n",
      "current j is: 0.1290000000000001\n",
      "the macro F-score is : 0.061257761677766615\n",
      "current j is: 0.1310000000000001\n",
      "the macro F-score is : 0.06159570473116542\n",
      "current j is: 0.1340000000000001\n",
      "the macro F-score is : 0.06227093690194031\n",
      "current j is: 0.1400000000000001\n",
      "the macro F-score is : 0.0626082264908383\n",
      "current j is: 0.1430000000000001\n",
      "the macro F-score is : 0.06292926248616662\n",
      "current j is: 0.1580000000000001\n",
      "the macro F-score is : 0.06326567793593735\n",
      "current j is: 0.17100000000000012\n",
      "the macro F-score is : 0.06360187680942397\n",
      "current j is: 0.17300000000000013\n",
      "the macro F-score is : 0.0642736257624089\n",
      "current j is: 0.18000000000000013\n",
      "the macro F-score is : 0.06460917630859003\n",
      "current j is: 0.18100000000000013\n",
      "the macro F-score is : 0.06494451121185384\n",
      "current j is: 0.18200000000000013\n",
      "the macro F-score is : 0.065279630704795\n",
      "current j is: 0.18600000000000014\n",
      "the macro F-score is : 0.06561453501971054\n",
      "current j is: 0.19000000000000014\n",
      "the macro F-score is : 0.0662836990431673\n",
      "current j is: 0.19200000000000014\n",
      "the macro F-score is : 0.06661795921481876\n",
      "current j is: 0.20000000000000015\n",
      "the macro F-score is : 0.06695200513466612\n",
      "current j is: 0.20400000000000015\n",
      "the macro F-score is : 0.06761945514191985\n",
      "current j is: 0.21300000000000016\n",
      "the macro F-score is : 0.06795285969007607\n",
      "current j is: 0.21600000000000016\n",
      "the macro F-score is : 0.06828605090792908\n",
      "current j is: 0.21700000000000016\n",
      "the macro F-score is : 0.06861902902512039\n",
      "current j is: 0.2410000000000002\n",
      "the macro F-score is : 0.06895179427099925\n",
      "current j is: 0.25100000000000017\n",
      "the macro F-score is : 0.06961668706475753\n",
      "current j is: 0.2600000000000002\n",
      "the macro F-score is : 0.06994881506987809\n",
      "current j is: 0.2720000000000002\n",
      "the macro F-score is : 0.07028073111816954\n",
      "current j is: 0.2740000000000002\n",
      "the macro F-score is : 0.07094392825555629\n",
      "current j is: 0.2770000000000002\n",
      "the macro F-score is : 0.07127520979957458\n",
      "current j is: 0.2790000000000002\n",
      "the macro F-score is : 0.0719371399734061\n",
      "current j is: 0.2850000000000002\n",
      "the macro F-score is : 0.07226778905641464\n",
      "current j is: 0.2870000000000002\n",
      "the macro F-score is : 0.07259822777180377\n",
      "current j is: 0.2970000000000002\n",
      "the macro F-score is : 0.07292845634545478\n",
      "current j is: 0.3010000000000002\n",
      "the macro F-score is : 0.07325847500296331\n",
      "current j is: 0.3030000000000002\n",
      "the macro F-score is : 0.0735882839696399\n",
      "current j is: 0.3170000000000002\n",
      "the macro F-score is : 0.07391788347051048\n",
      "current j is: 0.32100000000000023\n",
      "the macro F-score is : 0.07424727373031689\n",
      "current j is: 0.32200000000000023\n",
      "the macro F-score is : 0.07490542742428725\n",
      "current j is: 0.32300000000000023\n",
      "the macro F-score is : 0.07523419130651907\n",
      "current j is: 0.32400000000000023\n",
      "the macro F-score is : 0.07556274684382348\n",
      "current j is: 0.32600000000000023\n",
      "the macro F-score is : 0.07589109425952956\n",
      "current j is: 0.32800000000000024\n",
      "the macro F-score is : 0.0762192337766853\n",
      "current j is: 0.33200000000000024\n",
      "the macro F-score is : 0.07654716561805824\n",
      "current j is: 0.33400000000000024\n",
      "the macro F-score is : 0.07687489000613587\n",
      "current j is: 0.33700000000000024\n",
      "the macro F-score is : 0.07720240716312612\n",
      "current j is: 0.34600000000000025\n",
      "the macro F-score is : 0.07752971731095795\n",
      "current j is: 0.34700000000000025\n",
      "the macro F-score is : 0.07782041196397321\n",
      "current j is: 0.35700000000000026\n",
      "the macro F-score is : 0.07814688242099495\n",
      "current j is: 0.35800000000000026\n",
      "the macro F-score is : 0.07847314680965059\n",
      "current j is: 0.35900000000000026\n",
      "the macro F-score is : 0.07879920535018539\n",
      "current j is: 0.36000000000000026\n",
      "the macro F-score is : 0.07912505826256887\n",
      "current j is: 0.36200000000000027\n",
      "the macro F-score is : 0.07945070576649524\n",
      "current j is: 0.3700000000000003\n",
      "the macro F-score is : 0.07977614808138395\n",
      "current j is: 0.3740000000000003\n",
      "the macro F-score is : 0.08010138542638018\n",
      "current j is: 0.3770000000000003\n",
      "the macro F-score is : 0.0807512460819074\n",
      "current j is: 0.3780000000000003\n",
      "the macro F-score is : 0.08107586982936173\n",
      "current j is: 0.3810000000000003\n",
      "the macro F-score is : 0.08172450525391702\n",
      "current j is: 0.3830000000000003\n",
      "the macro F-score is : 0.08204851736630889\n",
      "current j is: 0.3850000000000003\n",
      "the macro F-score is : 0.08237232603518571\n",
      "current j is: 0.3940000000000003\n",
      "the macro F-score is : 0.08269593147751605\n",
      "current j is: 0.3990000000000003\n",
      "the macro F-score is : 0.08301933390999858\n",
      "current j is: 0.4020000000000003\n",
      "the macro F-score is : 0.08334253354906253\n",
      "current j is: 0.4060000000000003\n",
      "the macro F-score is : 0.08398832531130757\n",
      "current j is: 0.4070000000000003\n",
      "the macro F-score is : 0.0846333084903155\n",
      "current j is: 0.4080000000000003\n",
      "the macro F-score is : 0.08495549739932999\n",
      "current j is: 0.4100000000000003\n",
      "the macro F-score is : 0.08527748480787095\n",
      "current j is: 0.4120000000000003\n",
      "the macro F-score is : 0.0855992709304953\n",
      "current j is: 0.4140000000000003\n",
      "the macro F-score is : 0.08592085598149435\n",
      "current j is: 0.4150000000000003\n",
      "the macro F-score is : 0.08624224017489437\n",
      "current j is: 0.4160000000000003\n",
      "the macro F-score is : 0.086563423724457\n",
      "current j is: 0.4190000000000003\n",
      "the macro F-score is : 0.08720518974579651\n",
      "current j is: 0.4240000000000003\n",
      "the macro F-score is : 0.08752577264377788\n",
      "current j is: 0.4260000000000003\n",
      "the macro F-score is : 0.08784615575033182\n",
      "current j is: 0.4280000000000003\n",
      "the macro F-score is : 0.08848632343867827\n",
      "current j is: 0.4310000000000003\n",
      "the macro F-score is : 0.08912569450726288\n",
      "current j is: 0.43200000000000033\n",
      "the macro F-score is : 0.08976427064833904\n",
      "current j is: 0.43400000000000033\n",
      "the macro F-score is : 0.09008326114875315\n",
      "current j is: 0.43600000000000033\n",
      "the macro F-score is : 0.09072064806244921\n",
      "current j is: 0.43700000000000033\n",
      "the macro F-score is : 0.09103904489620218\n",
      "current j is: 0.44000000000000034\n",
      "the macro F-score is : 0.09167524636676289\n",
      "current j is: 0.44100000000000034\n",
      "the macro F-score is : 0.09231065963739231\n",
      "current j is: 0.44400000000000034\n",
      "the macro F-score is : 0.09262807122027038\n",
      "current j is: 0.45000000000000034\n",
      "the macro F-score is : 0.09326230532399295\n",
      "current j is: 0.45100000000000035\n",
      "the macro F-score is : 0.09357912826120918\n",
      "current j is: 0.45200000000000035\n",
      "the macro F-score is : 0.09421218694537567\n",
      "current j is: 0.45300000000000035\n",
      "the macro F-score is : 0.09516031010543713\n",
      "current j is: 0.45400000000000035\n",
      "the macro F-score is : 0.09547596135523456\n",
      "current j is: 0.45600000000000035\n",
      "the macro F-score is : 0.09579141804728115\n",
      "current j is: 0.45900000000000035\n",
      "the macro F-score is : 0.09673662283606453\n",
      "current j is: 0.46000000000000035\n",
      "the macro F-score is : 0.0973657903438996\n",
      "current j is: 0.46100000000000035\n",
      "the macro F-score is : 0.0979941845504606\n",
      "current j is: 0.46400000000000036\n",
      "the macro F-score is : 0.09956179759617201\n",
      "current j is: 0.46500000000000036\n",
      "the macro F-score is : 0.10043317055870278\n",
      "current j is: 0.46800000000000036\n",
      "the macro F-score is : 0.10136848926503667\n",
      "current j is: 0.47000000000000036\n",
      "the macro F-score is : 0.10261291551161922\n",
      "current j is: 0.47100000000000036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the macro F-score is : 0.1032339899466456\n",
      "current j is: 0.47300000000000036\n",
      "the macro F-score is : 0.10385430738817658\n",
      "current j is: 0.47500000000000037\n",
      "the macro F-score is : 0.10447386943043681\n",
      "current j is: 0.47600000000000037\n",
      "the macro F-score is : 0.10478336767399268\n",
      "current j is: 0.47700000000000037\n",
      "the macro F-score is : 0.1054017995981813\n",
      "current j is: 0.47800000000000037\n",
      "the macro F-score is : 0.10601948009201\n",
      "current j is: 0.47900000000000037\n",
      "the macro F-score is : 0.1069445953581039\n",
      "current j is: 0.48000000000000037\n",
      "the macro F-score is : 0.10725259310858135\n",
      "current j is: 0.48100000000000037\n",
      "the macro F-score is : 0.10756040418441154\n",
      "current j is: 0.4820000000000004\n",
      "the macro F-score is : 0.10817546709720534\n",
      "current j is: 0.4830000000000004\n",
      "the macro F-score is : 0.10940336144981538\n",
      "current j is: 0.4840000000000004\n",
      "the macro F-score is : 0.11001619601413144\n",
      "current j is: 0.4850000000000004\n",
      "the macro F-score is : 0.11032233582495632\n",
      "current j is: 0.4860000000000004\n",
      "the macro F-score is : 0.11276482059431356\n",
      "current j is: 0.4870000000000004\n",
      "the macro F-score is : 0.11367772467373567\n",
      "current j is: 0.4880000000000004\n",
      "the macro F-score is : 0.11458898534997286\n",
      "current j is: 0.4890000000000004\n",
      "the macro F-score is : 0.11489237460122986\n",
      "current j is: 0.4900000000000004\n",
      "the macro F-score is : 0.11610411515649317\n",
      "current j is: 0.4910000000000004\n",
      "the macro F-score is : 0.11731295851786742\n",
      "current j is: 0.4920000000000004\n",
      "the macro F-score is : 0.11851891680691398\n",
      "current j is: 0.4930000000000004\n",
      "the macro F-score is : 0.12032247110715247\n",
      "current j is: 0.4940000000000004\n",
      "the macro F-score is : 0.1245058524982641\n",
      "current j is: 0.4950000000000004\n",
      "the macro F-score is : 0.12688084927895418\n",
      "current j is: 0.4960000000000004\n",
      "the macro F-score is : 0.1315974543497455\n",
      "current j is: 0.4970000000000004\n",
      "the macro F-score is : 0.13615538590375245\n",
      "current j is: 0.4980000000000004\n",
      "the macro F-score is : 0.14164094494542961\n",
      "current j is: 0.4990000000000004\n",
      "the macro F-score is : 0.44079740092949893\n",
      "current j is: 0.5000000000000003\n",
      "the macro F-score is : 0.4871427249166976\n",
      "current j is: 0.5010000000000003\n",
      "the macro F-score is : 0.4929121081199051\n",
      "current j is: 0.5020000000000003\n",
      "the macro F-score is : 0.4956090436629869\n",
      "current j is: 0.5030000000000003\n",
      "the macro F-score is : 0.49606300532026304\n",
      "current j is: 0.5070000000000003\n",
      "the macro F-score is : 0.4972728931047063\n",
      "current j is: 0.5080000000000003\n",
      "the macro F-score is : 0.49779812450934435\n",
      "current j is: 0.5090000000000003\n",
      "the macro F-score is : 0.49832756123377464\n",
      "current j is: 0.5100000000000003\n",
      "the macro F-score is : 0.4990402462232456\n",
      "current j is: 0.5110000000000003\n",
      "the macro F-score is : 0.4997609669777664\n",
      "current j is: 0.5120000000000003\n",
      "the macro F-score is : 0.500124447167391\n",
      "current j is: 0.5130000000000003\n",
      "the macro F-score is : 0.5003069865087982\n",
      "current j is: 0.5150000000000003\n",
      "the macro F-score is : 0.5004900662251656\n",
      "current j is: 0.5160000000000003\n",
      "the macro F-score is : 0.5014137744382976\n",
      "current j is: 0.5180000000000003\n",
      "the macro F-score is : 0.501600219907521\n",
      "current j is: 0.5190000000000003\n",
      "the macro F-score is : 0.5019748640196819\n",
      "current j is: 0.5200000000000004\n",
      "the macro F-score is : 0.5023518882231559\n",
      "current j is: 0.5210000000000004\n",
      "the macro F-score is : 0.5025413091343087\n",
      "current j is: 0.5220000000000004\n",
      "the macro F-score is : 0.5027313447775387\n",
      "current j is: 0.5230000000000004\n",
      "the macro F-score is : 0.5031132873896748\n",
      "current j is: 0.5240000000000004\n",
      "the macro F-score is : 0.5034977712642688\n",
      "current j is: 0.5250000000000004\n",
      "the macro F-score is : 0.5038848531566347\n",
      "current j is: 0.5260000000000004\n",
      "the macro F-score is : 0.5044704753961097\n",
      "current j is: 0.5280000000000004\n",
      "the macro F-score is : 0.5046670461013091\n",
      "current j is: 0.5290000000000004\n",
      "the macro F-score is : 0.5050622789241452\n",
      "current j is: 0.5300000000000004\n",
      "the macro F-score is : 0.5054603534280634\n",
      "current j is: 0.5310000000000004\n",
      "the macro F-score is : 0.5058613349952993\n",
      "current j is: 0.5320000000000004\n",
      "the macro F-score is : 0.5064684058520209\n",
      "current j is: 0.5330000000000004\n",
      "the macro F-score is : 0.50667229051177\n",
      "current j is: 0.5340000000000004\n",
      "the macro F-score is : 0.5068769538900426\n",
      "current j is: 0.5350000000000004\n",
      "the macro F-score is : 0.5074957082011387\n",
      "current j is: 0.5360000000000004\n",
      "the macro F-score is : 0.5081218075492344\n",
      "current j is: 0.5370000000000004\n",
      "the macro F-score is : 0.5087555173083863\n",
      "current j is: 0.5380000000000004\n",
      "the macro F-score is : 0.5093971152193058\n",
      "current j is: 0.5390000000000004\n",
      "the macro F-score is : 0.5096127839884601\n",
      "current j is: 0.5400000000000004\n",
      "the macro F-score is : 0.5098293725278105\n",
      "current j is: 0.5410000000000004\n",
      "the macro F-score is : 0.5100468921197395\n",
      "current j is: 0.5420000000000004\n",
      "the macro F-score is : 0.5102653542247045\n",
      "current j is: 0.5430000000000004\n",
      "the macro F-score is : 0.5104847704847705\n",
      "current j is: 0.5440000000000004\n",
      "the macro F-score is : 0.5111488634169308\n",
      "current j is: 0.5450000000000004\n",
      "the macro F-score is : 0.5115965847596906\n",
      "current j is: 0.5470000000000004\n",
      "the macro F-score is : 0.5118219810707826\n",
      "current j is: 0.5480000000000004\n",
      "the macro F-score is : 0.512048418431616\n",
      "current j is: 0.5490000000000004\n",
      "the macro F-score is : 0.5127341102324752\n",
      "current j is: 0.5510000000000004\n",
      "the macro F-score is : 0.5129648463178285\n",
      "current j is: 0.5540000000000004\n",
      "the macro F-score is : 0.5131966918374685\n",
      "current j is: 0.5560000000000004\n",
      "the macro F-score is : 0.5136637688864187\n",
      "current j is: 0.5570000000000004\n",
      "the macro F-score is : 0.5141354592349434\n",
      "current j is: 0.5580000000000004\n",
      "the macro F-score is : 0.5143730723220804\n",
      "current j is: 0.5590000000000004\n",
      "the macro F-score is : 0.5146118847627469\n",
      "current j is: 0.5600000000000004\n",
      "the macro F-score is : 0.5148519124491263\n",
      "current j is: 0.5610000000000004\n",
      "the macro F-score is : 0.515093171547081\n",
      "current j is: 0.5630000000000004\n",
      "the macro F-score is : 0.515335678502076\n",
      "current j is: 0.5640000000000004\n",
      "the macro F-score is : 0.5160708552867637\n",
      "current j is: 0.5660000000000004\n",
      "the macro F-score is : 0.5163138390033278\n",
      "current j is: 0.6190000000000004\n",
      "the macro F-score is : 0.5165688826721581\n",
      "current j is: 0.6220000000000004\n",
      "the macro F-score is : 0.516825471730848\n",
      "current j is: 0.6260000000000004\n",
      "the macro F-score is : 0.517343378937856\n",
      "current j is: 0.6380000000000005\n",
      "the macro F-score is : 0.5176047446896305\n",
      "current j is: 0.6390000000000005\n",
      "the macro F-score is : 0.5178677510608203\n",
      "current j is: 0.6410000000000005\n",
      "the macro F-score is : 0.5181324230481231\n",
      "current j is: 0.6460000000000005\n",
      "the macro F-score is : 0.5183987861478043\n",
      "current j is: 0.6470000000000005\n",
      "the macro F-score is : 0.5186668663682503\n",
      "current j is: 0.6480000000000005\n",
      "the macro F-score is : 0.5189366902429001\n",
      "current j is: 0.6500000000000005\n",
      "the macro F-score is : 0.5192082848435725\n",
      "current j is: 0.6560000000000005\n",
      "the macro F-score is : 0.5192316384180791\n",
      "current j is: 0.7480000000000006\n",
      "the macro F-score is : 0.5195157224574217\n",
      "current j is: 0.7490000000000006\n",
      "the macro F-score is : 0.5198019751707329\n",
      "current j is: 0.7510000000000006\n",
      "the macro F-score is : 0.520090434526873\n",
      "current j is: 0.7520000000000006\n",
      "the macro F-score is : 0.5203811393721819\n",
      "current j is: 0.7600000000000006\n",
      "the macro F-score is : 0.5209694454570095\n",
      "current j is: 0.7610000000000006\n",
      "the macro F-score is : 0.5212671290106952\n",
      "current j is: 0.7710000000000006\n",
      "the macro F-score is : 0.5215672227375241\n",
      "current j is: 0.7730000000000006\n"
     ]
    }
   ],
   "source": [
    "predprob = predprobs[0]\n",
    "j = 0\n",
    "best_f1 = 0\n",
    "while j < 1:\n",
    "    predictions = np.array([1 if i > j else 0 for i in predprob])\n",
    "    score = f1_score(y_test, predictions, average='macro')\n",
    "    if best_f1 < score:\n",
    "        print('the macro F-score is :', score)\n",
    "        print('current j is:', j)\n",
    "        best_f1 = score\n",
    "    j += 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of predictions: 169\n",
      "Sum of Y test: 76\n",
      "the at-risk recall is : 0.10526315789473684\n",
      "the macro F-score is : 0.512048418431616\n",
      "the micro F-score is : 0.9210617028610824\n",
      "precision score is: 0.5112235438848796\n",
      "*****************************\n"
     ]
    }
   ],
   "source": [
    "j = 0.55\n",
    "predictions = np.array([1 if i > j else 0 for i in predprob])\n",
    "print('Sum of predictions:', predictions.sum())\n",
    "print('Sum of Y test:', y_test.sum())\n",
    "pos_recall = recall_score(y_test, predictions, pos_label=1)\n",
    "print('the at-risk recall is :', pos_recall)\n",
    "# neg_recall = recall_score(y_test, predictions, pos_label=0)\n",
    "# print('the normal recall is :', neg_recall)\n",
    "score = f1_score(y_test, predictions, average='macro')\n",
    "print('the macro F-score is :', score)\n",
    "score = f1_score(y_test, predictions, average='micro')\n",
    "print('the micro F-score is :', score)\n",
    "# score = f1_score(y_test, predictions, average='weighted')\n",
    "# print('the weighted F-score is :', score)\n",
    "# score = f1_score(y_test, predictions, average='binary')\n",
    "# print('the binary F-score is :', score)\n",
    "score = precision_score(y_test, predictions , average='macro')\n",
    "print('precision score is:', score)\n",
    "print('*****************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 213, (0.419514)\n",
      "2. feature 85, (0.099103)\n",
      "3. feature 212, (0.098023)\n",
      "4. feature 59, (0.043691)\n",
      "5. feature 207, (0.031869)\n",
      "6. feature 107, (0.030353)\n",
      "7. feature 102, (0.026030)\n",
      "8. feature 82, (0.024212)\n",
      "9. feature 5, (0.014468)\n",
      "10. feature 146, (0.007955)\n",
      "11. feature 167, (0.007539)\n",
      "12. feature 76, (0.006669)\n",
      "13. feature 90, (0.006603)\n",
      "14. feature 17, (0.005276)\n",
      "15. feature 121, (0.004925)\n",
      "16. feature 98, (0.004619)\n",
      "17. feature 147, (0.004449)\n",
      "18. feature 81, (0.004346)\n",
      "19. feature 31, (0.004255)\n",
      "20. feature 20, (0.004216)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAGiCAYAAADpzQ3SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOydd9gcVfXHP98ECL1HlBo6hioEBInAD0RBaSoICAKKICoCIkhRaVYURVQQC9IUqSpRQVCqtEiC9CIxtIgldASlnt8f527eeffd3bmzuynveD7Ps8/77uyce+/szJ65c+4pMjOCIAiC+jJidg8gCIIgmLmEog+CIKg5oeiDIAhqTij6IAiCmhOKPgiCoOaEog+CIKg5oeiD/2kknS7pC7N7HEEwM1H40QfdIOlhYCngtcLm1czs8R7a3AL4qZkt29vohieSzgKmmdnnZ/dYgnoRM/qgF7Y3swULr66VfD+QNNfs7L8XJI2c3WMI6kso+qDvSNpY0k2SnpF0R5qpNz77sKT7JD0vaaqkj6XtCwCXA0tL+nd6LS3pLElfKshvIWla4f3Dko6QdCfwgqS5ktwlkqZLekjSQR3GOqP9RtuSPivpX5L+LmknSe+W9BdJT0k6uiB7nKSLJV2Qjuc2SesWPn+zpGvT93CPpB2a+v2+pMskvQDsC+wBfDYd+6/TfkdK+mtq/15J7y20sY+kGySdJOnpdKzbFj5fXNKZkh5Pn/+q8Nl2km5PY7tJ0jqFz46Q9LfU5wOStso47cGcjJnFK16VX8DDwDtabF8GeBJ4Nz6R2Dq9H50+fw+wMiBgc+BFYP302Ra46aLY3lnAlwrvB+2TxnE7sBwwX+pzMnAMMA+wEjAVeFeb45jRfmr71SQ7N7AfMB04D1gIWBP4L7BS2v844BVg57T/YcBD6f+5gSnA0WkcWwLPA6sX+n0W2DSNed7mY0377QIsnfbZFXgBeFP6bJ/U/37ASODjwOMMmGR/C1wALJbGs3navj7wL+CtSW7v9D2OAlYHHgOWTvuOAVae3ddbvHp7xYw+6IVfpRnhM4XZ4p7AZWZ2mZm9bma/Bybhih8z+62Z/dWc64Argbf3OI7vmNljZvYfYEP8pnKCmb1sZlOBHwG7Zbb1CvBlM3sFOB9YEjjFzJ43s3uAe4B1CvtPNrOL0/7fwhX2xum1IPC1NI6rgd8AuxdkLzWzG9P39N9WgzGzi8zs8bTPBcCDwEaFXR4xsx+Z2WvA2cCbgKUkvQnYFjjAzJ42s1fS9w1+Y/iBmU00s9fM7GzgpTTm13CFP1bS3Gb2sJn9NfO7C+ZQQtEHvbCTmS2aXjulbSsAuxRuAM8A43EFhKRtJd2SzCDP4DeAJXscx2OF/1fAzT/F/o/GF45zeDIpTYD/pL//LHz+H1yBD+nbzF4HpuEz8KWBx9K2Bo/gTzytxt0SSXsVTCzPAGsx+Pv6R6H/F9O/C+JPOE+Z2dMtml0B+EzTd7QcPoufAhyCP638S9L5kpYuG2cwZxOKPug3jwHnFm4Ai5rZAmb2NUmjgEuAk4ClzGxR4DLcjAPQygXsBWD+wvs3ttinKPcY8FBT/wuZ2bt7PrLWLNf4R9IIYFncfPI4sFza1mB54G9txj3kvaQV8KeRA4El0vd1NwPfVyceAxaXtGibz77c9B3Nb2Y/BzCz88xsPH5DMODEjP6COZhQ9EG/+SmwvaR3SRopad60yLksbqsehdu9X00Lh+8syP4TWELSIoVttwPvTguLb8Rnm534E/BcWlCcL41hLUkb9u0IB7OBpPfJPX4OwU0gtwAT8ZvUZyXNnRakt8fNQe34J76m0GABXNFOB1/Ixmf0pZjZ3/HF7dMkLZbGsFn6+EfAAZLeKmcBSe+RtJCk1SVtmW7K/8WfYF5r000wTAhFH/QVM3sM2BE3l0zHZ4+HAyPM7HngIOBC4Gngg8CEguz9wM+BqcmksDRwLnAHvlh4Jb642Kn/13CFuh6+MPoE8GNgkU5yPXApvkj6NPAh4H3JHv4ysANuJ38COA3YKx1jO87AbePPSPqVmd0LfBO4Gb8JrA3cWGFsH8LXHO7HF18PATCzSbid/ntp3FPwhV3wG/HX0pj/AbwBP5fBMCYCpoKgSyQdB6xiZnvO7rEEQSdiRh8EQVBzQtEHQRDUnDDdBEEQ1JyY0QdBENScOS4J1JJLLmljxoyZ3cMIgiAYVkyePPkJMxvd6rM5TtGPGTOGSZMmze5hBEEQDCskPdLuszDdBEEQ1JwsRS9pm5SudIqkI1t8vllK0fqqpJ2bPttb0oPptXe/Bh4EQRDkUaro5QURTsUj/MYCu0sa27Tbo3hk3XlNsosDx+LpUDcCjpW0WO/DDoIgCHLJmdFvBEwxs6kprPt8PMR9BimV6Z3A602y7wJ+b2aNLHq/B7bpw7iDIAiCTHIU/TIMTqc6jcGpVnuWlbS/pEmSJk2fPj2z6SAIgiCHHEXfKiVqbpRVlqyZ/dDMxpnZuNGjW3oHBUEQBF2So+inUci5zUC+7Rx6kQ2CIAj6QI6ivxVYVdKKkubBS7JNKJFpcAXwzpQPezE89/gV3Q01CIIg6IZSRW9mr+IVbq4A7gMuNLN7JJ3QqGovaUNJ0/BCxj+QdE+SfQr4In6zuBU4IW0LgiAIZhFzXFKzcePGWVZkrHKqqTUxhx1rEARBv5A02czGtfosImODIAhqTij6IAiCmhOKPgiCoOaEog+CIKg5oeiDIAhqTij6IAiCmhOKPgiCoOaEog+CIKg5oeiDIAhqTij6IAiCmhOKPgiCoOaEog+CIKg5oeiDIAhqTij6IAiCmhOKPgiCoOaEog+CIKg5oeiDIAhqTij6IAiCmhOKPgiCoOaEog+CIKg5oeiDIAhqTij6IAiCmhOKPgiCoOaEog+CIKg5oeiDIAhqTij6IAiCmhOKPgiCoOaEog+CIKg5oeiDIAhqTij6IAiCmhOKPgiCoOaEog+CIKg5oeiDIAhqTij6IAiCmpOl6CVtI+kBSVMkHdni81GSLkifT5Q0Jm2fW9LZku6SdJ+ko/o7/CAIgqCMUkUvaSRwKrAtMBbYXdLYpt32BZ42s1WAk4ET0/ZdgFFmtjawAfCxxk0gCIIgmDXkzOg3AqaY2VQzexk4H9ixaZ8dgbPT/xcDW0kSYMACkuYC5gNeBp7ry8iDIAiCLHIU/TLAY4X309K2lvuY2avAs8ASuNJ/Afg78Chwkpk91dyBpP0lTZI0afr06ZUPIgiCIGhPjqJXi22Wuc9GwGvA0sCKwGckrTRkR7Mfmtk4Mxs3evTojCEFQRAEueQo+mnAcoX3ywKPt9snmWkWAZ4CPgj8zsxeMbN/ATcC43oddBAEQZBPjqK/FVhV0oqS5gF2AyY07TMB2Dv9vzNwtZkZbq7ZUs4CwMbA/f0ZehAEQZBDqaJPNvcDgSuA+4ALzeweSSdI2iHtdgawhKQpwKFAwwXzVGBB4G78hnGmmd3Z52MIgiAIOiCfeM85jBs3ziZNmlS+o1otC5Qwhx1rEARBv5A02cxamsYjMjYIgqDmhKIPgiCoOaHogyAIak4o+iAIgpoTij4IgqDmhKIPgiCoOaHogyAIak4o+iAIgpoTij4IgqDmhKIPgiCoOaHogyAIak4o+iAIgpoTij4IgqDmhKIPgiCoOaHogyAIak4o+iAIgpoTij4IgqDmhKIPgiCoOaHogyAIak4o+iAIgpoTij4IgqDmhKIPgiCoOaHogyAIak4o+iAIgpoTij4IgqDmhKIPgiCoOaHogyAIak4o+iAIgpoTij4IgqDmhKIPgiCoOaHogyAIak4o+iAIgpoTij4IgqDmZCl6SdtIekDSFElHtvh8lKQL0ucTJY0pfLaOpJsl3SPpLknz9m/4QRAEQRmlil7SSOBUYFtgLLC7pLFNu+0LPG1mqwAnAycm2bmAnwIHmNmawBbAK30bfRAEQVBKzox+I2CKmU01s5eB84Edm/bZETg7/X8xsJUkAe8E7jSzOwDM7Ekze60/Qw+CIAhyyFH0ywCPFd5PS9ta7mNmrwLPAksAqwEm6QpJt0n6bKsOJO0vaZKkSdOnT696DEEQBEEHchS9WmyzzH3mAsYDe6S/75W01ZAdzX5oZuPMbNzo0aMzhhQEQRDkkqPopwHLFd4vCzzebp9kl18EeCptv87MnjCzF4HLgPV7HXQQBEGQT46ivxVYVdKKkuYBdgMmNO0zAdg7/b8zcLWZGXAFsI6k+dMNYHPg3v4MPQiCIMhhrrIdzOxVSQfiSnsk8BMzu0fSCcAkM5sAnAGcK2kKPpPfLck+Lelb+M3CgMvM7Lcz6ViCIAiCFsgn3nMO48aNs0mTJpXvqFbLAiXMYccaBEHQLyRNNrNxrT6LyNggCIKaE4o+CIKg5oSiD4IgqDmh6IMgCGpOKPogCIKaE4o+CIKg5oSiD4IgqDmh6IMgCGpOKPogCIKaE4o+CIKg5oSiD4IgqDmh6IMgCGpOKPogCIKaE4o+CIKg5oSiD4IgqDmh6IMgCGpOKPogCIKaE4o+CIKg5oSiD4IgqDmh6IMgCGpOKPogCIKaE4o+CIKg5oSiD4IgqDmh6IMgCGpOKPogCIKaE4o+CIKg5oSiD4IgqDmh6IMgCGrOXLN7ALMNqbqMWf/HEQRBMJOJGX0QBEHNCUUfBEFQc0LRB0EQ1JxQ9EEQBDUnS9FL2kbSA5KmSDqyxeejJF2QPp8oaUzT58tL+rekw/oz7CAIgiCXUkUvaSRwKrAtMBbYXdLYpt32BZ42s1WAk4ETmz4/Gbi89+EGQRAEVcmZ0W8ETDGzqWb2MnA+sGPTPjsCZ6f/Lwa2ktx/UdJOwFTgnv4MOQiCIKhCjqJfBnis8H5a2tZyHzN7FXgWWELSAsARwPGdOpC0v6RJkiZNnz49d+xBEARBBjmKvlVkUXPkULt9jgdONrN/d+rAzH5oZuPMbNzo0aMzhhQEQRDkkhMZOw1YrvB+WeDxNvtMkzQXsAjwFPBWYGdJXwcWBV6X9F8z+17PIw+CIAiyyFH0twKrSloR+BuwG/DBpn0mAHsDNwM7A1ebmQFvb+wg6Tjg36HkgyAIZi2lit7MXpV0IHAFMBL4iZndI+kEYJKZTQDOAM6VNAWfye82MwcdBEEQ5CObwxJ1jRs3ziZNmlS+Y69JySKpWRAENULSZDMb1+qziIwNgiCoOaHogyAIak4o+iAIgpoTij4IgqDmhKIPgiCoOaHogyAIak4o+iAIgpoTij4IgqDmhKIPgiCoOaHogyAIak4o+iAIgpqTk70yaEXkygmCYJgQM/ogCIKaE4o+CIKg5oSiD4IgqDlho59dVLXxh30/CIIuiRl9EARBzQlFHwRBUHNC0QdBENScUPRBEAQ1JxR9EARBzQlFHwRBUHNC0QdBENScUPRBEAQ1JwKmhisRcBUEQSYxow+CIKg5oeiDIAhqTij6IAiCmhM2+v9VwsYfBP8zxIw+CIKg5oSiD4IgqDmh6IMgCGpOKPogCIKak6XoJW0j6QFJUyQd2eLzUZIuSJ9PlDQmbd9a0mRJd6W/W/Z3+EEQBEEZpYpe0kjgVGBbYCywu6SxTbvtCzxtZqsAJwMnpu1PANub2drA3sC5/Rp4EARBkEfOjH4jYIqZTTWzl4HzgR2b9tkRODv9fzGwlSSZ2Z/N7PG0/R5gXkmj+jHwIAiCII8cRb8M8Fjh/bS0reU+ZvYq8CywRNM+7wf+bGYvNXcgaX9JkyRNmj59eu7YgyAIggxyFH2ryJrm6JmO+0haEzfnfKxVB2b2QzMbZ2bjRo8enTGkIAiCIJccRT8NWK7wflng8Xb7SJoLWAR4Kr1fFvglsJeZ/bXXAQdBEATVyFH0twKrSlpR0jzAbsCEpn0m4IutADsDV5uZSVoU+C1wlJnd2K9BB0EQBPmUKvpkcz8QuAK4D7jQzO6RdIKkHdJuZwBLSJoCHAo0XDAPBFYBviDp9vR6Q9+PIgiCIGiLbA5LVjVu3DibNGlS+Y5Vk3LB4MRcw02++TzNbvkgCOYoJE02s3GtPovI2CAIgpoTij4IgqDmhKIPgiCoOaHogyAIak4o+iAIgpoTij4IgqDmRM3YoDvCPTMIhg0xow+CIKg5oeiDIAhqTij6IAiCmhOKPgiCoOaEog+CIKg5oeiDIAhqTij6IAiCmhOKPgiCoOaEog+CIKg5oeiDIAhqTij6IAiCmhOKPgiCoOaEog+CIKg5kb0ymPX0Wlg9CIJKhKIPhh9xowiCSoTpJgiCoObEjD7436PXJ4J4ogiGGTGjD4IgqDmh6IMgCGpOmG6CYFYTpqNgFhOKPgj+15jdN5q4Uc1yQtEHQTC8mN03mtkt3wVhow+CIKg5oeiDIAhqTij6IAiCmhOKPgiCoOaEog+CIKg5WYpe0jaSHpA0RdKRLT4fJemC9PlESWMKnx2Vtj8g6V39G3oQBEGQQ6milzQSOBXYFhgL7C5pbNNu+wJPm9kqwMnAiUl2LLAbsCawDXBaai8IgiCYReTM6DcCppjZVDN7GTgf2LFpnx2Bs9P/FwNbSVLafr6ZvWRmDwFTUntBEATBLCInYGoZ4LHC+2nAW9vtY2avSnoWWCJtv6VJdpnmDiTtD+yf3v5b0gNZo2/NksATLT/JC1SYM+XzgyxCPuRnl/yc+dv535Ffod0HOYq+VQ/NYVrt9smRxcx+CPwwYyylSJpkZuNCPuRDftbKD+ex10G+Ezmmm2nAcoX3ywKPt9tH0lzAIsBTmbJBEATBTCRH0d8KrCppRUnz4IurE5r2mQDsnf7fGbjazCxt3y155awIrAr8qT9DD4IgCHIoNd0km/uBwBXASOAnZnaPpBOASWY2ATgDOFfSFHwmv1uSvUfShcC9wKvAJ83stZl0LA16NQGFfMiH/PDrO+Q7IIv0n0EQBLUmImODIAhqTij6IAiCmhOKPgiCoObUUtFLmlfSLrOp78UkrZO57/I99jWqR/mv9CLfK5LO6lH+4PR30y5kzy220Q8kjZC0cL/ay+hv4z62NY+ktdJr7n6126G/A2d2H8EAtVH0kkZK2lbSOcAjwK4V5XeQdFJ6bV9R9lpJC0taHLgDOFPStzJEf1WlnxbcnPo/t0v5bXrsv2XfFcaTdUPswIfT3+92IbuBpBWAj6Sb8+LFV24jks5L534B3LvsAUmHVxlIcj/+oKSjJR3TeGWInlalnw79bwE8iOe0Og34i6TNSmSu7LHbj/QoPwNJ60s6SNKnJK3fhfymkn4v6S+Spkp6SNLUEplej7/RzmqSrpJ0d3q/jqTP96PtIsO+Zmy6ID8IvAf30d8UWNHMXqzQxlfxHDw/S5sOkvQ2Mzsqs4lFzOw5SR8FzjSzYyXdmdN17hjbMI+kvYG3SXpf84dm9osS+ZGSFms3DjN7KmMMaxbfpKR1G2TIAcwv6S0d+r+tRP4+SQ8Do5u+b7m4dbqRnA78DlgJmNw0Bkvbcxibzv0ewGXAEam9b2TKA1wKPJvkXqog1y++CbzTzB4AVz7Az+l8HkfPioGVkW6IuwCNa/1MSReZ2ZcqNHMG8Gn8+891/+7X8f8IOBz4AYCZ3SnpPKDK+EsZ1ope0jTgUeD7wOFm9rykh6oo+cR7gPXM7PXU7tnAn4FcRT+XpDcBHwA+V6HfZSR9p92HZnZQifwBwB7AokDzU4gxcPG3Yw2GKrmifFtlJ+ko4GhgPknPNTYDL5PvD7wMrmTa9b9lJ2Ez213SG/EYjx0y+2zwazP7jqTvm9nHK8oWmTuZOnYCvmdmr6h68edlzaybp6uVJDUHL87AzHK/k7kbSj7J/SXDfLNIq8lFoY2ya2+dwnVTpHGTzjWB7Q68xcz+CyDpa8BtVFOUz5rZ5RX2h96Pv8H8Zvanpmvm1YpjKWVYK3rgEvwHtivwmqRLaZFLJ5NF8WAv8BQOVTgeVzY3mNmtklbCH4XL+A+uaLvlTWb2cUl/TvmCqnKvmb2lm47N7KvAVyV9tcKTTzNTzKyjMu+EpKvMbCtJV5jZIxXFL8ZnrKt123/iB8DDuMnu+mQOerZiGzdJWtvM7qooNx2/UfbKJElnAA2T2x6UX5eLANvR/iZdpuju6vbaa+JhYF7gv+n9KOCvOYIFM881kr6Bj3nGE1XJE2Wvx9/gCUkrJxkk7Qz8PVM2m2EfMCW/Ff4ffmd/N7Awnh//MjP7d2YbuwNfA67BT9xmwFFmdn6m/KZmdmPZthZyt5lZZZtis3y37aQbRM8/NknL4JnzZkwczOz6md2/pHuBj+NmmA/S9KPr9EOV9Gd8jeSjeA2FQZhZzhoLklZMKbgb7wWsYmalN3pJd+E/8Lnw9CBTcUWTY3rq5/kbBXwSGJ/6vh44zczampH6cO32a+y/AjYEfo9/l1sDNwD/gs5PxZKu6dC0dZqE9Hr8hXZWwp+A3wY8DTwE7GlmD/fadpHhPqMn5dS5Grg6PW5ugyv90/C0n20pKONfANfiF4yAI8zsHxWG8V2g+aS32tbMyxX6aMWT6WJdsdUjfMaj+yk99t94VN4NX4hs2DcNVxZlfLbH7o8BjsST5TUr5jLTz2740+BcwEI9jOESCufZzEzS+eStU2zXQ7/gSqFrGk9EwAlmdgRDv8OO4r30DVzUo3yDX6ZXg2tzBc3s/8CVrZkNWnxNCrgTvR5/YwxTgXekxfwRZvZ8P9ptpg4z+rcAKwP3mNl9he3zmdl/SmQnm9kGPcyIN8HvxIcweFa4MPBeM1u3RH4DBpuaDHjCzB5rI9IsPw+uZM7FZ6aDMLPrSuR/3ap/4Boz+2nmGB4A1uk0++sg25jRDukfOKlhd81o5wtm9sWq/SfZbbuwzyJpDXwh+uv4YlqDhfH1ojVbCrZu61wz+1DZthZy76f193d7jsLo8YloTTO7p6yPDvLfpf21d0O37XY5liG//4Zu6CDT0/EX2jkYOBN4Hl+YXR840sz64tXTYFjP6NOK+54kLwdJXzGzHwGUKfnEK5LOpM2iaMZi6DzAggydFT6HZ/Es46QW2xZPCnx3M7u9k7B5xa9bkofQ9Iz+svoH9pS0lpkNqQ/cgqnA3HTnLdJqRrs4ngn1u8B+OY2Y2ReT99CquL22sb30qcLMLpf0HlxpF2VPKBFdHR9/80L487njLtCt51K7728dSfua2dUl8r08Ed0iqd1N+ggze7Kk70ktti2O/44vMLNvl8gDIOkhWte4KPWaKtysmxdWF6ZwLbSh1+Nv8BEzO0VeT/sNuMvwmUBfFf2wntFLugfY0MxelLQE8Dsz27CC/JLAO/Aat0P8ls3s7CFCrdtZoYvFwE7tjQO+ZWYdfZkL+4/G3frGMlhZdbXQmRTNZDNbr8M+jRnZMsC6wFUMXsgqu0mWjSHbhit3az0YV1i3AxsDN+ccv6TTgfnxdZ4f4zfoP5nZvpl9b2JmN+fs20J2hucS0PAUm+G51O0id1oQvtDMmivBtdu/6yeipnYWA/YB3mZmXQUsSpoPuKnCuV+i8HZe3NVycTMrjUOQtCNuvtuBwanXn8dLoN6UPXC6O35Jd5rZOpJOAa41s1/2a/1iUD/DXNEPerwqe9zq0M66ZnZHD+NYDTgMGMPgBclePEqyzUny4I0L0hgOwGfE05Pdtdv+by9R9Hu3+wzyb5Id2r+jzPRV2PcufH3lFjNbL83Ujjez0qC5wg+t8XdB4Bdm9s7MvkfjM/gxDD732QFBPXoutWuzkjmy2wX1fvTdQr7XRfobzGx8hf27vlm3aa/Kb/dMfLK0Ij5hGokr/Mp6rBPD2nQDrFxYhFTT+yp+xI9LOpruf6wX4XbOH5MfcNEWSUtRzU10CTM7Q9LByS5/naSO9vnUT6sI0MWAvYCO9sdeFXnqv9WPYTHcHFdFyfzXzP4rCUmjzOx+SatnyjZMfC9KWhp4Ev/R5XIp8EfgD3R57s3sqD4r2tWpYErrcUG9ua256VKvyKvTfQivTJcrU7yGRgDjqL64PqXH339xPNnHL0m4JWE0MLVgmfhwZ8nqDHdFv2PT+1Y25xx6/bG+ambfryrUYkEK3E75NtwUkcsr6e/fk735cdyMUcZkBtf2NVzRXYMv0pXSYkEV3I98EvClEltlsw94o/9rqVaEYZqkRXF3yd9Lepr8kpW/SbLfwANtDL9h5zJ/L09O0L2ibbGYDn79vAm/WebyXmD1Kgvqah0stBge03JxhvzzDK0r/SJwHfCx3HEw+Bp6Ffer/0AFeeji99/r8cMMD61fFWfv6feSa9/PZlibbvpFmZkiQ/443G/3lwy2U3dMIdDC/NFQdLea2b8q9L8dfqEuhy9iLgwcZ2a/zm2jWyR9Hf9xnJc27Yb/eJ8FxptZpbxBfRjP5ngwy+Vm9krG/qMaCk7uTz4v/oSQpfQkfQm3KV/Ww5i78lxKx1qkcf08mBbqc9u5HNjFMuNOksyZbfq+1sx+m9vOnEA3v/9+Hb+kU4GzzOzWKv1XZVgr+rSYsqyZnZreT2QgB8VnzSzrztrrjzWt/DdjOSv/SX5eYBX8YvlrrlthQb6rgK203xvwYJk1U//3Aqfm3mgk3Whmm7baJukuM1u7RH4t3D2x2P9JViFKVF26J6b9WrnWVbGxPg8sgC+gvgyVQ/i7UrRN8isy8P3dZ00+4RnylzATFtQz+p0Hj8ItnvvzKj5ZLAIciwc5gj8RnGBm2dHJ/bhZd4vcxXU1PBHjC5AXLFeV4W66+SypPm1iFL4otwDuopSl6HEzydGSXsLNIJV+rGZWxaY7g2ST/Aqeye8R3Ma4bJotfC5nRproKmBLnt73POAs4Bz8uNcH/iRpj5wbBbCgpLea2cTU5ka4yymU5OxIN+qTgK8ykPNmA+AXkg4zs0sz+ocu3BPlOXKWwXP1FBOrLYx74WRhZr0EWzV4EbhdUiVFK2khPCHXBngKBgHrSpoM7GtmrXLJtGICg71OspC0LZ4PaiwDivrEHIUpaWzq80YG8i1tAXxO0g5mdm/mMH4C3M2AueZD+G+/bR6aFjR+/y8zYAYt/f33cvwFtq2wb/eY2bB94SaO4vvvFf6/ZRaOY37g87hLHLg/93YZcifj9uCFCtsWxu3Tp2TIbwJ8BngMOLTwOg64I0P+FjwhVPP29fyoHZUAACAASURBVICJmce+IXAXHqX5MHAnngl0AeADJbJ3AGNabB+TOf6jcFe4V/HYhefS+yeBr5bI7o2vRTyPR1Zfk14TgPdVOPfC7eFfSO+XAzaqeP3s3eqVIXdWOtcjmsZzDHDOTL7m98PXYbZM1+zC6f8/AftnyF8FbN1i+zvwoKnccdyes21OO/5CO8u3evV7vMPddDPFzFZp89lfzWzlEvk1zD00Ws58rTxNbqOdC/BZyV5mtpbcF/hmK7H7SXoQWM2aTkKakd5vZquWyG+Oz4IOwL1+GjyPZ2fsmG9F0r1mNrbqZ232XwQ3BT5TQaYv/ffinijp/WZ2STeySf77wOvAlmb2Zrkv9ZVWIZ4jtTMPAwnWHrC89YUH210jnT4r7HOhmX2gzYI61sF8kEwO461pHSp5jdxgZm8u6ft+M1ujzWf3lckX9r0Zj0S+Ib3fFDf9bZIjX2hnBwbMP9ea2W9K9u/p+Av7N7574etDK+LnPzuyOofhbrqZKGk/S9GwDSR9DL+zlnEosD+tMwCWRQYWWdnMdpUnR8PM/pNcp8qwZiWfNr6mwVF37YQbrpRnWQrYkjQCWNDyHtslaTEze7pp4+KUFKWRtKeZ/VTSoU3bG2PLyZvyiqTlzezRpjZWoFqq1t9IWsDMXpC0J25+OsXygtiWlVeF6jYE/a3mieX+DGBmTyelnY288MfZ+BORgOUk7W3l7pW95ltpeHZ1k3NHzUoO3Gsk79JnRHEhfEajvl5VRS8dAJyTJhrgicE6xng0k7yeNmSgHsXBksZb58jwXo+/sf+gNaw06azidZTd0bB94SHDN+GP3N9Mr2vxyktLzcJx3IRHN96W3q+MR1eWyf0Kfwpo3r4nMKFC/+fhj44LAPfjaU4Pz5DbH7gV2Bz3PV4If0KYCHysRPZj6e+xrV6Z494J+AseTbg2sBbuQ/wAsFOF47+TZJ9O/x8MXJcpe0f6+y7cbLNu4zxmyk/Eg1wa53408OeK189k3L2x8X41PDK5TO5s3Eyjpu1fAM6t0P+BwKIVxzwRWLfF9nUzr/3PA7+hYLrDTXYTgGMyxzCCZB5M1//CVY6h6fopmr9GAnfOzOMvaTv7+stus98Nzo4XPvP+VHpt2eLzxUrkJwGfKNuvg/zW+Gr/dHxW8DCwRYbcMumCuRa/SZ2U2vkTsEyF/m9Pf/fAc5bMXXahFmS3w/21G/671wPbz8Jzty6+EDwZ92M/p9UPqKSNhpI9Bl+EzP6xNL4nPJPne9P/2Yo6fecT8CCfL+M3qV0qjn/Iuco5f0m5XYTnX78Edz6Ymv4uUqH/LwFTgAvx7K/KkBmPOxAch+f62Q6vy/AwbtLI6fdAvHDQE+n1CPCpit/d9X24Bu/E0yY03i+eoeh7Pv7UTnFt7TB80nZFr8fU/BrWNvpcytzlJK2CzyR3xZX+mbidNfvLSba5jfGZ5S1m9kQF2S1xzxHhWTivypVN8vfgC6jn4QvS1ymF9FdppxvUhxQAbdqdy8yyzDfyKODf4edwM/yGe7uVuHYm2TPpMQRdnnJhK/z8XWWFLKqZ8j/BTYXFwh9zmVlWhKS8cMVYBq6frMIbTW0IeCf+HY7Dlf4ZndpKnkufoHDt4q65VVJ8N7yHsC5S9Er6Ah7dfAHunkhqK6cMZqONrupR9OP4JR1beNsI+LrEKrpYl/bzP6Los3JnJPv2dnhpwtdx161Tci4aSeswVNl1rDIjaUtLGQY1tIDF+8rkC/sehCc1uwMvi7g88FMze3uJ3Jr4+sKE9P5kBqprfc8yFqMl3YQHaw2qt2kZC5wq5CRRk997RV/2N+Jpdm81sz9KWh5/ojonQ3YEfpOcambPpBv2MmaWU/O30cZiuLdN8dxnLeQn+cqFP5LcSGA+S/73kjbGM6qCP5VUUpyS1sUV/Ta40tsY+L2Z9Vo3oFVf3zazQ9L/B5vZKYXPzjKzfTLbeajFZrPMGJZCO29ioB7FxKo3q15JNzuzLmMpSun3I8Kc+CLjMR5YB3d3fAD4DvBW3HWx1FULvyFMwm2mZ6bXT6qMq3mMOWMu7Duq6b3w/Ddlcr/GM+013t8LvB/3Rf5VZt9du7JRMJHQZC5pfl/SzrYtth2QKXtC0/uRwM8q9P1F3L31WgZcNK/u9jup+P2dhAcGNt5PTef097g/d247B+E36ivw7I9zp+0j8AC+VjI7Ap8svJ+Y+p9KhumqX9d+j9/f+p1eJbI9HX9Bbi28PvUj6TUZWKvfxzrcvW76QgoweQYPPjnSBmZSE5O7VhkbWwVXxGLXbf5v9b4Tv5C0ow2YOt6IL3SVmR/eZINTsT5naSaePJdy+I2kd1t3UYXW5v9W7zvxBUkv2cDT0RH4ovLpHaWc5SUdZWZfTTPri/C1glw+gD8VVa4WJqnjU4OVm962wmehDZ41s+2TGeaPFYayJB47MMhLycxel6fXaEVZsGJZBalO1342ap1z5lm8Jm1ZdPck3NzSqOVQHEeZ112vx9/gh8ChZnYNzPDAapQW7Bv/K4q+7ELaxdqEjZtZToTdzZLGWn4034zm2/zf6n0nfgVcLK84tBy+OHhYhtygqE4z27jw9g2ZffcSVbyopPfiM8dFCz9aUa1A+w74Dedw3OywRtqWw4eBn8lzw/8fniNnSA3ZDtyNFx/Jzk1U4HX8PJ+Hz8RziuUUGWGD1zGOgBnJshZsIzMEMztG0mLJ/DjI/GTt1xvmscGV0G6wlJBLXhavdOzJ5DWi8H/jdzoyd+x4fehN8Ccp8Bv8LcBqkk4ws3PbCeJP7O/Hv/fzgV9avumk1+NvsEBDyQOY2bUV5bMY1jZ6tU6zOwNLtnVJi1sHO7s8e+FeDLWxZ+X6kLQZ/kP9B9WKOz+D22MFvJ2BbIXCV+4Xy+k/tfVJXMmNwV0fS4smyOvNHmkpfUFh+8bA18xsixJ5ActZkx98hTGf2elzy1yMTG29Ac8+OBmv2tPxwtbgILm5gR/g4fhnpL5zg+XG4dkP72Zw+oKsG01ayN0d99y4F1f6V1rGQrSk+/Ao3Oebti+C25lbBiS1aOcE/IY3Fb/5pEPoWBy712DFh1NfrSZhZvl5on4NfNTM/pneL4WvsX0U98hZK6ONFfFzsCNuPvmKlVR36/X4C/v+En+CbNyQ9gTGmdlOOfK5DHdF/zru1tb4UQx69KpwsdyEzwLuYuBCx/IrTE3B3aOa5TsG7Gho9sFBWHnN12KwknDb+l24zQ8rCVqS56W5AA+lbyi2DfCAk13NrDToTF0We+kHGkh122Ae/FowSp4q0k2uHR2VXFM79+A3ieZzX1oPoEVbuwKn4vb1b2TsfyieMuCAxs1WHmz2fdz7p1UgYKt2HgDWrmJ+kvQz3DupVbDiFma2e25bvaCmxHlp8nGXeYR6lSpla+KmmA/h6x4Xluzfl+NPTzLH4wvx4JO9460piLFXhruiPwV/VLsR+Dn++FT5gKp4eLSRvzpXMfSTJtesIZjZ8RltLMVA9koYcBH7Z+YYuk6z2nSjGkLZjWpOQNJ1Ztbxhl0ivwyuYN6LR3VeSAUTgqQD8HKEjcf9f+NPY9n1EeTZKz+eYdMuyrwBNxm+xOBJwig82K3j9aM2aUcaVHiiOg33MmvYxN+PT/4OB35jZv/XQXYl/LvfEV9QPz/JlLo29nr8s5phrehhxh18C/zRayO8qO73reCqmNHGp/EfyG+okE++IH8abqf9dZN8mXtlr4txze0tYGYvlO85RK7rNMnynB+r4/6/ldKspiey24HLGTB5zSDnRpXaEe57vqJ5ofDl8IXmnCeSpfAMokub2bbyrIqbmNkZmX1/K419AoPPfY5r6nX4OsmFeJDToOst9/pLbS2I/5678UXv2vykgRgQcB/+soLkDbnX6bAQWuGJSnimyoZr6g2Wn578dTxY6lI8Id4gZZgz0ej2+Avyv8fXCJ9J7xfD69W+q0o7ZQz7xdg0g79GnmtkN9zd7UE8b0kuL+MVhj7HwMk2INcXdz78B1KsM2pAmR98r4txAEjaBLctL4h7kayL2+k/USLXSJP8YTxCsZs0yb2kWV0fP2fvwW3rP8dNDlVnH6eREovh5//fuAkkJ7HYWbiXxOfS+7/g5qwsRQ80TAPFhewyj40GK6R9P4ano4ABhZd1/akpn3+68VbK54+7BZ9Ik/kpE2t65dLLQmiRbcw9xWbEbUg6wMxyPK5OYGDMzYvXucfS7fE3WNIKiQDNcyXlOkLkY7PAX3VmvfDH1Q/id+SbcE+T5bpo56/pC58dx7AGbqO7Dfgp8G48KrJKGxNxb5uiX/rdGXI9pUkuyIwHPpz+H43PrKt+D2/Dc+jfB+xQUbaRAqF4/KVpjtN+t7aQnelpbvt07eyIT2o+gseBrJv+fxDYsUI7WXmBmmQa6Tuuw9NunEx36TtWxE1PE/Enm/UqjuMmCmlPcM+jyyu2sWnOtpl0/JMppCXGb/6R66bpS3oBf/Q/Ap8dvK/4qtDOBLz2Z7fjWA3Pr313er8O8Pku2tkVz/lRmpCsSW5i+ltJ0SWFMCSvCe7e9mBm38fiTyN/Se+XBm6sOP7R+DrBtXiwz8ZVj58uE4ulPpcoyG5cRfEBS+Gz/8vT+7GkfDsVj2Ed3CU0+/qlx3z+hf2/hRd/2YT8gKFfAvu02L4XcGnFY18TfxJ7mJIaBi1kl8QdKd6O5xq6hBTwVaGNIYq1TNn26/hxT7lHca+bc3Gvn22qXj9lr+FuurkIf1xaI72K5JhOGryGV/i5hu5Kqf0If3z+QZK7U9J5eLKojrRYjPs0fhFV4TFJb8Mf3efBIx1z8q2YpautaWNWmuTEe3HzxW1J9nGl3CVlSGrkF5oXt1F/wCosCBb4Dv6dLSXpy8DOeHbEHA7Fb/QrS7oRv0nsXKHvs+jN9IM81806uM16hnsj5dfv3Gb2cPNGM3tY0ty5/dOd+Wmsmb23Rd/nSPpcK4EibRZCv2wVc7yY2RPyXPIN19qdW13TbcawCf4kObrJMWBhyn35ezr+wv6/SwvTjTxZn7YKebJyGdaK3jLzYWTwq/TqlvnN7E8anIc6xw+6uBi3DwOLcfOU+f43cQCefXEZ3OPgSnyGXMa9kvayppww8pzu92f2/bKZWePGUDHY4wzcLvwonib4ncXv0DJ90c3sZ/Lo5kZisZ0sM7GYmd2W3FxXT7JZRT8KLGlmF8oDrjCzVyW9VibURLeR1f3K579ts4KV5/zpREtFKM8dlBPwNIXBC6HLA59QZj2DNq61KwE7SzLLC9ibB7fNz8Xg4MHnKL/Z93r8jf1PMLNjcEcQJI2Q9DMz2yO3jRyGtaJv4Z5nuOnjBqvgdYObXCY3tb19Bfkn5BkEG8puZzwnfBmtFuMgea6QuRicZgDdXBifxNMnfASfDRm+gDkf+TU3L5T0AzyydT/cRpy7EN7W9a0LlgReNLMzJY1WU5K4dkiaH5/Vr2Bm+0laVdLqVlJhqMALSSk2zv3GeAh+FbqNrD4W+IOkrzD4/B1JipLN5BIVUmjIk8T9ls4pNH4t6UfAIZY8vdJN/mQgJx1Gp4XQUqwPtXqtt8I9vR5/g15TcOTRb1vQrHzRuujFKfhsdLcK7dyGB4w03u9OZs3UtP9K+KPji8DfgBtoYTudid9DT2sEDOTzPwjYqov+t8a9lk6iRR3QWXQddLVOgJtZPlv47uajwmIsbs++EVfuN+Kmm3Uqjn+zJP8APsu9i/x6Av3I578f/kQ7Erfv3wm8s0Rm7nS+n0h9T8JdJU+ioo28x3Pfj5q9lQv39Ov40/jPw+sfX4mbbvr+PQ17P/pWyFMj/MHy09yuhNuI98A9SPbCi3tXmpmlO/oIy/Rl7mPQyHWkNQJLkYCS7raM8O8ObT5qZstn7Pdp4CIzm9ZFHy1rlTawzDgCSbeT1gkKx5+Vj1/SJDMbp0IUpaQ7zGzdrINghptqt6afriOrS9o8ycxy8h019q+cQiPJzYfHYAiYYmYvSnqrNaXVaCH3XTqf+9z0Iz3X7JV0u5mtJ2kP/CnmCLzCV8710+3x9yUFRy7D2nTTDjN7Ssov3GhmUyXths9qHsNnM9k+7enR+es2OOjhM2ZWtiDYKUS9bDGsSFdrBCXkfn8LA1dIegpfULvY8qMCu6lV2ope1gleTj/WhuzKFBbky0gK8mdmdk96v5ik3c3stApjeNRSTYA+8gFKEttpaAqN5XAvto0lbWwZAUPpd9Lss38RbnPvxKSytjPpuWYvMHdavN4Jr8PwSq4zQg/H3/zbfxr32Pom1X77WdRS0cuj1UpzRbSYUS6OP75OlJQ9o8QXs45uvEkX27sp9/w42sxuzuyjE92uEXQi90I/HjhenvlwV9zmOc3M3pEh/iMze2f5bqX0sk5wHF6dajl5/pJN8YXxXPYzs1Mbb9K53w8P4srlfrmXVqXI6hJybtTNdu5fttk+M/pevfib6YFX5AVYGtf+aKoHfZ2Ou3beAVyfFrPLbPSdKD1+65CaYWYwrBV9m0f/xYHHyasE368Z5UgVKtqnGeKoDLlTcRtvr3wSD3JaQ9LfgIfIWJxtsZg94yOqL5D9C8/e+ST5KY5HV+yjJWZ2kqSt8R/n6nhx6d9nyl6ZPHYa7m0HWzX3thFKbh4ASelUnVF2FVmt9tlbRZ6yGZRiQl2m0GjVdMY+2+CBUr3Si2ttY/H1n2a2TGHbo/TmKJBtD1ePKThyGdaKnqGK2oAncy/Wog1U0nhgVUteG1RTdD8FrpKnDjB8RpmT+bLrggtFzHPpv6PqGgGdZ26ndPhsBpI+js/kR+PrHPtZvvfIImpdOALIn9Emr6E/mtnhmf0WZc/FMwb+0cxyXUqLXIE/UZyOn/sD8CeEbKxCOuYmGp42ra6j7HUCdZFCQ54euJVCEx6AVsZIDc5BPwjLdC22Hlxrk/zrkg7EXZwb24wS02cfjr/BWfQYh5HDsF6MlbQh7sd8edP27YHHrcllskM7x+IFkVc3s9UkLY0vMOZUl2q0sS0DF9uVZnZFhkwjH31LLD+n+V/x6MA/4jm4K7npqYXPfgX3xK/hOWo2wy/8P5rZHZn9Pon7UbfLSZ5VYFyeT3087q46Gf8e/mglOcWT7JZJ9u2499Tt+HeYe6MbgbvHzjj3wI/NLNuXXp5Ubl88QnTexvbc42/T5oynjIx9J+Iz4Qm5i/nqPcX2S7iHWk/56FNbQyZpOdduQb5ygfFej7/Qzq1mtmGTM8DtZrZe1uBzyXHNmVNfePj6mBbbV6FC3U78xy0GpxDIcm/rcfwPApu3e1VoZxSuaD+H+/BOxZNE5crfCCxceP9mMnLlpH0Pxhejjsd9o+8CPpUp29ecHrgJ5CA8AOu1CnIjcdPNUXgI+v0z+9w39X8RngLgr7jJ8Uqq5Rpqrns7gmp1b7tKoZH226DFtu0z5LJrApe007VrbaGNh1q8ps7M4y/sey09pODIfQ13080S1joEfIrKI/uK9OK10RylNw/uLvWClUfnPW9dFKhowWv4o/pr+ELUP6lW2u4reADIe3Ab9znkB2Dti0d2NoJGTgRuxhOUldEX05Wkz+OLqAviRVcOI7NmqqSrcP/pm5PMhlYtL/tDtHiEtwozUmAVM9tFHrR0dlqYLX0iLNBr0E23KTQAfiRpb0vZMiXtDhyCK99ZQdcpOBqY2Yo99N/r8feagiOL4a7o5+vwWRVl3YvXBtYUpSdpJzw3fhkP57QvaWvrvLj4HD6T/hbuyfJkTrsNzOy3yb3sStxuv5OZPZgpLvwG0+A18hX4h7I6kG42s0067PI+3Kb6WzyD4C2WnzPlTtx3ei08aOmZ1F+ue+24wv/zArvgDgFVaNjTn5GnHf4H7s+eS691b7tNoQGulC6W+6A3YlByPKlyTWPfNbNPddil60mapC3N7Op260SWt0bU7fE3+ug1BUcWw91Gfzru5fF5KxyIpOPxwhP7txUe2tbW+AkScEWJYs1p7xYbXGy7l7Y6VsCStCN+kW2E59a/CbczX1XSbnPQypa42edhyAtaSZ47ezPgmrcTXnHq22WyuSijJFyaxY1Prw/gnhTjO8k0yS+IK8zDgDeaWY7XVLu2bqjY90fxrItr44tzC+KeQx1zqmsWB910GMdqDMSg7FThJpnTdtm1fxiwKh6d/VV8knaemZU+UUo6zsyOU+vaxWb5a0RdH79apODA1wpzU3Dk9TPMFf0CeD71jXA7O3hI+CS8YHB2IYPkO7uqmf0hffkjLT/CtTgjGIHP8jYvmYVmk6Po0n5r4IVADgHeYGadnniQ1NEF1fJr5q7PQIWf683szzlyuWT82NfCF1M3x7/7x/DF2GMy2j4wyW6A2+cbHji5lZKK42qc+49bhcjablH/6t6uhteZXcq81uo6eE2AttlXNdS1+Q34E9FLqfNK1dE69FNa5rPbSZqkg83sFEnjzeyGiuPqy/FLugB3INgrfffzATdbnxdjh7WibyBPYVAs5zW16fM1LUUutpHfD08qtriZrZzuqqeb2VaZ/RdnBK/iM+IfVbH1lrRfpuguAdbDMwL+Mb0mVjBfNHz/lzezB3odb7/JOP6GyeYGvJBIFdfCw3HlPtlSUq+mzxezDoWam5Rt49yfVOV7lLt4Hmgp5UaadPwk9/rrFXWRQiONsS3WQ/qGpn7Kzn3DtTbX1FiUbaQ+qFwzul/Hrz6k4MhhuNvogRl+5FM77HIunQOTPok/FUxM7T2oCuW8rHs/6H7xNXzVvqVLX5mNX+6OehK+kLyipPVwT44s985ZQEebv5m9p6OwdImZvb+N7DdK+r6KDteO9SfC8QY8GvtQ3E5+OF5qLwv1HnRTOYWG9S8GpYyy9Z4xwJ5J8VZyrQXuk/Qwno++WL+5tO5xH4+/pxQc2Vif3XjmxBclrlw0uZfhN8Bs90pgWdxG/S/c4+USYNk+jv8XPcqXVcuZDCzCYPe6u2b3eSuMZa2Zef57vHYWwRfBJ6XXN4FFuuhnPL4o+3d8jaCK7OX4usQd6f1cVc5fkl+ZARe/ncksx0cf3BtL2t8nc79uXWvfiKc+WKH5NSuOHzc5XYdnvvwZ/kS4Rb++v8arFjP6DMrsU9dJOhqYL9n7PkE197Az8VSju6T3e6ZtW3cSkrRZp8/N7Pr0Nzc3fNuuSj5/1cyebZrRzXSbXgvXRBXem5mtnP65u8euejmWMtmfAHfjihbck+hM8vP5I+lDwBdwj411gMskfdgyA8/ovfhJVyk0El25N2ogirwVZmb7pn/OKmmna9fa1P4/8HW9Tn20fSKkR/dO6z0FRxb/K4q+jCNxf/C78CjHy/BF3lxGm1nRTn+WpEMy5FqF7Bt+4S1LhUo1JZQpq7slfRAPS18VnxllpantkXFN70cwkHWxrwu6M5GVm5TA8fK0yVV4PzDefE3n55J+iafQyF2Q66n4iXWfQgO6d29s5VWyPO5IUOW678W1NpdOMRG9xuD0moIjj34/IsyJL/zkd/p8S3orDv4HfBY/Mr32BK7qop3x+GP0LVSIrstot8x0Mz9eWPnW9PoSMO8sPD8jcBfNu/G8QWP73P7MNN3cjCvpxvtNca+JXsc8T4V9eyp+gkfk/gz3p6/03eM35R/ga2T7pe8jKzK60MZK+MTqL8DHqxx7kl8I9zb7Mh5tfkOfr5+2v59ejz/pnmOA36fzcAk+q+/b+M2sHoqeFhVd8MfZXPlz0kV2M/B1YHtgsQryy+PRbdNxO/2vyLTxJfmt8FDoa5gJFZrItPEDC8zq84Y/Qd2ffugrz6R+yqoljcRtq8s3XoXPFi+RXRe38T6Mu2f+mcwKT8CFhf9PbPrsyorHOBfuebZWq99DiWyvKTS6qjCGp9r4KV4UfR9gri7O7Vrp5nA+7nV2DU0pIfpw/ZRNlHqqsMYsSMExrN0rJf0f7lEzCv+B7W8pJUKXLlNL4wtRh+EeDDPVtCVPOfA5fCb2JTO7sYe23oZ7IMwYszUV/S6R/TGeDCore2E/kDQNf+z+Nr6INgjLz165KZ5XfgX8+BteE6VpCCR9Cl9Q+ycDeczNKvqBS1o4CWbnMW9yqRt0vebGTqR9ewq6kVfI2hCPQxiP516508w+lilfOQZF0kW46e4kPHPkoDUFy8xe2YtrbS5l56LHGJzmFBw3WJ/csgf1M8wV/a34qvw98mIbXwU+ZGa3VPyh7IkHzaxNKi6O28yyioIkl6r9GKpoO0bWSXodDzm/g9b5UnKzV56Le03czsAPxiy/HFvl7IX9QNJZdF6Qy41MvB/4NO49NENhWEYqCHkZv7fm7NtGfhRuYx/D4HN/QobsDOXeQtFnT1R6DbqR9CIDKTT+UOW76DYGJbk1zlh4Z7DDQNZNOnN8nRZSc9t4p5ld2eazXmNwTsaD9V7CzW7X4+eub9HFMPwXY+exFAhlZhdLug/4haQjqeZp8W3cPnY6cI21SJRWwqX43fgPNM1MSuhXlZlxuG2167u2mT3W5HVT5Ti67XOfPjX1rDWlqq7AY1RYuGzBpUl+MtX9n+eX9BZ8jWK+9H+jaEjHqOYmVjazXeUJtTCz/0j5pTSB3fGZ/CeAj0rKSqGR6CoGxczGVBhfL+Q81bUqYPQs7i77pXZKPtFrDM6n0xgaKTjOxF0+u07B0YrhruhfkfRGcxcp0sx+K3xFf+XcRsxsSUlr4nbKL6e78gNmlpV0C1/IPaLq4C1lrpTnI18Fv9j+atW9Bu7GL45uywf2kr2wJ+TpCw7H7csG3ItHljbX4Wwl25jxXiPpG3hFpmIpvra5XjRQXWsqcG0yARRlS+ulJpY1s20y923m7/gsGjyRWbHPf1Rop6egGzO7FLhUg1NofJa8m81LZvZy476SzEBZE450re3B4HN/nqVKbX0iZyyX4xOb89L73dLf5/DcQ9t3kO36+NP+zSk4fkIF99BchruiPxJYisKPwsymSdqC/Ox7Dfvq8riNdwweBFOlopgsQwAAIABJREFU7uRvJL3bzC6rINO4KL6CJ2J6BJ/ZLZt8jD9XZm/UQJWbhYB7Jf2JwcoqN7K1l+yFXSNPxnYSbnL7Jj6T3QB/KjssKaBONBdYLrprGp0LLDd8nR9Nr3kYKAFY5cnoJklr59yYmrEUVStp3uabezIJ5XIcPdS91dAUGnuRZqgZXKcuYlDk0bsTcHPFZPzcbwF8Tp6uuW3KkpnApja4yNBdkm40s02TWbcTXR1/gfnwG3xXKThyGdY2+iLqIVeLPPz5hvS63symVZR/Hl9QeQmPbmwsBnbMR5/scwsBn24s3qSbzknAf8zs4BL5zTt9bvlVboYomlmBpDuAHZtNZZLGAJdaZr4PSSvZ0PxGQ7a1kd3FzC4q29ZB/l78aewh/PyXhs+3aGOIPb6qM4Hcj74RdHOLVQi6kVdq6yqFhrzC1r4UkorhFbY6Kpa0CPm15nYlvQOf5PTFrJmzVpeuw/3NbGJ6vxGeq2rdjIXYro6/wvgrO5W0xPrsxjM7Xvij1QPAQ+n9evjCYr/a/+5MGveDpJtt0/aRwIMV2jkxZ1sH+Sn4zOprwLvpIoS/y+O/t5vPWuw7xP0NnyF1K5td+YoWofPkh8+/EX+CuQ+Prlw/vbaggosd7nm2H7DGTDpPnfzIu4pB6XR8wH0V2hnic17cRolrbdpnQ3wx+iHcTfZO3O6+APCBEtmeYnAyxtaXSlzD3XTT4Dj8xFwLYGa3S+qlakwzpbVjJS3DgHsfaRxt68EO7GKtvG1eU4q0y2RroHmNYNsW29oNYhVJy+O2wu2A0yQ9Y/2uWzmUVyQtb2aDXCuTu1rHpFppvzVw+25zkfGFKdRebSO7LX5TW0bSd5pkS/tuYGaPSBqJmxCr/p7ehZtYlmWwff554OgK7ZyJL6Z+V57JtVLd2ww6LezuA5wur//byJx6g5WbG0ZIGmVN9vi0XlXle9yboUVM9mlss84LqaR9bgXWlrQIPvF6pvDxhW3Ein11c/y59OXJoC6KfrbkamkgL5+3K76YNMO9kQ6FvxP3StrLmvzdk12wNBxa0sdxm+DKGpx9byEqpDCQtCx+M3s7HgB0D27GmtkcC/xB0ldwO63hs6sjybtJrY7fmBZl8ILZ8/gMtxOP414VO6S+i7Kfzhk8tPfDx3PWdMQ83//Zkt5vZpfk9tminavlqYY3xD25DsBvgP1S9G1/S2a2FwyKQTkVDz4r0y3nAJdIOtAGYl/GAN/Bn1A6kjyMPohnW51Q+GhhvBhRNmpykW3oEctwke3h+GcptbDRSzoDTyd7JH7CDsKjAw/oU/tlObEfwEPOK3kLpKeAX+AV6IuKbj7gvWb2txL5RYDF8MXMIwsfPW+ZASepndfx1AdfsfIF0L4iD876DK6YhN9kTrL8hF5I2sQyYx6a5EYC55hZbgKvVm305Ief2lgUD4NvJLm7Do/uzHL71EwOuul0/auHGJTkcfJZPAWHgH/j5z6nOtQKwIq0uPbxYK/spzJJv2PARbYYh9G82N9KtqcYnIz2s+OBOrZTE0U/Px5hWlwQ+aL1aYExY0HmcmAXq1DRqkl+SwqKzvL8l4vy7zCzPzRt29vyK0Stiz/6b4Z7Hz2IV6LPzWc+W1GXAWtJ9nd4NaWXu+y7kbYiW7G0aOMS3EW2cb4+hKdRyMqAqZkcdCPpF+3GIukJeotBQSnbo1VLptaQXQB3XHhdXilrDTzFcpXiM10HB/bp+IeY/hrmTEmLV5m0te2jDoq+SPrSFrAKoegZbe5jHdKlph/quvhTRdG9sWNkqqSORaRzT7Ck6/GZ8GF4utYf4/692dXk5QEb4/HZyZ7e/cwNatGAe2hLLD8y+CZ8Jts8Iys1h8iLwq+Pu/q9UJDN8qNPT5Or49kTu/HDR6nSUdm2jHa6rnur3lJoNGJQxuP1W0tjUDQQx9CSCt//ZPyaXQxPBjgJeLHKU5qkH+IOF5VdZJN85eMvyPYlBUcZc5QdqVsknYfbJV8jFdGQ9C0rqR6Uq2g6KfnEhPSqSsNcU8zD3lhoMDKi+hKb4+aPRnrcY8zs57mDkDQJj8S7CX/03Mz6VAquhJP61E5XAWuJx9NrBAO+9VVo5Ydflf+oULdUnrunSoHpnoJu1CaFBm5HL5PtNgalm++65RDM7EVJ++LK+uuSqqa4Hg/sI6+PUMlFtofjb3Awnpeoa9NfDrWY0Wug9uMe+MV+BO5e1/FEacAP/X24q9tP0/vdgYfNrIrnw2wjPRn8AP/xLIsfx4mtPHrayI82s+kdPs82A/WCpLnxbIR/q2JjlvQl4CarGLDW1MZC+I+7K/NbLyTT2Tm4khDwFJ7DKWudQr3Xvb2PLlNoqMcYlF5JSv0TwMnAvubR8XeZ2doV2lih1facyU6vx98P018WNpP8P2flCzdbzA1cBGyett1RQf76nG0d5FcFLsa9bhr1a6dmyK1AwWcd95g4Bff6qJKP/C/AR9L/8+GeCzf18fvN9iuv2O7pwJrp/0XS93cX8Ddg9wrtPI/Pov6Lh60/DzyXKbsWnvn0kfSa3BhTpvxoPEXtZcDVjVeX38fCwMIz4XsuS7N7EfCmmXSOW8ag4Gsqq6b/hT+FPIv7sL+lQvub4U/TR6T3KwHfyf2+09/FW71m8vEfml5n4DeJowrbDu33eaiF6QafzT6MZ4G8Pt2hq9joR6sQSSn3wR9dQf5M3M52Mq6sP0xn3+MGF+KlyJ6VF+S+CPciWA84DfhoZv/vsLR4Y74Ad5BKyhRWpEqCrCq83QY8oz6M193cSdIb8fwjWeYnM+vFDPBD/Id1DYA8fcaPgLdlyv8MuAB38zwA9+tu+3TUil7c+3K7aNNvv1JodKJdDMrBeB4Z8CfodXEl/RZ8ovL2sobTetz2xXGm33BW1lY8t812DDahzmiKfNNpJ9odf79ScGRRC0VvZt/BLw4AJD1KITNkhunh03hiq0bI/Bg89Wgu85nZVZJk/rh3nKQ/4sq/TO7x9P+ewE/M7JvysOrScnSS1jAvP7akpCWbPu6nCWJm2feKni5b4zc6zOwfqpB8Ub7zHsCKZvZFScvhM9Q/ZYgv0FDyqe9rVa0c3BJmdoakg81TTlwn92mvQi8ZMHNod/76tUbSDa/agGfMdrib65N4XMXXcxowDyzcoNsBmNl26W8/gytz+z4eQG1ScPS7v1oo+mbMn42KNq+DGXBdG0RSqs/h5pc10ub7rZpP/H9TOw+mhbG/ATmpSovabEv88Q1zV7Gcfg/Fb0hFf9/ij7pTUq8qzKwZ/TOStsO/r03xnCHIk71VSdN7Gm662RL4In6TOxWPSShjqqQvMBCksyceCp9LQ1n9XV5I5nF8naQKvWTA7BobyJ56ojUtZsuDAKvesKrwuqQ3AU/jFda+XPisyrn/szxg6iIGe01lFa1poO4i2/vBUaQJTsm2nqilom9BW0WVlOo3zWwT3PTTDYfgQR8H4YpmS/wRvoyrJV2Ip6tdDLfvkn4ApX7dZtZ46vg+8Dszey4prfXTOPpF15WvSvgY/iT2RuAQS+mm8R/+byu081YzW7/hbWFmT8tT4LZF0rnmLnB/xJ/gfoFfJ9fhZqRcviQPXPsM8F3czp4dWZvoOgNmJmU36p5SaHTZ9zG4K+RIPC/VPTDDQaI0GV2BxfFI2OKkxvDzmTfA7iPbs5pv02dfUnBkDyItDNQalUe2Ho8vAv3CuvhCJI2xoRkYNzTPodFJTvgF9ia8fujf0va3AG8wsysy+7/TzNaRNB5Pe/xN4Ggze2umfNdVkuYE5BWy3oaXkltfHkB1pXUOcrsXV2YTcDNf0cUVy49hGBLQImlFM8t+KlB/MmBWDrpRIYUGntiuwUL4Yn7XEcOFPvaxNu7J6cltISt4BMmDH0fYLPR+UpeR7Zlttzz+5Gm1HnACftNr8DweeNWvXDne3/+Ioi+LbG2kGX4V99zISjNckJ+MR1c2FPVmwKlWwcUryS2BexE8amaTy/YvyP3ZzN4i6avAXWZ2XtkxN8l3HQLeC/IybNeaV+VpeF68H19Y39vMsvyhk1vtrviTzNl4zpHPN9s+m2QOwotKr4SbjmZ8RIVSdpJuBLa1FKAn6c3ARVYh0rLMvS/DPbKroBv1IYWGPBr1cIaaPTqaDeWpkR9rPMVJ2gs/948Ax5X1L+mz5j7z36XFGoRlltFMbVWObFf/gv3mtplQ53ZIP/8jiv57ZnbgTGx/Q9xOvD2ubL6CewM8ViL3G+BIM7s7mWtuwx9nVwZ+aGbfzuz/N7iyegceR/Af4E+Wn899pteHbdcv7kr3iqQP4uaPd+KeF8eaWannRaGtNXCTj4CrzCyrQpak75vZx6uPfob8e/B8Le/BI2TPAfYws9LF9Ap9lD2R9lr3tusUGvJc7qczdJLQcaIi6TbcW+ypNDE6H/gUPst9s5VEdUt60syWkHTI/7d37nGXjuUe//5ikmMzMopkMDk0EjtyjoioZLMLnXaiVCoUOgyJ1Mag3WEqmtLYsaeNaZcOQoohohphUPjQwaFICantkGv/cd3PvM+7Zr3rOd3r+N7fz+f5vGut572f537XWu/93M91X9fvh8f5x1Gm77ljVa5sV6QaHDUwtq+EdSF3tl8bXuF2JCU0qMPvbxJ+vrTdVvHc2+Hhn58B00u2uSX3+Bg88wD81vmmCudeCf/CZXnJa5V9D8LvzwM268PndUPu8QLG64hX0YT/HLB9H793++BVxUuyzyDy8TtqkgOXA8s3OP6V+DrPynj457vAwpJtS+n+t2l3Y+7xF/FZ/DLfiw7tb8UHxxtpmAOPr6cts5V978q81qH9r/EQ4prAc7It9ndoqBdjJf3MzLYOjw/B7e++BRwv6aVmdkrBIdplrWQYBVkrbW7fVsJDIGdJwopv3/K3bK/E87cxs0flipKlMLO/k1t8MrM/UMI/VmOmyMsDB8nTS2vFiGsSK/PieuBjIYzwLeA8M/tFvG4uS5uQwWr4IuJh4bMvHTooQdvbbsXzva0soaExnabvSnov/r7nz10U+llO0vLmFaGvZHw6c5lx6QzcPnED/C54adeokAMf1jZ2N7Miy8CJaFqD08TYvjRDPdDj1bAZ78I/sD9JOh0XOOo40FvIWrH6tmVN85DvDvHVe/C7iIsB5LaIUzo1jMRePThHJ6JkXtiYrvvqeJx3jtzQZMMu9Dmj9UJSek0lIrGKbqYB2+AqjOsAMyTJwpRzAlqLjD6U21dmoP0GXnPwIB5qvApA0gvxyVJHzKWM5zYNvZnn4k+X9Eyrp2DatAansrF9HYY6Rh/ig6/ABakuMbOtcvsq6TirgXpfaD8Dv22/LGQOLGcFsquS1sRX3dfCF28vDa/vAmxpZj0paMmlGnZ8rUvnbpd5sTL+3ayUeSH3+jwAD6XcamavK2gSBTXwKy55/KJkgqa+t7fj/q1fC3/LHGArMyusDlZ7Y/NSHsSStsW/+5ea2WPhtY2AVWIPdAX9qKVgKq+d2Ra/6NWqwZFr3bRiVrCYXZnYsaBebnh2xl14WtpduDQruFRvYZwvd5xz8Bjrl/Bc6LmU1MsI7Q/BjTvuDM83xBcEm/xttWOuNc51fcvz5ajg2drgvB/OPd6vZd9JFY4zB9fQvxjPgZ/aw/eusV8xcE6n1yiIObd+fhO91qH9um1e26nOd6fsuYFdc4/Xb9n3b736/ML5jm+3lWz70172tfbf2O8OdOmDW6n1y1Pw+7+CZU26K7S/Ab9l/mXutSUl2v0k9/icln1dERJrOcdsPG/3Kbw6OBME+zNwcg/Of327x1X/flxjZo1efb9azr0YF2Sr9Nl3+lvLXmjxRby5eFrl53Pb2XjWVVH72skINDQ2j/XZR/4sV8XvJqq0+QQeLqw1fuCL32fhZikAs3AVzqh/27DH6Ntirk9dRVjqZvyLW7iAOQGPm9kTCrIFIRxRJiaW11TZtGVft2QH8lxpZidLOsXMPlr869HRBI/bPe/EPODNYVHsRLnR+fOsnNZNU2r7FUuajWdbrSgpE+ETXhU9r8QhmvreNpHQaGpsHuuzb4ykF+N39auH5w8Cb7OwZlTAkYQaHEmVa3Dwi/J83CEPXIn2PHzwj8ZIDvSBW3FDgAlRPPW+RZKyf9jd8WrD75Zo12lA6MXiyefxWdmrGF8w0ytsgsftnnfii4xp3ZyIDzbfpJzWTVNuDjUAy0naEJfBKGXMbmYnAydLOtnMZlc9sble/Y2SFliNohtrIKFhzY3NY332MaitYGrNlFPB70TPDxd9zOwpSf8salSVoR7oNbEdmfA4fRGnh9+dgy/g5dvPqdCVj+KCXEtw/ZaLcDu/IqZK2hdfTJ4qKfPlFB4O6DZPSprPsnobQLXqwppsHmayYtlZ7bMqHKey1k1EDsNnY4/jtQCXAJ+qcgAzm61molpbSzqB+kU3HwuDzY647s2n8cG/jITG98KFbj2qyWdsIBcjU+4x4Xmv1SQrK5gqKMdKalvIZuUXkx+TV8RbOO62lMg6qspQD/R4BepptBcBekZRYxtT75uSPc4I2QelMBdGOxcPhVTJvFiE33Znj/NZIr1QztsLr6bdlT6kB5rZcpEO9WTIh87+WaZTzc6tNuY1DMdKOslC5khVJJ0CvJH6olpn4aGacdWpFcjavBY408wuDBeOMtSVWP7X3OPW7LJeyyfXUTBtVIOT4yg822emXE5jOi7hEZd+LHrE2vBb5C0n2Hd3ifaH4rPwx/Cq1mz7DXBuhX7sTcPMiz6/j5v36bwrAVNyzzfGB6x9Kx7nLeGf5R686Oo2WrJ4uvg3bI8P0L/P3kvgSxWPcRuwQoM+XNfwb/gebt5zJzAV9w8u5dAG3BzpfZyCL+qu2YvPreXc0/Aw5mK8+O6z9DZza3l8je7F+f+HmNuw59FvDPzF2vidSnqumd1f0L6xqFM4zmL8Cn6FhXxnBUXJgnavw6UOMvGqjzMm7HSEVVBArIMiCkPVPP+VeIbBHaFQ5me4Y9MsXImy9LqBamrdNEWunPkG/MKeffaVtINUQ1QrtMvCBvvjmTq1im5C3ceeeLbQHaFaeTMLdR0FbefhdnmVJJYlnRna3RL+D3+K31msDhxtFcztmyJpKzz8th5jUQ4r+v/Nta9dgxNqgc7Dq7nvLN/ragz1QD8oSLrOzLbJF7aUHOhvArY1zxLaC89eeBM+s9nPzPbocr+jCUPVPP9SE2dJn8Tzxd8X4uuLrUD9U2Nl+G2pcrGuywSf/Y1WQlAud4F9PhVFtUL7dsU2ueaRi27a96GWxLKkW8xs0/D4A8ArLGcjaRWKHZsilyk+Gs++Wxrys3Lm4OfgIoQ3kAu7lZ0khULLA8L2ND7on29BYjoWQx2jDzOB2fhCaqYv8QAeNzzFzP7ao67Uzbww8xgvuCjZWeaqf4vl+iHd5v7wRTuInPViD2lN5TsNwDxVtUyMPV+Gnz9WJb2ThtwdZnQWLlCH47nlZchkFBbjoadKWH3pjpi8uma7KDaSkfiTmZXJkmvHVsAsqzljDheTU4FTw9hxHJ4IEmv9ChjygR431/4xPhvIdK2fh6vPXYB/gXpBPvPiG3iFZpnMC0laBfg7Hnb4Um5flayTukQRhmrATXJdonvxWWEmATG1TGMLXp+hFD3zjM3y6NfqTpeX4T24eubz8TWCS3FxvUJi3TFNkH32MH5XFE0uuR1m9ruQrbOhmc0PC+FlMt4yG8n7aGYjGYPjJX2VZe+oyrhUNa3BQdJ6ePjtAPyu4MN1jzXhOYY5dCPpNjPbuOq+LvRjqXpdxXYH48UljwAPWPANlTtMnW5mr4zb0wn70UgYqsF5V8T9fNfCjdFvDK9vD8w0s3M6tc8d5wxCHr2ZvUjSNFw/pet59Cqp61JwjExFNM/D+MX3U1agMy9pAT6zzGalr8UlOTbBTVBKmW3XQdLx4dwbm9lGktYO59yhoN1GjNlIftaCC5OkPXCJ7aO61ec2fTkXf69uYbxxy8Ed2uRrcLbA15cq1+CENZ4p+MT0vDrjSKnzDPlAfylwGfBf2cKrpOfiFXu7m9luPerHlfiM7ud4StxVZRenQv70mniWw9PhtbVwrZuOxiWjgqQtrcWoQtLryt5OKxhz1ImTN0Vu+nE/rr54JXC1mVXKg5Z0Kj6TWxBeeiN+V/UwsKMViLNJugR4fbaYG+4SFwL74rP6WVX6U7HvN+BrStdXWZ/KtX9O64VMFa0Ym5JfK6rQZmfG6m3yM3ABc6y8jecmZvbrKueuQ2Gu+YBzAC7Uv0jSQ5L+AlyBr9zv36tOmNlOwItw3ZFpwPdDX8q0vRdPJ8zHpB+gQGJ5xPiKpKX/aJLeBHysQvt+5tG/EF9AX4LXJdwYBr8q7GBms81sSdiOBXY2szl4NkcR6zI+5v0kMMPM/kG13PY6PBHi09l737HQqA3fkbRULkDSLMpVlcfk2nDe0pjZIjO7Ak+HXJTbrqBa6OkhSWeFzCskzZL0jip9KcNQx+jNKyDnAz8Ers2np0nak6Dv3m1CjPLlYZuK5yVfVeEQ60qaba47swJ+G9czmdYB4A3AQrn3647A23BZhrJ8Hje+WFPSf4TjVblQ1EbSOniM+eV45swtwE8qHmYVSduY2XXhmFszFuduVwzYygJ8sLowPH8d8I0w6N5asS9VOV8u8ztVbv5zMMFApyQn4eYl46wY43ezIzsCB0oqnTmkMWP1DUL2XMaqwNUVzn02PdC6GfbQzeH4wtev8DjZEWZ2YdjX0Wczcj/+icdTTwYusooGBvI0g//GZ4W74Olln4ne0QEmxGy/DdwN7BNmo1Xa9yuP/mk8ZHdS9t2rcYyX4cboq+D9fwR4J37ReK2ZnV/iGFviA5ZwVdSuOmzlzjsHD5++Kpz7EtwL9iMVjrEPHv5YFZcovqMbfe1w/hntXu+UXql4NTg/N7OXtYQdbzCzLcoeo9R5hnygXwJsZ2Z/CyvXC3G538+povFIw35MxWd1O+FCWk/jOtXHFbTLX4im4NWJVxOu5tZD84V+0GYRck08Lv04QNk4bz+RtDk+wO6Eh1DuABaZWeUZWRg8VDYtWNJq5kJkbesJqgw4dWk3oSoTo9eyRXq74p4Sv4We6CwNBJKuwIskfxjWmbbFY/w7xzzPUIducBenvwGY2W/lqnMLwxW6Z8m4ZvZXuZXYC3DZ1u0pZwXYqpPxEF4V+mmq6WUMK/22MmyMmd0o6U5cPuDluE7KTpS49Zb0VjM7tzU9UiGP3Io9Xxfg72FWT7D0EHQ5PTZC6GIQrBgHgSPpgdbNsA/0f5S0RZYrHGb2e+G3wZVW0ZsQ/tFvw+PyZwIHlQnfDEjBS9/I3xrXzMXuO5J+gWvDXIPH5nfqdMvfQrZwWUvq1syyC+VMel9HsAD4ATVDF/kaAnXZinHAmYkXnb0An9lvQzfGZeuxgFDMDZ89P2+CfTv0sB/PKNg/u2B/T1xmBnXDrdu+C9wenq+Npyn2vW8l+j69YP+BPejDGbgm/6/C82m4VlDf358SfW9sxTjMG651BR7+uxJX9WwkUtduG+r0SjO7x0JFbJt9VVa+m/ajKJVvv4L9Z+OLWGuH57cDH2jYrWFiX1wB9DEAM7uPmrPcXmNtBPVaOKLoGJKmSzpG0jxJX8u2Ct3YxszeB/xf6NNDuLXlMHACsDXwVwDzu/Ne69H3k2UkounCZzfsoZthoWi9oCcuMwPME2ZmkurmYg8yZdaKLsTDfpdRT0++b3UEEahtxTgi3BvSU3cD5oT06ugT8DTQ94aiL25PXGYGmKa52INMmUFrJauQjtiGvtURRKC2FeOIsD8uEX26eVLHWsCHYp9kqNMrh4WiVM+QZjkXNx64mbDybmY3TdRm1JB77S7NxTazH/a5S1Eok+Yr6VPANWZ2UYPz9KWOoClyLfxjGSuQuwTX92mkH5QYTxroe4CkY8zspILfWR6vDBRwm9Uwex5mQkrshmZ2WfjnX87MHu13v5oi6Qtm9v6C33kUz8B5HJcvyCozV+vUbpSQtLLVtGJMFJMG+giEmOghLOsyM6H6XUv7lfB82hlmdki4hd3YzL7Xhe4OHCFc8y7ceGRm+PvPtB6pdzYhxFRfT3Vz7Ky9gBdYZKOJYUGuVPpVYBUzWzcUoL3bzHrhxzBpGOqsmwHiQuDZ+GLa93NbWebjolTbhef3UE7PflR4H15Z/AiAeQn8mn3tUXkuxFPinsKzhrKtFOYzrW91p2tDwWeAPYA/gxeg4QVniYikxdg4NF1Mm2lmBwTVRszsH1LvbXb6yOPmrlLA0jDWsNxqrmPBR6AB10p6mZn9PEqPhgwzu7vl6z6ZMs56QprRx+F7kl7ToP0ToTowy7qZSfflZQeJRZKOAVYMi7IX0Hup2rpco5zEck12wQf7OyXdJGlJi6zAKDPOilHS0ZS3YkyUJMXoGxAW0TLP0tqLaZJehWcezMKt6HYA3m6ubT3yyK0A38F4BcSv2gB/OXOCbMsDG+KCXKXNsVuOVVk9cVSQtAZuxbgb/t5diqvQdnTVSlQjDfQDQsij3xb/sl9rZg/2uUs9Q9Ku+N/898JfHhAmGpwzqg7S7bR+rIcuS/1CEawYE8WkgT4Ckn7UmiHS7rUO7c9hzIKw67Zig4akr+MXuT/jFaJX4ZrqD/W1YyWQdI6Z/XvRawXHqOW7OgooghVjopgUo2+ApGeFmfgakqZJWj1s6zGmW1OG+bja4NwQp/2mpEKNlFHBzN5mZhvhaYr34AJdRRoyg8Km+SdBimDLiscYWq2fplgcK8ZEASnrphnvxsXH1sb1tLPUgUfwwaoUZvZjSYtw05JdgPfgA8jnovZ2QJH0VlzLfTPgQeALVLNi7DlBlyhbQH4kexlPk51X8XCjrPXTEcWxYkwUkEI3EZB0mJnNbdD+R/hi7k8ZC1s8EKt/g46kB3HjjjOBy83st/3tUTGSdjCzqyWdYmYfLW7R8VhH4wu6u+N+GA+uAAAIS0lEQVT67gcDC5p8p4YFRbBiTBSTBvpIhBSx9RhfHfn1km0/g9/uP46781yJWxFW8k0dZiRtihfK7IgPerdViXP3GkmLzWxLRfImHlWtnyIU0YoxMTFpoI9AWEydCdzAWLGHWUXfS0mrAAcBR+OGKitE7eiAImk1/PZ9Z/wWfg08C+fAvnasA5KuxfO9XwOc17q/ymcv6YP44us98Xo4PITv/Y6MWTGama3X106NGClGH4etgFl1874lvR//km8J/A63QhzoGHVkfpLbvjAkA95eeO73rjT3O10NuETSX4D/ARaa2f0NjzkUqJkVY6IkaUYfAUkXAIeb2R9qtv8QHq5ZbGZPtdk/bRhSDbuFpLlmdli/+9EOSZsHfZYYx3oJcAAh+8jMdotx3EFG0vROLl2SDrScv2yiHmlGH4c1gFsl/YycdIGZ7V2msZmdVvArPwIax4GHmIHLJ5f0YTM7FXhnli2Tp2rYLvAA8Ee8nmBYRN0a0WmQDxwBpIG+IWmgj8MJXT7+ZBI4GxY+ApyKZws1utuSdCg+k58OLAQOMbNbG/dwNEjf/QikgT4CZraonXFGzFNEPFYiDveHz/wgvPahCTPwmetO+Gc9peHxRon03Y9AqoyNQDDOWAh8Obz0fODb/evRyDGIs7ozgIuBTYBf5LbF4WcV/gCci4cA1wTOlTSQaxJ9YBA/+6EjLcZGIJRsbw1cl/mDSlpiZk3la7PjF/qOjjKS3m5mZ/e7H+2QdIaZHdrwGDcB22VWeqEy9qdVFDBHlTJWjIliUugmDo2NM4JGynMZX3CV2csNvKVeEyRthDvfz2D8379r+Hl2f3pWTNNBPiDGm238k0kyky2yYkyDfBzSQB+HVuOM91LBOCPcph+Pq/g9HV424CUAZvaXuN0dOC7A5Q++wuR0F5oPXCcpsxTcB5gslaEXAg/jIa/JZLbTU1LoJgJNjTOCVOs2k9VsIZMT6Hc/+omkl+LVoQKuNLNf9rlLPUHSzWb24n73Y9RJA30kghXgumZ2W422lwO7tyuWGmUkrR4eHo7nkH+L8XUIo34nM+mRNA+Ya2ZL+t2XUSYN9BGQtDdwGvBMM1tf0hbAiUUFU5KODA83BTYGvs/4ge4/u9TlgUDSbxizYmzFzGyDHncp0SNiWjEmikkx+jgcj2fdXAFgZjcE85EiMnOJ34ftmWGDSZA/bGbrQ3s7OUnP6k+vEj1ir353YDKRBvo4PGVmD2dZN2Uxs08ASNrPzC7I75O0X8T+DTrXsKzEQ7vXEiNCJlw2kRUjMLAS1cNIGujjcLOkNwPLSdoQjzlfU6H9bDzzpOi1kULS8/DishUl/QtjIZzVgJX61rFEL4lhxZgoIA30cTgMOBaPMS7As24+WdRI0qtxPfPnS/p8btdqwGRYmN0DeDuwDpBfj3gUt+lLjCiRrRgTBaTF2AhMFHppfa1Nu82BLYATgY/ndj2KW+pNCmliSa83s2/2ux+J3hHTijFRTBroI9DOTq6KxZykKWb2ZHd6N/gUVUcmRo/YVoyJzqTQTQMihl62lnQCYxIAWYrZZEkvTNWRk48nJc1n2f8doLaef2IC0kDfjPtwpcK9GW8n9yjwwQrHOSv8/mImpwTAOma2Z787kegpMa0YEwWk0E1DQpbA183sLQ2OcZ2ZbROxW0NFqo6cvMS0YkxMTBroIyDpYmBvM3uiZvtTcKOS/2V8Zez1cXo42Ei6FXgh8BtSdeSkILNilDSXNsWBKXQTlxS6icPvgKslfQd4LHuxgoRBNpvfKvea4be1k4FX97sDiZ4TzYoxUUwa6ONwX9iewZisQWnMrKkV3VBjZr+TtCNuxThf0nRglX73K9FVYloxJgpIoZuISFoVDzn8rWK75wInAWub2aslzcIdhyaFJrmk4/G7mY3NbCNJawMXmNkOfe5aoksED4b3AhsA9+Z3MbkyznpC8oyNgKQXS/olcDNwi6TFkjYtapfjbLyadu3w/HbgA3F7OdDsi2cuPQZgZvdR484oMTyY2VwzexHwNTPbILetnwb5+KSBPg7zgCPNbIaZzQCOwt2SyrKGmZ1PcJcKuvSTKc3yiWDSYrDUMzUxCYhkxZgoIA30cVjZzC7PnpjZFUCVweoxSc9hbKDbFi8gmiycL+nLwFRJhwCXUe1CmUgkOpAWY+Nwl6TjgHPC87fiqYJlOQr4DjBT0tXAdOANcbs40EwHFgKP4AYsH8eLaRKJRATSYmwDMi3t4BS1HmOen4uAT1QRJZO0PD7ICbhtMmnfTKAVdFPKo08k4pBm9M3YMqSIHYiniImx4o/SLiSSbgTOA84zszuj93JAkXQoIfNC0k25XasCV/enV4nE6JFm9A2QdDhwKA1TxMLF4oCwPY0P+ueb2e/j9niwkPRsYBpwMpCXqn00GYMnEvFIA30EJJ0RK3sgOFQdB7zFzJaLccxEIjG5SQP9gBDMxPfHZ/X/xMM4n+5nnxKJxGiQYvQDgKTrgCm4R+x+ZnZXn7uUSCRGiDSjHwAkbWJmv+53PxKJxGiSCqYGg4cknSXpBwCSZkl6R787lUgkRoM00A8GZzO5tW4SiUQXSQP9YDDZtW4SiUQXSQP9YDDZtW4SiUQXSVk3g8GRTG6tm0Qi0UXSjH4wmInb6W2Px+rvIF2EE4lEJNJAPxgcZ2aP4HIAu+H69mf0t0uJRGJUSAP9YJAtvL4WONPMLgSe2cf+JBKJESIN9IPBvcF4Y3/gIkkrkD6bRCIRiVQZOwBIWgnYE1hiZndIWgvYzMwu7XPXEonECJAG+kQikRhxUnggkUgkRpw00CcSicSIkwb6RCKRGHHSQJ9IJBIjzv8DUn13gC2dcUIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_importances = clf.feature_importances_\n",
    "x_importances = list(df_se1_features.columns)\n",
    "y_pos = np.arange(len(x_importances))\n",
    "\n",
    "# plt.barh(y_pos, y_importances, align='center', height=5.0)\n",
    "# plt.yticks(y_pos, x_importances)\n",
    "# plt.xlabel('Importances')\n",
    "# plt.xlim(0,1)\n",
    "# plt.title('Features Importances')\n",
    "# plt.show()\n",
    "\n",
    "X_resampled_smote, y_resampled_smote \n",
    "\n",
    "\n",
    "importances = clf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1] # Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "for f in range(min(20,X_resampled_smote.shape[1])):    \n",
    "    print(\"%d. feature %d, (%f)\" % (f + 1, indices[f], importances[indices[f]]))# Plot the feature importances of the forest\n",
    "    \n",
    "\n",
    "num_important = 20    \n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(num_important), importances[indices][2:num_important+2],color=\"r\", align=\"center\")\n",
    "plt.xticks(range(num_important), [x_importances[i] for i in indices[2:num_important+2]], rotation=90)\n",
    "plt.xlim([-1, num_important])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_index [ 3101  3102  3103 ... 15500 15501 15502] test_index [   0    1    2 ... 3098 3099 3100]\n",
      "the classifier is : gradient_boost\n",
      "0.9503288162614587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wenzhy/.conda/envs/py3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of predictions: 15\n",
      "Sum of Y test: 13\n",
      "the at-risk recall is : 0.46153846153846156\n",
      "the normal recall is : 0.9970854922279793\n",
      "the macro F-score is : 0.7129899578879171\n",
      "the micro F-score is : 0.9948403740728797\n",
      "*****************************\n",
      "train_index [    0     1     2 ... 15500 15501 15502] test_index [3101 3102 3103 ... 6199 6200 6201]\n",
      "the classifier is : gradient_boost\n",
      "0.9098140444708562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wenzhy/.conda/envs/py3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of predictions: 38\n",
      "Sum of Y test: 53\n",
      "the at-risk recall is : 0.20754716981132076\n",
      "the normal recall is : 0.9911417322834646\n",
      "the macro F-score is : 0.615233563687172\n",
      "the micro F-score is : 0.9777491131892938\n",
      "*****************************\n",
      "train_index [    0     1     2 ... 15500 15501 15502] test_index [6202 6203 6204 ... 9300 9301 9302]\n",
      "the classifier is : gradient_boost\n",
      "0.8888697152717859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wenzhy/.conda/envs/py3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of predictions: 25\n",
      "Sum of Y test: 61\n",
      "the at-risk recall is : 0.16393442622950818\n",
      "the normal recall is : 0.9950657894736842\n",
      "the macro F-score is : 0.6108833863142045\n",
      "the micro F-score is : 0.9787165430506288\n",
      "*****************************\n",
      "train_index [    0     1     2 ... 15500 15501 15502] test_index [ 9303  9304  9305 ... 12400 12401 12402]\n",
      "the classifier is : gradient_boost\n",
      "0.8617962174876613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wenzhy/.conda/envs/py3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of predictions: 131\n",
      "Sum of Y test: 98\n",
      "the at-risk recall is : 0.32653061224489793\n",
      "the normal recall is : 0.9670219853431046\n",
      "the macro F-score is : 0.6259212101576836\n",
      "the micro F-score is : 0.9467741935483871\n",
      "*****************************\n",
      "train_index [    0     1     2 ... 12400 12401 12402] test_index [12403 12404 12405 ... 15500 15501 15502]\n",
      "the classifier is : gradient_boost\n",
      "0.7653637123745819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wenzhy/.conda/envs/py3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of predictions: 217\n",
      "Sum of Y test: 156\n",
      "the at-risk recall is : 0.26282051282051283\n",
      "the normal recall is : 0.9402173913043478\n",
      "the macro F-score is : 0.5849496036524067\n",
      "the micro F-score is : 0.9061290322580645\n",
      "*****************************\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "clfs = {\n",
    "        'lr': LogisticRegression(),\\\n",
    "        'svm': svm.SVC(class_weight='balanced'),\\\n",
    "        'decision_tree':tree.DecisionTreeClassifier(),\\\n",
    "        'naive_gaussian': naive_bayes.GaussianNB(), \\\n",
    "        'naive_mul':naive_bayes.MultinomialNB(),\\\n",
    "        'K_neighbor' : neighbors.KNeighborsClassifier(),\\\n",
    "        'bagging_knn' : BaggingClassifier(neighbors.KNeighborsClassifier(), max_samples=0.5,max_features=0.5),\\\n",
    "        'bagging_tree': BaggingClassifier(tree.DecisionTreeClassifier(), max_samples=0.5,max_features=0.5),\\\n",
    "        'random_forest' : RandomForestClassifier(n_estimators=100),\\\n",
    "        'balanced_rf':BalancedRandomForestClassifier(n_estimators=200, criterion = 'gini', max_features = 1.0, random_state=0),\n",
    "        'adaboost':AdaBoostClassifier(n_estimators=50),\\\n",
    "        'gradient_boost' : GradientBoostingClassifier(n_estimators=100, learning_rate=0.1,max_depth=10, random_state=42, min_samples_leaf=1),\n",
    "        'bbc' : BalancedBaggingClassifier(base_estimator=tree.DecisionTreeClassifier(),\n",
    "                                ratio='auto',\n",
    "                                replacement=False,\n",
    "                                random_state=0)\n",
    "\n",
    "}\n",
    "\n",
    "def try_different_method(clf, X_train, y_train, X_test):\n",
    "    # clf.fit(X_train, y_train.ravel())\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_predprob = clf.predict_proba(X_test)[:,1]     \n",
    "    return y_predprob\n",
    "\n",
    "# clf_keys  = ['lr', 'svm', 'decision_tree', 'random_forest']\n",
    "# clf_keys  = ['gradient_boost']\n",
    "# for clf_key in clf_keys:\n",
    "#     print('the classifier is :',clf_key)\n",
    "#     clf = clfs[clf_key]\n",
    "#     y_predprob = try_different_method(clf)\n",
    "#     fpr,tpr,threshold = roc_curve(y_test, y_predprob)\n",
    "#     roc_auc = auc(fpr,tpr)\n",
    "#     roc_aucs.append(roc_auc)\n",
    "#     print(roc_auc)\n",
    "#     predprobs.append(y_predprob)\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "for train_index, test_index in kf.split(df_se1_features):\n",
    "    print('train_index', train_index, 'test_index', test_index)\n",
    "    train_X, train_y = df_se1_features.iloc[train_index], df_se1_labels.iloc[train_index]\n",
    "    test_X, test_y = df_se1_features.iloc[test_index], df_se1_labels.iloc[test_index]\n",
    "    \n",
    "    X_resampled_smote, y_resampled_smote = SMOTE(\n",
    "        random_state=0, sampling_strategy='auto',k_neighbors=10).fit_sample(train_X, train_y)\n",
    "    \n",
    "    for clf_key in clf_keys:\n",
    "        print('the classifier is :',clf_key)\n",
    "        clf = clfs[clf_key]\n",
    "        y_predprob = try_different_method(clf, X_resampled_smote, y_resampled_smote.ravel(), test_X)\n",
    "        fpr,tpr,threshold = roc_curve(test_y, y_predprob)\n",
    "        roc_auc = auc(fpr,tpr)\n",
    "        print(roc_auc)\n",
    "    \n",
    "        predprob = y_predprob\n",
    "        j = 0\n",
    "        best_f1 = 0\n",
    "        best_j = 0\n",
    "        while j < 1:\n",
    "            predictions = np.array([1 if i > j else 0 for i in predprob])\n",
    "            score = f1_score(test_y, predictions, average='macro')\n",
    "            if best_f1 < score:\n",
    "                best_j = j\n",
    "                best_f1 = score\n",
    "            j += 0.001\n",
    "        \n",
    "        j = best_j\n",
    "        predictions = np.array([1 if i > j else 0 for i in predprob])\n",
    "        print('Sum of predictions:', predictions.sum())\n",
    "        print('Sum of Y test:', test_y.sum())\n",
    "        pos_recall = recall_score(test_y, predictions, pos_label=1)\n",
    "        print('the at-risk recall is :', pos_recall)\n",
    "        neg_recall = recall_score(test_y, predictions, pos_label=0)\n",
    "        print('the normal recall is :', neg_recall)\n",
    "        score = f1_score(test_y, predictions, average='macro')\n",
    "        print('the macro F-score is :', score)\n",
    "        score = f1_score(test_y, predictions, average='micro')\n",
    "        print('the micro F-score is :', score)\n",
    "        score = f1_score(test_y, predictions, average='weighted')\n",
    "        print('the micro F-score is :', score)\n",
    "        score = f1_score(test_y, predictions, average='binary')\n",
    "        print('the micro F-score is :', score)\n",
    "        score = precision_score(test_y, predictions , average='weighted')\n",
    "        print('precision score is:', )\n",
    "        print('*****************************')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
